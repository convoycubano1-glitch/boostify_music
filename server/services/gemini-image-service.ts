/**
 * Servicio de generaci√≥n de im√°genes con Gemini 2.5 Flash Image (Nano Banana)
 * Para crear im√°genes cinematogr√°ficas de alta calidad para videos musicales
 */
import { GoogleGenAI, Modality } from "@google/genai";

const ai = new GoogleGenAI({ 
  apiKey: process.env.GEMINI_API_KEY || "" 
});

export interface CinematicScene {
  id: number;
  scene: string;
  camera: string;
  lighting: string;
  style: string;
  movement: string;
}

export interface ImageGenerationResult {
  success: boolean;
  imageBase64?: string;
  imageUrl?: string;
  error?: string;
  quotaError?: boolean;
  provider?: 'gemini' | 'fal' | 'unknown';
}

/**
 * Genera una imagen usando Gemini 2.5 Flash Image
 * @param prompt - Descripci√≥n detallada de la escena
 * @returns Imagen en formato base64
 */
export async function generateCinematicImage(
  prompt: string
): Promise<ImageGenerationResult> {
  try {
    if (!process.env.GEMINI_API_KEY) {
      throw new Error('GEMINI_API_KEY no est√° configurada');
    }

    console.log('Generando imagen con Gemini:', prompt.substring(0, 100) + '...');

    // Usar el modelo de generaci√≥n de im√°genes de Gemini 2.5 Flash
    const response = await ai.models.generateContent({
      model: "gemini-2.0-flash-preview-image-generation",
      contents: [{ role: "user", parts: [{ text: prompt }] }],
      config: {
        responseModalities: [Modality.TEXT, Modality.IMAGE],
      },
    });

    const candidates = response.candidates;
    if (!candidates || candidates.length === 0) {
      throw new Error('No se recibieron candidatos de la API');
    }

    const content = candidates[0].content;
    if (!content || !content.parts) {
      throw new Error('Contenido vac√≠o en la respuesta');
    }

    // Buscar la parte de imagen en la respuesta
    for (const part of content.parts) {
      if (part.text) {
        console.log('Texto de respuesta:', part.text);
      } else if (part.inlineData && part.inlineData.data) {
        const imageBase64 = part.inlineData.data;
        console.log('Imagen generada exitosamente');
        
        return {
          success: true,
          imageBase64: imageBase64,
          imageUrl: `data:${part.inlineData.mimeType || 'image/png'};base64,${imageBase64}`,
          provider: 'gemini'
        };
      }
    }

    throw new Error('No se encontr√≥ imagen en la respuesta');
  } catch (error: any) {
    console.error('Error generando imagen con Gemini:', error);
    return {
      success: false,
      error: error.message || 'Error desconocido al generar imagen'
    };
  }
}

/**
 * Genera imagen a partir de una escena cinematogr√°fica completa
 * Combina todos los par√°metros cinematogr√°ficos en un prompt optimizado
 */
export async function generateImageFromCinematicScene(
  scene: CinematicScene
): Promise<ImageGenerationResult> {
  // Construir prompt cinematogr√°fico detallado
  const cinematicPrompt = `
Professional cinematic photography for a music video:

Scene: ${scene.scene}

Camera Setup: ${scene.camera}

Lighting: ${scene.lighting}

Visual Style: ${scene.style}

Camera Movement: ${scene.movement}

Create a high-quality, professional music video frame with cinematic composition, perfect lighting, and stunning visual aesthetics. The image should be production-ready for a premium music video.
  `.trim();

  return await generateCinematicImage(cinematicPrompt);
}

/**
 * Genera m√∫ltiples im√°genes en lote
 */
export async function generateBatchImages(
  scenes: CinematicScene[]
): Promise<Map<number, ImageGenerationResult>> {
  const results = new Map<number, ImageGenerationResult>();
  
  // Generar im√°genes secuencialmente para evitar rate limits
  for (const scene of scenes) {
    console.log(`Generando imagen ${scene.id}/${scenes.length}...`);
    const result = await generateImageFromCinematicScene(scene);
    results.set(scene.id, result);
    
    // Peque√±o delay para evitar rate limiting
    if (scenes.indexOf(scene) < scenes.length - 1) {
      await new Promise(resolve => setTimeout(resolve, 1000));
    }
  }
  
  return results;
}

/**
 * Genera una imagen adaptando el rostro de una imagen de referencia
 * Usa image-to-image editing de Gemini para mantener consistencia facial
 */
export async function generateImageWithFaceReference(
  prompt: string,
  referenceImageBase64: string
): Promise<ImageGenerationResult> {
  try {
    if (!process.env.GEMINI_API_KEY) {
      throw new Error('GEMINI_API_KEY no est√° configurada');
    }

    console.log('Generando imagen con referencia facial...');

    // Crear el prompt combinado para mantener la cara de la referencia
    const combinedPrompt = `${prompt}

IMPORTANT: Maintain the exact same face, facial features, and person from the reference image. Keep their identity, facial structure, skin tone, and distinctive features identical.`;

    // Usar Gemini con imagen de referencia para edici√≥n
    const response = await ai.models.generateContent({
      model: "gemini-2.0-flash-preview-image-generation",
      contents: [
        { 
          role: "user", 
          parts: [
            {
              inlineData: {
                data: referenceImageBase64,
                mimeType: "image/jpeg"
              }
            },
            { text: combinedPrompt }
          ] 
        }
      ],
      config: {
        responseModalities: [Modality.TEXT, Modality.IMAGE],
      },
    });

    const candidates = response.candidates;
    if (!candidates || candidates.length === 0) {
      throw new Error('No se recibieron candidatos de la API');
    }

    const content = candidates[0].content;
    if (!content || !content.parts) {
      throw new Error('Contenido vac√≠o en la respuesta');
    }

    // Buscar la parte de imagen en la respuesta
    for (const part of content.parts) {
      if (part.text) {
        console.log('Texto de respuesta:', part.text);
      } else if (part.inlineData && part.inlineData.data) {
        const imageBase64 = part.inlineData.data;
        console.log('Imagen con rostro adaptado generada exitosamente');
        
        return {
          success: true,
          imageBase64: imageBase64,
          imageUrl: `data:${part.inlineData.mimeType || 'image/png'};base64,${imageBase64}`,
          provider: 'gemini'
        };
      }
    }

    throw new Error('No se encontr√≥ imagen en la respuesta');
  } catch (error: any) {
    console.error('Error generando imagen con referencia facial:', error);
    return {
      success: false,
      error: error.message || 'Error desconocido al generar imagen con rostro'
    };
  }
}

/**
 * Genera m√∫ltiples im√°genes en lote con referencia facial
 */
export async function generateBatchImagesWithFaceReference(
  scenes: CinematicScene[],
  referenceImageBase64: string
): Promise<Map<number, ImageGenerationResult>> {
  const results = new Map<number, ImageGenerationResult>();
  
  for (const scene of scenes) {
    console.log(`Generando imagen con rostro ${scene.id}/${scenes.length}...`);
    
    // Construir prompt cinematogr√°fico
    const cinematicPrompt = `
Professional cinematic photography for a music video:

Scene: ${scene.scene}
Camera Setup: ${scene.camera}
Lighting: ${scene.lighting}
Visual Style: ${scene.style}
Camera Movement: ${scene.movement}

Create a high-quality, professional music video frame with cinematic composition.
    `.trim();
    
    const result = await generateImageWithFaceReference(cinematicPrompt, referenceImageBase64);
    results.set(scene.id, result);
    
    // Delay para evitar rate limiting
    if (scenes.indexOf(scene) < scenes.length - 1) {
      await new Promise(resolve => setTimeout(resolve, 1500));
    }
  }
  
  return results;
}

/**
 * Genera una imagen usando M√öLTIPLES im√°genes de referencia (hasta 3)
 * Nano Banana puede usar m√∫ltiples referencias para mejor adaptaci√≥n facial
 */
export async function generateImageWithMultipleFaceReferences(
  prompt: string,
  referenceImagesBase64: string[]
): Promise<ImageGenerationResult> {
  try {
    if (!process.env.GEMINI_API_KEY) {
      throw new Error('GEMINI_API_KEY no est√° configurada');
    }

    if (!referenceImagesBase64 || referenceImagesBase64.length === 0) {
      // Si no hay referencias, usar generaci√≥n normal
      return await generateCinematicImage(prompt);
    }

    console.log(`Generando imagen con ${referenceImagesBase64.length} referencias faciales...`);

    // Crear el prompt mejorado para m√∫ltiples referencias
    const combinedPrompt = `${prompt}

CRITICAL: Use these ${referenceImagesBase64.length} reference images to maintain facial consistency. The person should have the EXACT same face, features, skin tone, and identity across all generated images. Blend the best features from all reference angles to create a consistent appearance.`;

    // Construir array de parts con todas las im√°genes de referencia
    const parts: any[] = [];
    
    // Agregar todas las im√°genes de referencia primero
    for (let i = 0; i < Math.min(referenceImagesBase64.length, 3); i++) {
      const base64Data = referenceImagesBase64[i].split(',')[1] || referenceImagesBase64[i];
      parts.push({
        inlineData: {
          data: base64Data,
          mimeType: "image/jpeg"
        }
      });
    }
    
    // Agregar el prompt al final
    parts.push({ text: combinedPrompt });

    // Usar Gemini con m√∫ltiples im√°genes de referencia
    const response = await ai.models.generateContent({
      model: "gemini-2.0-flash-preview-image-generation",
      contents: [
        { 
          role: "user", 
          parts: parts
        }
      ],
      config: {
        responseModalities: [Modality.TEXT, Modality.IMAGE],
      },
    });

    const candidates = response.candidates;
    if (!candidates || candidates.length === 0) {
      throw new Error('No se recibieron candidatos de la API');
    }

    const content = candidates[0].content;
    if (!content || !content.parts) {
      throw new Error('Contenido vac√≠o en la respuesta');
    }

    // Buscar la parte de imagen en la respuesta
    for (const part of content.parts) {
      if (part.text) {
        console.log('Texto de respuesta:', part.text);
      } else if (part.inlineData && part.inlineData.data) {
        const imageBase64 = part.inlineData.data;
        console.log('Imagen con rostros adaptados generada exitosamente');
        
        return {
          success: true,
          imageBase64: imageBase64,
          imageUrl: `data:${part.inlineData.mimeType || 'image/png'};base64,${imageBase64}`,
          provider: 'gemini'
        };
      }
    }

    throw new Error('No se encontr√≥ imagen en la respuesta');
  } catch (error: any) {
    console.error('Error generando imagen con m√∫ltiples referencias faciales:', error);
    
    // Detectar error de cuota excedida (429)
    if (error.status === 429 || error.message?.includes('quota') || error.message?.includes('RESOURCE_EXHAUSTED')) {
      return {
        success: false,
        error: 'QUOTA_EXCEEDED',
        quotaError: true
      };
    }
    
    return {
      success: false,
      error: error.message || 'Error desconocido al generar imagen con rostros'
    };
  }
}

/**
 * Genera m√∫ltiples im√°genes en lote con M√öLTIPLES referencias faciales
 * Ideal para crear videos musicales con consistencia facial usando hasta 3 fotos del artista
 * USA SEMILLA CONSISTENTE PARA COHERENCIA VISUAL (color, tono, iluminaci√≥n)
 */
export async function generateBatchImagesWithMultipleFaceReferences(
  scenes: CinematicScene[],
  referenceImagesBase64: string[],
  useFallback: boolean = true
): Promise<Map<number, ImageGenerationResult>> {
  const results = new Map<number, ImageGenerationResult>();
  let quotaExceeded = false;
  
  // üå± GENERAR SEMILLA BASE para coherencia visual entre escenas
  // Usar timestamp + random para unicidad, pero consistente dentro de la sesi√≥n
  const baseSeed = Math.floor(Date.now() / 1000) + Math.floor(Math.random() * 1000);
  
  console.log(`üé® Generando ${scenes.length} escenas con ${referenceImagesBase64.length} referencias faciales`);
  console.log(`üìå Fallback a FAL AI: ${useFallback ? 'ACTIVADO' : 'DESACTIVADO'}`);
  console.log(`üå± Semilla base para coherencia visual: ${baseSeed}`);
  
  for (const scene of scenes) {
    console.log(`üé¨ Generando escena ${scene.id}/${scenes.length}...`);
    
    // Construir prompt cinematogr√°fico detallado
    const cinematicPrompt = `
Professional cinematic photography for a music video:

Scene: ${scene.scene}
Camera Setup: ${scene.camera}
Lighting: ${scene.lighting}
Visual Style: ${scene.style}
Camera Movement: ${scene.movement}

Create a high-quality, professional music video frame with cinematic composition, perfect lighting, and stunning visual aesthetics.
    `.trim();
    
    // Intentar primero con Gemini
    let result = await generateImageWithMultipleFaceReferences(cinematicPrompt, referenceImagesBase64);
    
    // CR√çTICO: Extraer n√∫mero del scene.id para calcular semilla y key
    // scene.id puede ser "scene-1", "scene-2", etc.
    const sceneIdStr = String(scene.id);
    const sceneNumber = sceneIdStr.includes('scene-') 
      ? parseInt(sceneIdStr.replace('scene-', '')) 
      : parseInt(sceneIdStr);
    
    // Calcular semilla √∫nica para esta escena (mantiene coherencia visual)
    const sceneSeed = baseSeed + sceneNumber;
    
    // Si falla y el fallback est√° activado, intentar con FAL AI
    if (!result.success && useFallback && !quotaExceeded) {
      console.log(`‚ö†Ô∏è Gemini fall√≥ para escena ${scene.id}, intentando con FAL AI...`);
      result = await generateImageWithFAL(cinematicPrompt, referenceImagesBase64, sceneSeed);
      
      if (result.success) {
        console.log(`‚úÖ Escena ${scene.id} generada exitosamente con FAL AI (fallback)`);
      }
    }
    
    results.set(sceneNumber, result);
    
    // Si se detecta error de cuota, detener la generaci√≥n
    if ((result as any).quotaError) {
      console.log(`‚ö†Ô∏è Cuota de API excedida despu√©s de generar ${results.size} im√°genes. Deteniendo generaci√≥n.`);
      quotaExceeded = true;
      break;
    }
    
    // Delay para evitar rate limiting (1.5 segundos entre requests)
    if (scenes.indexOf(scene) < scenes.length - 1) {
      await new Promise(resolve => setTimeout(resolve, 1500));
    }
  }
  
  if (quotaExceeded) {
    console.log(`‚ö†Ô∏è Generaci√≥n detenida por l√≠mite de cuota: ${results.size}/${scenes.length} im√°genes creadas`);
  } else {
    console.log(`‚úÖ Generaci√≥n completada: ${results.size} im√°genes creadas`);
  }
  
  return results;
}

/**
 * Genera una imagen usando FAL AI FLUX Pro v1.1 con referencias faciales
 * USAR IM√ÅGENES DE REFERENCIA SUBIDAS POR EL USUARIO
 * USA SEMILLA (SEED) PARA COHERENCIA VISUAL
 */
async function generateImageWithFAL(
  prompt: string,
  referenceImagesBase64: string[],
  seed?: number
): Promise<ImageGenerationResult> {
  try {
    // Importar axios din√°micamente
    const axios = (await import('axios')).default;
    
    // Obtener la API key de FAL
    const FAL_API_KEY = process.env.FAL_API_KEY;
    
    if (!FAL_API_KEY) {
      return {
        success: false,
        error: 'FAL_API_KEY no configurada'
      };
    }
    
    // Mejorar el prompt para mantener consistencia facial
    const enhancedPrompt = `${prompt}. Professional photography, same person, consistent facial features, high quality, detailed, 8k resolution.`;
    
    console.log(`üé® Generando con FAL AI FLUX Pro v1.1 (${referenceImagesBase64.length} referencias, seed: ${seed || 'auto'})...`);
    
    // Preparar request body base
    const requestBody: any = {
      prompt: enhancedPrompt,
      image_size: 'landscape_16_9',
      num_inference_steps: 28,
      guidance_scale: 3.5,
      num_images: 1,
      enable_safety_checker: false,
      output_format: 'jpeg'
    };
    
    // üå± CR√çTICO: Agregar semilla para coherencia visual
    if (seed !== undefined) {
      requestBody.seed = seed;
      console.log(`üå± Usando semilla ${seed} para coherencia visual (color, tono, estilo)`);
    }
    
    // CR√çTICO: Usar imagen de referencia si est√° disponible
    if (referenceImagesBase64 && referenceImagesBase64.length > 0) {
      // Usar la primera imagen de referencia como base
      const referenceImage = referenceImagesBase64[0];
      
      // Convertir base64 a data URI si no lo es ya
      const imageDataUri = referenceImage.startsWith('data:') 
        ? referenceImage 
        : `data:image/jpeg;base64,${referenceImage}`;
      
      requestBody.image_url = imageDataUri;
      requestBody.image_prompt_strength = 0.4; // Influencia media-alta para mantener rasgos faciales
      
      console.log(`‚úÖ Usando referencia facial (strength: 0.4)`);
    }
    
    // Usar FLUX Pro v1.1 que soporta image_url
    const response = await axios.post(
      'https://fal.run/fal-ai/flux-pro/v1.1',
      requestBody,
      {
        headers: {
          'Authorization': `Key ${FAL_API_KEY}`,
          'Content-Type': 'application/json'
        },
        timeout: 90000 // Aumentar timeout por referencias
      }
    );
    
    // Verificar si hay im√°genes en la respuesta
    if (response.data && response.data.images && response.data.images.length > 0) {
      const imageUrl = response.data.images[0].url;
      
      console.log(`‚úÖ Imagen generada con FAL AI (con referencia facial)`);
      
      return {
        success: true,
        imageUrl: imageUrl,
        provider: 'fal',
        error: undefined
      };
    }
    
    return {
      success: false,
      error: 'No se generaron im√°genes con FAL AI'
    };
    
  } catch (error: any) {
    console.error('Error generando imagen con FAL AI:', error.response?.data || error.message);
    return {
      success: false,
      error: error.response?.data?.detail || error.message || 'Error al generar imagen con FAL AI'
    };
  }
}
