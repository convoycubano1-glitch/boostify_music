# API Cost Integration Guide

## ðŸ“Š Sistema Completo de Monitoreo de Costos

He creado un sistema completo para extraer, calcular y monitorear costos de todas las APIs. AquÃ­ estÃ¡ cÃ³mo funciona:

## 1ï¸âƒ£ **Archivos Creados**

### `server/utils/api-pricing.ts`
- **Precios actualizados** para OpenAI, Gemini, Anthropic, FAL y mÃ¡s
- Soporta dos formatos de precios:
  - Por 1K tokens (OpenAI, Anthropic)
  - Por 1M tokens (Gemini)
- FunciÃ³n `calculateApiCost()` que calcula automÃ¡ticamente el costo basado en:
  - Tokens de entrada (prompt)
  - Tokens de salida (completion)
  - Modelo y proveedor

### `server/utils/api-logger.ts`
- FunciÃ³n `logApiUsage()` - Registra cada llamada API en la base de datos
- Extrae automÃ¡ticamente tokens segÃºn el proveedor
- Calcula costos automÃ¡ticamente
- Funciones helper para cada API:
  - `extractOpenAITokens()`
  - `extractGeminiTokens()`
  - `extractAnthropicTokens()`

## 2ï¸âƒ£ **CÃ³mo Integrar en Tus Rutas**

### Ejemplo 1: OpenAI (Chat Completion)

```typescript
import { logApiUsage, extractOpenAITokens } from '../utils/api-logger';

app.post('/api/openai/chat', async (req: Request, res: Response) => {
  const userId = req.user?.id;
  
  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-4o',
      messages: req.body.messages,
      temperature: 0.7,
    });
    
    // Registrar uso de API
    const { promptTokens, completionTokens } = extractOpenAITokens(response);
    
    await logApiUsage({
      userId,
      apiProvider: 'openai',
      endpoint: '/chat/completions',
      model: 'gpt-4o',
      promptTokens,
      completionTokens,
      responseTime: Date.now() - startTime,
      status: 'success'
    });
    
    return res.json({ success: true, data: response });
  } catch (error) {
    // Registrar error tambiÃ©n
    await logApiUsage({
      userId,
      apiProvider: 'openai',
      endpoint: '/chat/completions',
      model: 'gpt-4o',
      promptTokens: 0,
      completionTokens: 0,
      status: 'error',
      errorMessage: error.message
    });
    
    return res.status(500).json({ error: 'OpenAI request failed' });
  }
});
```

### Ejemplo 2: Gemini (Vision)

```typescript
import { logApiUsage, extractGeminiTokens } from '../utils/api-logger';

app.post('/api/gemini/vision', async (req: Request, res: Response) => {
  const userId = req.user?.id;
  const startTime = Date.now();
  
  try {
    const response = await genAI.getGenerativeModel({ model: 'gemini-2.0-flash' })
      .generateContent(req.body.content);
    
    // Registrar uso
    const { promptTokens, completionTokens } = extractGeminiTokens(response);
    
    await logApiUsage({
      userId,
      apiProvider: 'gemini',
      endpoint: '/generateContent',
      model: 'gemini-2.0-flash',
      promptTokens,
      completionTokens,
      responseTime: Date.now() - startTime,
      status: 'success',
      metadata: { contentType: 'vision' }
    });
    
    return res.json({ success: true, data: response });
  } catch (error) {
    await logApiUsage({
      userId,
      apiProvider: 'gemini',
      endpoint: '/generateContent',
      model: 'gemini-2.0-flash',
      status: 'error',
      errorMessage: error.message
    });
  }
});
```

### Ejemplo 3: FAL (ImÃ¡genes)

```typescript
import { logApiUsage } from '../utils/api-logger';
import { calculateApiCost } from '../utils/api-pricing';

app.post('/api/fal/image-generation', async (req: Request, res: Response) => {
  const userId = req.user?.id;
  
  try {
    const result = await fal.subscribe('fal-ai/flux-pro', {
      input: req.body.input,
    });
    
    // Para FAL, contamos "tokens" como nÃºmero de imÃ¡genes
    const imageCount = result.images?.length || 1;
    const cost = calculateApiCost('fal', 'fal-ai/flux-pro', 0, imageCount * 1000);
    
    await logApiUsage({
      userId,
      apiProvider: 'fal',
      endpoint: '/subscribe',
      model: 'fal-ai/flux-pro',
      totalTokens: imageCount * 1000, // 1000 "tokens" por imagen
      status: 'success',
      metadata: { imageCount, imageUrls: result.images }
    });
    
    return res.json({ success: true, data: result });
  } catch (error) {
    await logApiUsage({
      userId,
      apiProvider: 'fal',
      endpoint: '/subscribe',
      model: 'fal-ai/flux-pro',
      status: 'error',
      errorMessage: error.message
    });
  }
});
```

## 3ï¸âƒ£ **CÃ³mo Funciona el CÃ¡lculo de Costos**

### Paso 1: Determina el proveedor y modelo
```typescript
const provider = 'openai';
const model = 'gpt-4o';
const promptTokens = 150;
const completionTokens = 250;
```

### Paso 2: El sistema busca el precio
```typescript
// Para gpt-4o:
// inputCost: $0.005 per 1K tokens
// outputCost: $0.015 per 1K tokens
```

### Paso 3: Calcula automÃ¡ticamente
```typescript
// Costo = (150 / 1000) * 0.005 + (250 / 1000) * 0.015
//       = 0.00075 + 0.00375
//       = $0.0045
```

## 4ï¸âƒ£ **Precios Soportados**

### OpenAI
- gpt-4: $0.03/$0.06 per 1K tokens
- gpt-4-turbo: $0.01/$0.03
- gpt-4o: $0.005/$0.015 â­
- gpt-3.5-turbo: $0.0005/$0.0015

### Gemini
- gemini-2.0-flash: $0.075/$0.3 per 1M tokens
- gemini-1.5-pro: $1.25/$5 per 1M tokens
- gemini-1.5-flash: $0.075/$0.3 per 1M tokens

### Anthropic
- claude-3-opus: $0.015/$0.075 per 1K tokens
- claude-3-sonnet: $0.003/$0.015
- claude-3-haiku: $0.00025/$0.00125

### FAL
- flux-pro: ~$0.005 por imagen
- fast-sdxl: ~$0.002 por imagen
- kling-video: ~$0.1 por video

## 5ï¸âƒ£ **Ver Dashboard**

Una vez integrado, ve a **Admin â†’ API Usage** y verÃ¡s:

âœ… **MÃ©tricas en tiempo real:**
- Total de requests y tokens
- Costo total de la plataforma
- Costo por proveedor
- Tendencias diarias
- Top modelos usados
- Ãšltimas llamadas con status

âœ… **Filtros:**
- Ãšltimos 7, 30 o 90 dÃ­as
- Por usuario
- Por proveedor

## 6ï¸âƒ£ **PrÃ³ximos Pasos Recomendados**

1. **Integra logging en tus rutas existentes:**
   - `server/routes/openai.ts`
   - `server/routes/gemini-agents.ts`
   - `server/routes/fal-api.ts`
   - Y otras que uses

2. **Actualiza precios mensualmente:**
   - Edita `server/utils/api-pricing.ts`
   - Los cambios se aplican automÃ¡ticamente

3. **Monitorea en el dashboard:**
   - Track costos por usuario
   - Identifica modelos caros
   - Optimiza API calls

## ðŸ“ **Ejemplo Completo Integrado**

```typescript
// 1. Import las funciones
import { logApiUsage, extractOpenAITokens } from '../utils/api-logger';

// 2. En tu ruta de API
router.post('/chat', async (req, res) => {
  const startTime = Date.now();
  const userId = req.user?.id;
  
  try {
    // 3. Haz la llamada a la API
    const response = await openai.chat.completions.create({
      model: 'gpt-4o',
      messages: req.body.messages,
    });
    
    // 4. Registra el uso automÃ¡ticamente
    await logApiUsage({
      userId,
      apiProvider: 'openai',
      endpoint: '/chat/completions',
      model: 'gpt-4o',
      ...extractOpenAITokens(response),
      responseTime: Date.now() - startTime,
      status: 'success'
    });
    
    res.json({ success: true, data: response });
  } catch (error) {
    // 5. Registra errores tambiÃ©n
    await logApiUsage({
      userId,
      apiProvider: 'openai',
      endpoint: '/chat/completions',
      status: 'error',
      errorMessage: error.message
    });
    
    res.status(500).json({ error: error.message });
  }
});
```

Â¡Listo! Ahora tus APIs estÃ¡n siendo monitoradas y los costos se calculan automÃ¡ticamente. ðŸš€
