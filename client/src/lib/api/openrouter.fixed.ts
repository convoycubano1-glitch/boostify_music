import { env } from "../../env";
import { 
  ShotType, 
  SceneRole, 
  CameraMovement, 
  LensType, 
  VisualStyle, 
  LightingType, 
  MusicSection,
  type MusicVideoScene,
  type MusicVideoScript,
  type MusicVideoConcept,
  validateSceneBalance,
  generateVariedShotSequence
} from "../../types/music-video-scene";
import type { DirectorProfile } from "../../data/directors/director-schema";

interface Message {
  role: "user" | "assistant" | "system";
  content: string;
}

export interface VideoPromptParams {
  shotType: string;
  cameraFormat: string;
  mood: string;
  visualStyle: string;
  visualIntensity: number;
  narrativeIntensity: number;
  colorPalette: string;
  duration: number;
  directorStyle?: string;
  specialty?: string;
  styleReference?: string;
}

const promptCache = new Map<string, string>();

const generateVideoPrompt = ({
  shotType,
  cameraFormat,
  mood,
  visualStyle,
  visualIntensity,
  narrativeIntensity,
  colorPalette,
  duration,
  directorStyle,
  specialty,
  styleReference
}: VideoPromptParams): string => {
  const cacheKey = JSON.stringify({ shotType, cameraFormat, mood, visualStyle });
  if (promptCache.has(cacheKey)) {
    return promptCache.get(cacheKey)!;
  }

  // Simplified and more specific prompt format
  let prompt = `Generate a detailed cinematic prompt for a ${duration} second shot:

Key Requirements:
1. Shot Type: ${shotType}
2. Camera Format: ${cameraFormat}
3. Mood: ${mood}
4. Visual Style: ${visualStyle} at ${visualIntensity}% intensity
5. Color Scheme: ${colorPalette}
6. Narrative Focus: ${narrativeIntensity}%

Technical Requirements:
- Professional cinematic lighting
- High production value
- Clear composition guidelines`;

  if (directorStyle) {
    prompt += `\n\nDirector's Style: ${directorStyle}`;
  }

  if (specialty) {
    prompt += `\n\nSpecialty Focus: ${specialty}`;
  }

  if (styleReference) {
    prompt += `\n\nVisual Reference: ${styleReference}`;
  }

  prompt += "\n\nProvide a detailed and specific description for generating this shot.";

  promptCache.set(cacheKey, prompt);
  return prompt;
};

const wait = (ms: number) => new Promise(resolve => setTimeout(resolve, ms));

const backoff = async (retryCount: number) => {
  const baseDelay = 3000;
  const maxDelay = 60000;
  const delay = Math.min(baseDelay * Math.pow(2, retryCount), maxDelay);
  console.log(`Backing off for ${delay}ms before retry #${retryCount + 1}`);
  await wait(delay);
};

// Function to create a fallback course structure when API calls fail
function createFallbackCourseContent(prompt: string) {
  console.log("Creating fallback course content from prompt:", prompt.substring(0, 100) + "...");
  
  // Extract course title and category from the prompt if possible
  const titleMatch = prompt.match(/Title: "([^"]+)"/i);
  const descriptionMatch = prompt.match(/Description: "([^"]+)"/i);
  const levelMatch = prompt.match(/Level: ([A-Za-z]+)/i);
  const categoryMatch = prompt.match(/Category: ([A-Za-z]+)/i);
  
  const title = titleMatch ? titleMatch[1] : "Music Course";
  const description = descriptionMatch ? descriptionMatch[1] : "Comprehensive music industry course";
  const level = levelMatch ? levelMatch[1] : "Intermediate";
  const category = categoryMatch ? categoryMatch[1] : "Music";
  
  // Create modular structure based on extracted information
  return {
    overview: `A comprehensive ${level.toLowerCase()} level course focusing on ${category.toLowerCase()} in the music industry. ${description}`,
    objectives: [
      `Understand key concepts and principles in ${category}`,
      `Develop practical skills through guided exercises and hands-on projects`,
      `Learn industry best practices and professional techniques for ${category.toLowerCase()}`,
      `Build a professional portfolio demonstrating your ${category.toLowerCase()} skills`
    ],
    curriculum: [
      {
        title: `Introduction to ${title}`,
        description: "A comprehensive introduction to the key concepts covered in this course.",
        estimatedMinutes: 45
      },
      {
        title: `${category} Fundamentals`,
        description: "Master the essential building blocks necessary for success.",
        estimatedMinutes: 60
      },
      {
        title: "Practical Applications",
        description: `Apply your ${category.toLowerCase()} knowledge to real-world scenarios and projects.`,
        estimatedMinutes: 90
      },
      {
        title: `Advanced ${category} Techniques`,
        description: "Take your skills to the next level with advanced concepts and methods.",
        estimatedMinutes: 75
      },
      {
        title: "Professional Development",
        description: `Prepare for success in the ${category.toLowerCase()} industry with career-focused strategies.`,
        estimatedMinutes: 60
      },
      {
        title: "Industry Integration",
        description: "Learn how to position your skills in the current music industry landscape.",
        estimatedMinutes: 90
      },
      {
        title: "Final Project",
        description: "Apply everything you've learned to create a professional portfolio piece.",
        estimatedMinutes: 120
      }
    ],
    topics: [`${category} Fundamentals`, "Best Practices", "Technical Skills", "Industry Standards", "Career Growth", "Portfolio Development"],
    assignments: ["Concept Development", "Technical Exercise", "Research Project", "Creative Application", "Final Portfolio"],
    applications: ["Professional Portfolio Development", `${category} Industry Implementation`, "Creative Collaboration", "Career Advancement"]
  };
}

// Funci√≥n para generar contenido del curso
export async function generateCourseContent(prompt: string) {
  try {
    console.log("Starting course content generation with OpenRouter (Gemini 2.0)...");
    console.log("Prompt:", prompt.substring(0, 150) + "...");

    // Verificar la presencia de la API key y crear una estructura de respaldo si no est√° disponible
    if (!env.VITE_OPENROUTER_API_KEY) {
      console.error("OpenRouter API key is missing - using fallback content structure");
      return createFallbackCourseContent(prompt);
    }

    // Obtener la clave API para el curso
    const apiKey = env.VITE_OPENROUTER_API_KEY;
    if (!apiKey) {
      console.error("OpenRouter API key is empty or undefined - using fallback content structure");
      return createFallbackCourseContent(prompt);
    }
    
    // Preparar los headers correctos para OpenRouter
    const headers = {
      "Authorization": `Bearer ${apiKey.trim()}`,
      "HTTP-Referer": window.location.origin || "https://boostify.music.app",
      "X-Title": "Boostify Music Education",
      "Content-Type": "application/json"
    };
    
    // Log para debugging (sin exponer la clave completa)
    console.log("OpenRouter course generation headers:", {
      Authorization: `Bearer ${apiKey.substring(0, 3)}...${apiKey.substring(apiKey.length - 3)}`,
      "HTTP-Referer": headers["HTTP-Referer"],
      "X-Title": headers["X-Title"]
    });
    
    // Usar el modelo Gemini 2.0 Flash seg√∫n lo solicitado por el usuario
    console.log("Using Gemini 2.0 Flash model for course content generation");
    
    const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
      method: "POST",
      headers,
      body: JSON.stringify({
        model: "google/gemini-2.0-flash-001", // Modelo solicitado por el usuario
        messages: [
          {
            role: "system",
            content: `You are a JSON generator for music education courses. You MUST return a valid JSON object with this EXACT structure:
{
  "overview": "course overview text",
  "objectives": ["objective1", "objective2", "objective3"],
  "curriculum": [
    {
      "title": "lesson title",
      "description": "lesson description",
      "estimatedMinutes": 60
    }
  ],
  "topics": ["topic1", "topic2", "topic3"],
  "assignments": ["assignment1", "assignment2"],
  "applications": ["application1", "application2"]
}`
          },
          {
            role: "user",
            content: prompt
          }
        ],
        temperature: 0.1,
        max_tokens: 2000,
        response_format: { type: "json_object" }
      })
    });

    console.log("OpenRouter API response status:", response.status);

    // Manejo mejorado de respuestas de la API
    const contentType = response.headers.get('content-type') || '';
    let data;
    let responseText;

    if (!response.ok) {
      try {
        const errorData = await response.json().catch(async () => {
          // Si no podemos obtener JSON, intentamos obtener el texto
          const errorText = await response.text().catch(() => "Unknown error");
          return { error: { message: errorText } };
        });
        console.error("OpenRouter API error:", errorData);
        throw new Error(`Error generating course content: ${response.statusText}. Status: ${response.status}`);
      } catch (parseError) {
        console.error("Error parsing error response:", parseError);
        throw new Error(`API error (${response.status}): Could not parse error response`);
      }
    }

    // Manejo de posibles respuestas no-JSON
    if (!contentType.includes('application/json')) {
      try {
        responseText = await response.text();
        console.log("Non-JSON response received:", responseText.substring(0, 100) + "...");
        
        // Comprobar si es realmente JSON a pesar del tipo de contenido incorrecto
        if (responseText.trim().startsWith('{') || responseText.trim().startsWith('[')) {
          try {
            data = JSON.parse(responseText);
            console.log("Successfully parsed response as JSON despite incorrect content-type");
          } catch (parseError) {
            console.error("Failed to parse as JSON even though it looked like JSON:", parseError);
            throw new Error("API returned invalid JSON response");
          }
        } else {
          throw new Error("API returned non-JSON response: " + responseText.substring(0, 100) + "...");
        }
      } catch (textError) {
        console.error("Error reading response:", textError);
        throw new Error(`Unable to read API response: ${(textError as Error).message}`);
      }
    } else {
      // Manejo est√°ndar de JSON
      try {
        data = await response.json();
      } catch (jsonError) {
        console.error("Error parsing API JSON response:", jsonError);
        throw new Error(`Unable to parse API response as JSON: ${(jsonError as Error).message}`);
      }
    }

    console.log("OpenRouter raw response:", data);

    // Validaci√≥n de estructura de respuesta con manejo de errores mejorado
    if (!data || !data.choices || !Array.isArray(data.choices) || data.choices.length === 0) {
      console.error("Invalid API response structure (missing/empty choices array):", data);
      
      // Crear una estructura de respuesta de respaldo en lugar de fallar
      console.log("Generating fallback course content structure");
      return createFallbackCourseContent(prompt);
    }

    // Extracci√≥n del contenido con manejo de diferentes estructuras posibles
    let content;
    const firstChoice = data.choices[0];
    
    try {
      if (firstChoice.message?.content) {
        content = firstChoice.message.content;
      } else if (firstChoice.text) {
        content = firstChoice.text;
      } else if (firstChoice.content) {
        content = firstChoice.content;
      } else if (typeof firstChoice === 'string') {
        content = firstChoice;
      } else {
        console.error("Cannot extract content from API response:", firstChoice);
        throw new Error("Cannot extract content from API response");
      }

      console.log("Raw content received (first 200 chars):", content.substring(0, 200) + "...");

      // Procesar el contenido - intentar parsear JSON
      let parsed;
      try {
        parsed = typeof content === 'string' ? JSON.parse(content) : content;
      } catch (parseError) {
        console.error("Error parsing JSON content:", parseError);
        console.log("Content that failed parsing (sample):", content.substring(0, 200));
        
        // Intentar extraer JSON del texto si hay { } en el contenido
        const jsonMatch = content.match(/\{[\s\S]*\}/);
        if (jsonMatch) {
          try {
            console.log("Attempting to extract JSON from text content");
            parsed = JSON.parse(jsonMatch[0]);
            console.log("Successfully extracted JSON");
          } catch (extractError) {
            console.error("Failed to extract JSON from content:", extractError);
            throw new Error("Could not parse JSON response: " + (parseError as Error).message);
          }
        } else {
          throw new Error("Could not parse JSON response and no JSON found in content");
        }
      }

      // Validar y corregir la estructura para garantizar una estructura v√°lida
      // aunque falten campos o tengan el formato incorrecto
      const validatedContent = {
        overview: typeof parsed.overview === 'string' 
          ? parsed.overview 
          : "A comprehensive course designed to help you succeed in the music industry.",
          
        objectives: Array.isArray(parsed.objectives) && parsed.objectives.length > 0
          ? parsed.objectives
          : ["Learn key concepts", "Develop practical skills", "Master industry techniques"],
          
        curriculum: Array.isArray(parsed.curriculum) && parsed.curriculum.length > 0
          ? parsed.curriculum.map((lesson: any) => ({
              title: lesson.title || "Untitled Lesson",
              description: lesson.description || "No description provided",
              estimatedMinutes: typeof lesson.estimatedMinutes === 'number' ? 
                                lesson.estimatedMinutes : 
                                (parseInt(String(lesson.estimatedMinutes)) || 60)
            }))
          : [
              { title: "Introduction", description: "Course introduction", estimatedMinutes: 45 },
              { title: "Fundamentals", description: "Core concepts", estimatedMinutes: 60 },
              { title: "Practical Applications", description: "Hands-on learning", estimatedMinutes: 90 }
            ],
            
        topics: Array.isArray(parsed.topics) && parsed.topics.length > 0
          ? parsed.topics
          : ["Fundamentals", "Best Practices", "Professional Techniques", "Industry Standards"],
          
        assignments: Array.isArray(parsed.assignments) && parsed.assignments.length > 0
          ? parsed.assignments
          : ["Practice Exercise", "Case Study Analysis", "Final Project"],
          
        applications: Array.isArray(parsed.applications) && parsed.applications.length > 0
          ? parsed.applications
          : ["Professional Portfolio Development", "Industry Implementation"]
      };
      
      console.log("Validated course content structure with curriculum length:", validatedContent.curriculum.length);
      return validatedContent;
    } catch (parseError) {
      console.error("JSON parsing/validation error:", parseError);
      console.error("Content that failed validation:", content);
      throw new Error(`Validation error: ${(parseError as Error).message}`);
    }
  } catch (error) {
    console.error("Course generation error:", error);
    console.log("Using fallback course content generation due to error");
    return createFallbackCourseContent(prompt);
  }
}

export async function chatWithAI(messages: Message[]) {
  try {
    // Obtener la clave API para chat
    const apiKey = env.VITE_OPENROUTER_API_KEY;
    if (!apiKey) {
      throw new Error('OpenRouter API key is missing or undefined');
    }
    
    // Preparar los headers correctos para OpenRouter
    const headers = {
      "Authorization": `Bearer ${apiKey.trim()}`,
      "HTTP-Referer": window.location.origin || "https://boostify.music.app",
      "X-Title": "Music Video Creator",
      "Content-Type": "application/json"
    };
    
    // Log para debugging (sin exponer la clave completa)
    console.log("OpenRouter chat headers:", {
      Authorization: `Bearer ${apiKey.substring(0, 3)}...${apiKey.substring(apiKey.length - 3)}`,
      "HTTP-Referer": headers["HTTP-Referer"],
      "X-Title": headers["X-Title"]
    });
    
    // Usar el modelo Gemini 2.0 Flash seg√∫n lo solicitado por el usuario
    console.log("Using Gemini 2.0 Flash model for chat completion");
    
    const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
      method: "POST",
      headers,
      body: JSON.stringify({
        model: "google/gemini-2.0-flash-001", // Modelo solicitado por el usuario
        messages,
        temperature: 0.7,
        max_tokens: 2000
      })
    });

    // Manejo mejorado de respuestas y errores
    const contentType = response.headers.get('content-type') || '';
    let data;
    let responseText;

    if (!response.ok) {
      try {
        const errorData = await response.json().catch(async () => {
          // Si no podemos obtener JSON, intentamos obtener el texto
          const errorText = await response.text().catch(() => "Unknown error");
          return { error: { message: errorText } };
        });
        console.error("OpenRouter API error:", errorData);
        throw new Error(`Error in AI chat: ${response.statusText}. Status: ${response.status}`);
      } catch (parseError) {
        console.error("Error parsing error response:", parseError);
        throw new Error(`API error (${response.status}): Could not parse error response`);
      }
    }

    // Manejo de posibles respuestas no-JSON
    if (!contentType.includes('application/json')) {
      try {
        responseText = await response.text();
        console.log("Non-JSON response received from chat API:", responseText.substring(0, 100) + "...");
        
        // Comprobar si es realmente JSON a pesar del tipo de contenido incorrecto
        if (responseText.trim().startsWith('{') || responseText.trim().startsWith('[')) {
          try {
            data = JSON.parse(responseText);
            console.log("Successfully parsed chat response as JSON despite incorrect content-type");
          } catch (parseError) {
            console.error("Failed to parse chat response as JSON:", parseError);
            // Si no se puede analizar como JSON pero la respuesta se ve bien, usamos el texto como respuesta
            return responseText;
          }
        } else {
          // Si no es JSON pero la respuesta tiene contenido, la usamos directamente
          return responseText;
        }
      } catch (textError) {
        console.error("Error reading chat response:", textError);
        throw new Error(`Unable to read API response: ${(textError as Error).message}`);
      }
    } else {
      // Manejo est√°ndar de JSON
      try {
        data = await response.json();
      } catch (jsonError) {
        console.error("Error parsing chat JSON response:", jsonError);
        throw new Error(`Unable to parse API response as JSON: ${(jsonError as Error).message}`);
      }
    }

    // Extraer el contenido con manejo de diferentes estructuras posibles
    if (!data || !data.choices || data.choices.length === 0) {
      console.error("Invalid chat API response structure:", data);
      
      // Si tenemos texto de respuesta, us√©moslo como √∫ltimo recurso
      if (responseText) {
        return responseText;
      }
      
      throw new Error("Invalid API response format: missing choices array");
    }

    const firstChoice = data.choices[0];
    
    if (firstChoice.message?.content) {
      return firstChoice.message.content;
    } else if (firstChoice.text) {
      return firstChoice.text;
    } else if (firstChoice.content) {
      return firstChoice.content;
    } else if (typeof firstChoice === 'string') {
      return firstChoice;
    }
    
    console.error("Unexpected chat response format:", firstChoice);
    throw new Error("Cannot extract content from API response");
  } catch (error) {
    console.error('Error in AI chat:', error);
    return `Lo siento, no puedo procesar tu solicitud en este momento debido a un error: ${error instanceof Error ? error.message : 'Error desconocido'}. Por favor, intenta nuevamente m√°s tarde.`;
  }
}

/**
 * Genera un guion para un video musical utilizando IA avanzada
 * @param prompt - Texto que describe la canci√≥n y los requisitos del video
 * @returns Una cadena JSON con el guion del video musical
 * @throws Error si hay problemas con la API o el formato de respuesta
 */
export async function generateVideoScript(prompt: string): Promise<string> {
  if (!prompt || typeof prompt !== 'string') {
    throw new Error("El prompt debe ser una cadena de texto v√°lida");
  }

  // Verificar si la API key est√° presente antes de realizar cualquier solicitud
  const apiKey = env.VITE_OPENROUTER_API_KEY;
  if (!apiKey) {
    console.error("OpenRouter API key is missing or undefined. Using fallback script generation.");
    return generateFallbackVideoScript(prompt);
  }

  console.log("OpenRouter API key availability check:", !!apiKey);

  const maxRetries = 3;
  let retryCount = 0;

  while (retryCount < maxRetries) {
    try {
      console.log(`Intento ${retryCount + 1}/${maxRetries} para generar guion de video`);

      // Preparar headers con formato exacto para OpenRouter
      const headers = {
        "Authorization": `Bearer ${apiKey.trim()}`,
        "HTTP-Referer": window.location.origin || "https://boostify.music.app",
        "X-Title": "Music Video Creator",
        "Content-Type": "application/json"
      };

      // Log para debugging (sin exponer la clave completa)
      console.log("OpenRouter script headers:", {
        Authorization: `Bearer ${apiKey.substring(0, 3)}...${apiKey.substring(apiKey.length - 3)}`,
        "HTTP-Referer": headers["HTTP-Referer"],
        "X-Title": headers["X-Title"]
      });

      // Verificar que la clave de autorizaci√≥n no est√© vac√≠a
      if (!headers.Authorization || headers.Authorization === "Bearer " || headers.Authorization === "Bearer undefined") {
        throw new Error("Authorization header is invalid: API key is missing");
      }

      // Usar el modelo Gemini 2.0 Flash seg√∫n lo solicitado por el usuario
      console.log("Using Gemini 2.0 Flash model for video script generation");
      
      const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
        method: "POST", 
        headers,
        body: JSON.stringify({
          model: "google/gemini-2.0-flash-001", // Modelo solicitado por el usuario
          messages: [
            {
              role: "system",
              content: `Eres un director creativo de videos musicales experto en an√°lisis musical y narrativa visual.
Tu tarea es crear un guion detallado para un video musical siguiendo estas reglas:

1. AN√ÅLISIS DE LETRA:
- Divide la letra en segmentos narrativos coherentes
- Identifica el tema principal y subtemas
- Analiza el significado y contexto de cada parte
- Extrae las emociones y el tono de cada segmento

2. AN√ÅLISIS MUSICAL:
- Identifica los instrumentos y elementos musicales
- Describe c√≥mo la m√∫sica refuerza el mensaje
- Se√±ala cambios en ritmo, intensidad y momentos clave

3. CREACI√ìN DE GUION:
- Cada segmento debe tener una conexi√≥n directa con una parte espec√≠fica de la letra
- Las escenas deben visualizar el significado literal y metaf√≥rico de la letra
- Los prompts de imagen deben ser detallados y reflejar el contenido exacto
- Las transiciones deben seguir el flujo musical y narrativo

REQUISITOS:
- M√°ximo 10 segmentos para mantener coherencia
- Cada segmento debe corresponder a una parte espec√≠fica de la letra
- Los prompts deben ser detallados y espec√≠ficos para generar im√°genes
- La descripci√≥n debe explicar la conexi√≥n entre la escena y la letra

FORMATO DE RESPUESTA (JSON):
{
  "segments": [
    {
      "id": n√∫mero,
      "lyrics": "parte espec√≠fica de la letra para este segmento",
      "musical_elements": "descripci√≥n detallada de instrumentos y elementos musicales en este momento",
      "description": "descripci√≥n detallada de la escena y c√≥mo se conecta con la letra",
      "imagePrompt": "prompt detallado para generar una imagen que capture el significado de la letra",
      "shotType": "tipo espec√≠fico de plano que mejor capture la escena",
      "mood": "estado de √°nimo basado en la letra y m√∫sica",
      "transition": "tipo de transici√≥n que conecte con el siguiente segmento"
    }
  ]
}`
            },
            { role: "user", content: prompt }
          ],
          temperature: 0.7,
          max_tokens: 2000,
          response_format: { type: "json_object" }
        })
      });

      // Manejar la respuesta
      let errorData;
      
      if (!response.ok) {
        try {
          errorData = await response.json();
        } catch (e) {
          errorData = { error: { message: "Failed to parse error response" } };
        }
        console.error("Script generation API Error:", errorData);

        if (response.status === 401 || response.status === 403) {
          console.error("Authentication error with OpenRouter API. Check your API key.");
          return generateFallbackVideoScript(prompt);
        }

        if (response.status === 429) {
          console.log("Rate limit hit, implementing backoff...");
          await backoff(retryCount);
          retryCount++;
          continue;
        }

        throw new Error(`Error generating script: ${response.statusText}`);
      }

      let data;
      try {
        data = await response.json();
      } catch (error) {
        console.error("Error parsing API response:", error as Error);
        throw new Error(`Unable to parse API response: ${(error as Error).message}`);
      }
      
      console.log("Script generation response:", data);

      if (!data.choices?.[0]?.message?.content) {
        throw new Error("Invalid API response format");
      }

      const content = data.choices[0].message.content;

      try {
        const parsed = JSON.parse(content);
        if (!parsed.segments || !Array.isArray(parsed.segments)) {
          throw new Error("Invalid script format - missing segments array");
        }

        parsed.segments.forEach((segment: any, index: number) => {
          if (!segment.id || !segment.lyrics || !segment.musical_elements || 
              !segment.description || !segment.imagePrompt || !segment.shotType || 
              !segment.mood || !segment.transition) {
            throw new Error(`Invalid segment format at index ${index}`);
          }
        });

        return content;

      } catch (parseError) {
        console.error("JSON parsing/validation error:", parseError);
        throw new Error("Invalid script format");
      }

    } catch (error) {
      console.error(`Error in attempt ${retryCount + 1}:`, error);

      if (retryCount === maxRetries - 1) {
        if (error instanceof Error && error.message.includes("API key")) {
          return generateFallbackVideoScript(prompt);
        }
        throw error;
      }

      await backoff(retryCount);
      retryCount++;
    }
  }

  // Si todos los intentos fallan, usar la generaci√≥n de respaldo
  console.warn("Failed all attempts to generate script - using fallback");
  return generateFallbackVideoScript(prompt);
}

/**
 * Genera un guion de video de fallback cuando la API no est√° disponible
 * @param prompt El prompt original con informaci√≥n de la canci√≥n
 * @returns Un JSON string con una estructura b√°sica de guion
 */
function generateFallbackVideoScript(prompt: string): string {
  console.log("Generating fallback video script for:", prompt.substring(0, 100) + "...");
  
  // Extraer posibles l√≠neas de letras del prompt
  const lines = prompt.split('\n');
  const lyricsLines = lines.filter(line => 
    line.length > 10 && 
    !line.includes("http") && 
    !line.includes("Requisitos:") &&
    !line.startsWith("G√©nero:") &&
    !line.startsWith("Estilo:") &&
    !line.startsWith("Mood:") &&
    !line.startsWith("Tema:")
  );
  
  // Crear segmentos dividiendo las letras disponibles
  const totalSegments = Math.min(6, Math.ceil(lyricsLines.length / 2));
  const segments = [];
  
  for (let i = 0; i < totalSegments; i++) {
    const startIndex = Math.floor(i * lyricsLines.length / totalSegments);
    const endIndex = Math.floor((i + 1) * lyricsLines.length / totalSegments);
    const segmentLyrics = lyricsLines.slice(startIndex, endIndex).join(" ");
    
    segments.push({
      id: i + 1,
      lyrics: segmentLyrics || `Segmento ${i + 1} de la canci√≥n`,
      musical_elements: "Elementos instrumentales y ritmo base de la canci√≥n",
      description: `Escena visual representando el segmento ${i + 1} de la canci√≥n, capturando la esencia emocional de este momento.`,
      imagePrompt: `Escena cinematogr√°fica para un video musical con iluminaci√≥n dram√°tica, enfoque en los detalles emocionales del momento representado por las letras: "${segmentLyrics || 'esta parte de la canci√≥n'}"`,
      shotType: ["close-up", "medium shot", "wide shot", "tracking shot", "overhead shot"][i % 5],
      mood: ["emotivo", "en√©rgico", "melanc√≥lico", "introspectivo", "celebratorio"][i % 5],
      transition: ["cut", "fade", "dissolve", "swipe", "zoom"][i % 5]
    });
  }
  
  return JSON.stringify({ segments }, null, 2);
}

// Additional utility functions
export async function generateVideoPromptWithRetry(params: VideoPromptParams): Promise<string> {
  const maxRetries = 3;
  let retryCount = 0;
  let promptText = "";

  while (retryCount < maxRetries) {
    try {
      console.log(`Attempt ${retryCount + 1}/${maxRetries} to generate prompt`);
      
      // Verify API key
      const apiKey = env.VITE_OPENROUTER_API_KEY;
      if (!apiKey) {
        console.error("OpenRouter API key is missing or undefined. Using direct prompt generation.");
        return generateVideoPrompt(params);
      }
      
      // Basic validation
      if (!params.shotType || !params.mood || !params.visualStyle) {
        throw new Error("Missing required parameters for prompt generation");
      }
      
      const headers = {
        "Authorization": `Bearer ${apiKey.trim()}`,
        "HTTP-Referer": window.location.origin || "https://boostify.music.app",
        "X-Title": "Music Video Creator",
        "Content-Type": "application/json"
      };
      
      // Log for debugging (mask API key)
      console.log("Headers for prompt generation:", {
        Authorization: `Bearer ${apiKey.substring(0, 3)}...${apiKey.substring(apiKey.length - 3)}`,
        "HTTP-Referer": headers["HTTP-Referer"],
        "X-Title": headers["X-Title"]
      });
      
      // Generate base prompt text to send to AI
      promptText = generateVideoPrompt(params);
      
      const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
        method: "POST",
        headers,
        body: JSON.stringify({
          model: "google/gemini-2.0-flash-001", // Requested model by user
          messages: [
            {
              role: "system",
              content: "You are a professional cinematic prompt engineer. You take basic prompts and transform them into detailed, visually expressive prompts that generate compelling cinematic images. Maintain all the technical specifications from the input prompt but enhance the visual description with clear, evocative details."
            },
            { role: "user", content: promptText }
          ],
          temperature: 0.7,
          max_tokens: 500
        })
      });
      
      let data;
      try {
        // Response is not OK (error)
        if (!response.ok) {
          console.log("Response wasn't OK:", response.status, response.statusText);
          
          if (response.status === 401 || response.status === 403) {
            console.error("Authentication error with OpenRouter API. Check your API key.");
            return promptText;
          }
          
          // Rate limiting - implement backoff
          if (response.status === 429) {
            console.log("Rate limit hit, implementing backoff...");
            await backoff(retryCount);
            retryCount++;
            continue;
          }
          
          throw new Error(`API error: ${response.status} ${response.statusText}`);
        }
        
        data = await response.json();
      } catch (jsonError) {
        try {
          const responseText = await response.text();
          console.log("Response couldn't be parsed as JSON. Raw text:", 
                    responseText.substring(0, 100) + "...");
          
          // If the response is actually text we can use, create a mock JSON structure
          if (response.ok && responseText) {
            data = {
              choices: [{
                message: {
                  content: responseText
                }
              }]
            };
          } else {
            throw new Error(`Unable to parse API response as JSON: ${(jsonError as Error).message}`);
          }
        } catch (textError) {
          console.error("Error reading response as text after JSON parse failed:", textError);
          throw new Error(`Unable to read API response: ${(textError as Error).message}`);
        }
      }
      
      console.log("API Response:", data);

      if (!response.ok) {
        const errorMessage = data?.error?.message || response.statusText;
        console.error("API Error:", errorMessage);

        if (response.status === 401 || response.status === 403) {
          console.error("Authentication error with OpenRouter API. Check your API key.");
          
          // Despu√©s de un error de autenticaci√≥n, usar el prompt generado localmente
          console.log("Using locally generated prompt instead");
          return `${promptText} (Note: This is a fallback prompt - AI enhancement unavailable)`;
        }
        
        if (response.status === 429) {
          console.log("Rate limit hit, implementing backoff...");
          await backoff(retryCount);
          retryCount++;
          continue;
        }

        throw new Error(`API error: ${response.status} ${errorMessage}`);
      }

      // Validate the response structure
      if (!data || !data.choices) {
        console.error("Invalid response structure (missing choices array):", data);
        
        // Return generic message when no valid response structure
        console.log("No valid response structure available");
        return "Sorry, I couldn't generate a proper response at this time.";
      }
      
      if (!data.choices[0]?.message?.content) {
        console.error("Invalid response structure (missing message content):", data);
        
        // Try to extract content from alternative response structures
        const alternativeContent = 
          data.choices[0]?.text || // Some APIs use 'text' instead of 'message.content'
          data.choices[0]?.content || // Some use direct 'content'
          (typeof data.choices[0] === 'string' ? data.choices[0] : null); // Some return the string directly
          
        if (alternativeContent) {
          console.log("Using alternative content structure");
          return alternativeContent;
        }
        
        throw new Error("Invalid API response format: missing message content");
      }

      const generatedPrompt = data.choices[0].message.content.trim();
      if (!generatedPrompt) {
        throw new Error("Empty prompt generated");
      }

      // Guardar en cach√© para futuros usos
      promptCache.set(JSON.stringify(params), generatedPrompt);
      return generatedPrompt;

    } catch (error) {
      console.error(`Error in attempt ${retryCount + 1}:`, error);

      if (retryCount === maxRetries - 1) {
        // En el √∫ltimo intento, intentar usar el cache o el prompt base
        const cacheKey = JSON.stringify(params);
        const cachedPrompt = promptCache.get(cacheKey);
        if (cachedPrompt) {
          console.log("Using cached prompt as fallback");
          return cachedPrompt;
        }

        // Generar un prompt base como √∫ltimo recurso
        const fallbackPrompt = generateVideoPrompt(params);
        console.log("Using fallback prompt generation:", fallbackPrompt.substring(0, 50) + "...");
        return fallbackPrompt;
      }

      await backoff(retryCount);
      retryCount++;
    }
  }

  throw new Error("Failed to generate prompt after all retries");
}

/**
 * Genera 3 propuestas de concepto visual diferentes para que el usuario escoja
 * 
 * @param lyrics La transcripci√≥n de la letra de la canci√≥n
 * @param directorName Nombre del director para adaptar el estilo
 * @param artistReferences Im√°genes de referencia del artista
 * @param audioDuration Duraci√≥n del audio en segundos
 * @returns Promise con array de 3 conceptos visuales
 */
export async function generateThreeConceptProposals(
  lyrics: string,
  directorName: string,
  artistReferences?: string[],
  audioDuration?: number
): Promise<MusicVideoConcept[]> {
  try {
    console.log("üé® Generando 3 propuestas de concepto visual con Gemini...");
    
    // Llamar al endpoint del backend que usa Gemini
    const response = await fetch("/api/music-video/generate-concepts", {
      method: "POST",
      headers: {
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        lyrics,
        directorName,
        characterReference: artistReferences,
        audioDuration
      })
    });
    
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({ error: 'Unknown error' }));
      throw new Error(`Error generating concepts: ${response.status} - ${errorData.error || errorData.details || 'Unknown error'}`);
    }
    
    const data = await response.json();
    
    if (!data.success || !data.concepts) {
      throw new Error("No concept data received from backend");
    }
    
    console.log("‚úÖ 3 conceptos visuales generados exitosamente con Gemini");
    return data.concepts;
    
  } catch (error) {
    console.error("Error generating concept proposals:", error);
    throw error;
  }
}

/**
 * Genera el concepto visual y narrativo del video musical PRIMERO
 * Este concepto se usa como base para generar un script m√°s coherente
 * 
 * @param lyrics La transcripci√≥n de la letra de la canci√≥n
 * @param artistReferences Im√°genes de referencia del artista para extraer estilo
 * @param audioDuration Duraci√≥n del audio en segundos
 * @returns Promise con el concepto visual en formato JSON
 */
export async function generateMusicVideoConcept(
  lyrics: string,
  artistReferences?: string[],
  audioDuration?: number
): Promise<MusicVideoConcept | null> {
  try {
    console.log("üé® Generando concepto visual y narrativo del video...");
    
    const apiKey = env.VITE_OPENROUTER_API_KEY;
    if (!apiKey) {
      console.warn("OpenRouter API key missing - skipping concept generation");
      return null;
    }
    
    const headers = {
      "Authorization": `Bearer ${apiKey.trim()}`,
      "HTTP-Referer": window.location.origin,
      "X-Title": "Boostify Music Video Concept Generator",
      "Content-Type": "application/json"
    };
    
    const prompt = `Based on these lyrics, create a comprehensive visual and narrative concept for a music video:

LYRICS:
${lyrics}

${audioDuration ? `DURATION: ${Math.floor(audioDuration)} seconds` : ''}

${artistReferences && artistReferences.length > 0 ? `NOTE: The artist has ${artistReferences.length} reference images provided. Use these to inform wardrobe and styling consistency.` : ''}

Create a detailed visual concept that includes:
1. A compelling narrative/story concept that ties the entire video together
2. Specific wardrobe details (outfit, colors, accessories, hair/makeup)
3. 2-3 main locations with detailed descriptions
4. A cohesive color palette
5. Recurring visual elements for continuity
6. Key narrative moments throughout the video

Return ONLY valid JSON matching this structure:
{
  "story_concept": "Complete narrative description...",
  "visual_theme": "Main visual theme...",
  "mood_progression": "How the mood evolves...",
  "main_wardrobe": {
    "outfit_description": "Detailed outfit description",
    "colors": ["color1", "color2"],
    "style": "urban/elegant/casual/etc",
    "accessories": ["accessory1", "accessory2"],
    "hair_makeup": "Hair and makeup description"
  },
  "locations": [
    {
      "name": "Location name",
      "description": "Detailed description",
      "mood": "Mood of this location",
      "scenes_usage": "When/how this location is used"
    }
  ],
  "color_palette": {
    "primary_colors": ["color1", "color2"],
    "accent_colors": ["color3"],
    "mood_colors": "Description of color mood"
  },
  "recurring_visual_elements": ["element1", "element2"],
  "key_narrative_moments": [
    {
      "timestamp": "0:30",
      "description": "What happens at this moment"
    }
  ]
}`;

    const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
      method: "POST",
      headers,
      body: JSON.stringify({
        model: "google/gemini-2.0-flash-001",
        messages: [
          {
            role: "system",
            content: "You are an expert music video creative director. Create detailed, cohesive visual concepts that ensure consistency throughout the entire video production."
          },
          {
            role: "user",
            content: prompt
          }
        ],
        temperature: 0.8,
        max_tokens: 4000,
        response_format: { type: "json_object" }
      })
    });
    
    if (!response.ok) {
      console.error("Error generating concept:", response.status);
      return null;
    }
    
    const data = await response.json();
    const conceptContent = data.choices?.[0]?.message?.content;
    
    if (!conceptContent) {
      console.error("No concept content received");
      return null;
    }
    
    const concept: MusicVideoConcept = JSON.parse(conceptContent);
    console.log("‚úÖ Concepto visual generado exitosamente");
    return concept;
    
  } catch (error) {
    console.error("Error generating music video concept:", error);
    return null;
  }
}

/**
 * Genera un guion detallado para un video musical basado en la transcripci√≥n de la letra
 * AHORA USA EL CONCEPTO VISUAL Y PERFIL COMPLETO DEL DIRECTOR como base para mayor coherencia
 * 
 * @param lyrics La transcripci√≥n de la letra de la canci√≥n
 * @param audioAnalysis An√°lisis opcional de la pista de audio (beats, segmentos, etc)
 * @param director Perfil COMPLETO del director con todos sus detalles t√©cnicos y estil√≠sticos (DirectorProfile)
 * @param audioDuration Duraci√≥n del audio en segundos para calcular n√∫mero de escenas
 * @param editingStyle Estilo de edici√≥n seleccionado
 * @param concept Concepto visual generado previamente (opcional pero recomendado)
 * @returns Promise con el guion en formato JSON estructurado
 */
export async function generateMusicVideoScript(
  lyrics: string, 
  audioAnalysis?: any, 
  director?: DirectorProfile,
  audioDuration?: number,
  editingStyle?: { id: string; name: string; description: string; duration: { min: number; max: number } },
  concept?: MusicVideoConcept | null
): Promise<string> {
  try {
    if (!lyrics) {
      throw new Error("No lyrics provided for script generation");
    }
    
    console.log("Generating music video script from lyrics:", lyrics.substring(0, 100) + "...");
    
    // Verificar API key
    const apiKey = env.VITE_OPENROUTER_API_KEY;
    if (!apiKey) {
      console.error("OpenRouter API key missing - using fallback script generation");
      const calculatedScenes = Math.ceil((audioDuration || 40) / 4);
      const maxScenes = 40; // Generate 40 scenes for full video
      return generarGuionFallback(lyrics, Math.min(calculatedScenes, maxScenes), audioDuration);
    }
    
    // Preparar headers para OpenRouter con modelo actualizado a Gemini 2.0 Flash
    const headers = {
      "Authorization": `Bearer ${apiKey.trim()}`,
      "HTTP-Referer": window.location.origin,
      "X-Title": "Boostify Music Video Generator",
      "Content-Type": "application/json"
    };
    
    // Usar estilo de edici√≥n para calcular escenas y duraciones
    const minDuration = editingStyle?.duration.min || 2;
    const maxDuration = editingStyle?.duration.max || 4;
    const avgDuration = (minDuration + maxDuration) / 2;
    
    // Calcular n√∫mero de escenas basado en duraci√≥n promedio del estilo
    const calculatedScenes = audioDuration ? Math.ceil(audioDuration / avgDuration) : 12;
    const maxScenes = 40; // Generate 40 scenes for full video
    const targetSceneCount = Math.min(calculatedScenes, maxScenes);
    
    console.log(`üé¨ Estilo de edici√≥n: ${editingStyle?.name || 'Phrase-based'}`);
    console.log(`‚è±Ô∏è Duraciones: ${minDuration}s - ${maxDuration}s por escena`);
    console.log(`üìä Escenas calculadas: ${targetSceneCount}`);
    
    // Crear el prompt con la letra y an√°lisis de audio si est√° disponible
    let userPrompt = `Generate a detailed music video script for these lyrics:\n\n${lyrics}`;
    
    // ‚ú® NUEVO: Agregar concepto visual si est√° disponible
    if (concept) {
      console.log("üìù Usando concepto visual para mejorar coherencia del script");
      userPrompt += `\n\nüé® VISUAL CONCEPT (USE THIS AS BASE FOR ALL SCENES):

STORY & THEME:
${concept.story_concept}

VISUAL THEME: ${concept.visual_theme}
MOOD PROGRESSION: ${concept.mood_progression}

üé≠ ARTIST WARDROBE (MAINTAIN CONSISTENCY):
Outfit: ${concept.main_wardrobe.outfit_description}
Colors: ${concept.main_wardrobe.colors.join(', ')}
Style: ${concept.main_wardrobe.style}
Accessories: ${concept.main_wardrobe.accessories.join(', ')}
Hair & Makeup: ${concept.main_wardrobe.hair_makeup}

üìç LOCATIONS:
${concept.locations.map((loc, i) => `${i + 1}. ${loc.name}: ${loc.description} (${loc.scenes_usage})`).join('\n')}

üé® COLOR PALETTE:
Primary: ${concept.color_palette.primary_colors.join(', ')}
Accent: ${concept.color_palette.accent_colors.join(', ')}
Mood: ${concept.color_palette.mood_colors}

üîÅ RECURRING ELEMENTS: ${concept.recurring_visual_elements.join(', ')}

IMPORTANT:
- Use the wardrobe details for ALL performance scenes to maintain visual consistency
- Reference the locations described above for b-roll scenes
- Incorporate recurring visual elements throughout the video
- Follow the color palette in lighting and scene composition
- Build upon the story concept in the scene descriptions`;
    }
    
    if (audioDuration) {
      userPrompt += `\n\nAUDIO INFORMATION:
- Total duration: ${Math.floor(audioDuration)} seconds
- Required number of scenes: ${targetSceneCount} scenes

üé¨ EDITING STYLE: ${editingStyle?.name || 'Phrase-based Editing'}
Description: ${editingStyle?.description || 'Cuts synchronized with musical phrases'}

üéµ CRITICAL TIMING REQUIREMENTS:
1. Create EXACTLY ${targetSceneCount} scenes to cover the entire song duration
2. Each scene MUST have a duration between ${minDuration} and ${maxDuration} seconds
3. ${editingStyle?.id === 'rhythmic' ? 'Make PRECISE cuts on each beat' : editingStyle?.id === 'minimalist' ? 'Create LONG, smooth scenes with few cuts' : editingStyle?.id === 'dynamic' ? 'Use FAST cuts in intense moments, SLOWER in soft parts' : 'Align scenes with MUSICAL PHRASES'}
4. Vary durations within the ${minDuration}-${maxDuration}s range for dynamic pacing
5. Make sure the total duration adds up to approximately ${Math.floor(audioDuration)} seconds

üé§ LIP-SYNC SYNCHRONIZATION:
- Each PERFORMANCE scene must show the artist singing the EXACT lyrics from that time segment
- Match scene timing to where those specific words are sung in the audio
- Performance scenes should align with vocal-heavy sections (verses, choruses)
- B-roll scenes can fill instrumental breaks and transitions`;
    }
    
    // Agregar PERFIL COMPLETO del director si est√° disponible
    if (director) {
      console.log(`üìΩÔ∏è Usando perfil completo del director: ${director.name}`);
      userPrompt += `\n\nüé¨ DIRECTOR'S COMPLETE CINEMATIC PROFILE:

**Director:** ${director.name}
**Specialty:** ${director.specialty}
**Bio:** ${director.bio}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üì∏ VISUAL STYLE & AESTHETIC:
${director.visual_style.description}

**Signature Techniques:**
${director.visual_style.signature_techniques.map((tech, i) => `${i + 1}. ${tech}`).join('\n')}

**Color Palette Philosophy:**
‚Ä¢ Primary Colors: ${director.visual_style.color_palette.primary_colors.join(', ')}
‚Ä¢ Accent Colors: ${director.visual_style.color_palette.accent_colors.join(', ')}
‚Ä¢ Mood: ${director.visual_style.color_palette.mood}

**Creative Influences:** ${director.visual_style.influences.join(', ')}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üé• CAMERA PREFERENCES:
**Favorite Lenses:** ${director.camera_preferences.favorite_lenses.join(', ')}
**Favorite Shot Types:** ${director.camera_preferences.favorite_shot_types.join(', ')}
**Favorite Movements:** ${director.camera_preferences.favorite_movements.join(', ')}
**Shot Composition Style:** ${director.camera_preferences.shot_composition}
**Preferred Aspect Ratio:** ${director.camera_preferences.aspect_ratio}
**Camera Notes:** ${director.camera_preferences.camera_notes}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üí° LIGHTING STYLE:
**Preferred Lighting:** ${director.lighting_style.preferred_lighting.join(', ')}
**Color Temperature:** ${director.lighting_style.color_temperature}
**Key Techniques:** ${director.lighting_style.key_techniques.join(', ')}
**Mood Lighting:** ${director.lighting_style.mood_lighting}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

‚úÇÔ∏è EDITING STYLE:
**Pace:** ${director.editing_style.pace}
**Transitions:** ${director.editing_style.transitions.join(', ')}
**Average Shot Length:** ${director.editing_style.average_shot_length}
**Rhythm Approach:** ${director.editing_style.rhythm_approach}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üìñ STORYTELLING APPROACH:
**Narrative Style:** ${director.storytelling.narrative_approach}
**Preferred Themes:** ${director.storytelling.preferred_themes.join(', ')}
**Performance vs B-roll Ratio:** ${director.storytelling.performance_vs_broll_ratio}
**Symbolism Level:** ${director.storytelling.symbolism_level}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üé® POST-PRODUCTION STYLE:
**Color Grading:** ${director.post_production.color_grading_style}
**VFX Approach:** ${director.post_production.vfx_approach}
**Preferred Effects:** ${director.post_production.preferred_effects.join(', ')}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üéØ AI GENERATION PRIORITIES:

**MUST INCLUDE:**
${director.ai_generation_notes.key_priorities.map((p, i) => `${i + 1}. ${p}`).join('\n')}

**MUST AVOID:**
${director.ai_generation_notes.avoid.map((a, i) => `${i + 1}. ${a}`).join('\n')}

**SPECIAL EMPHASIS:**
${director.ai_generation_notes.emphasis.map((e, i) => `${i + 1}. ${e}`).join('\n')}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üö® CRITICAL INSTRUCTION:
Every single scene MUST embody ${director.name}'s unique cinematic signature.
Use the exact techniques, camera preferences, lighting style, and aesthetic described above.
This is NOT a suggestion - it is a REQUIREMENT for EVERY scene you generate.`;
    }
    
    if (audioAnalysis) {
      try {
        userPrompt += "\n\nPlease consider this audio analysis information:\n" + 
                     (typeof audioAnalysis === 'string' ? audioAnalysis : JSON.stringify(audioAnalysis, null, 2));
      } catch (e) {
        console.error("Error processing audio analysis:", e);
      }
    }
    
    const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
      method: "POST",
      headers,
      body: JSON.stringify({
        model: "google/gemini-2.0-flash-001", // Actualizado al modelo solicitado
        messages: [
          {
            role: "system",
            content: `You are a professional music video director. Create a detailed cinematic script for a music video using the MusicVideoScene schema.

CRITICAL REQUIREMENTS:
1. Return EXACTLY the number of scenes specified in the user prompt
2. STRICT 50/50 BALANCE: Half the scenes MUST be "performance" (artist performing) and half MUST be "b-roll" (environmental/story scenes)
3. VARY shot types - NEVER use the same type consecutively
4. Use FULL DESCRIPTIVE NAMES for shot types - NEVER use abbreviations

üö® MANDATORY: Use ONLY these EXACT shot type names (full names only):
"Extreme Close-Up", "Close-Up", "Medium Close-Up", "Medium Shot", "Medium Wide Shot", 
"Long Shot", "Wide Shot", "Extreme Wide Shot", "Over-the-Shoulder", "Point of View", 
"High Angle", "Low Angle", "Dutch Angle"

‚ùå WRONG: "ECU", "CU", "MCU", "MS", "WS", "EWS", "OTS", "POV", "HIGH", "LOW", "DUTCH"
‚úÖ CORRECT: "Close-Up", "Medium Shot", "Wide Shot", "Extreme Close-Up"

RESPONSE FORMAT (JSON):
{
  "scenes": [
    {
      "scene_id": "scene-1",
      "start_time": 0,
      "duration": 3.0,  // Must be between 2-4 seconds, aligned with musical phrases
      "lyrics_segment": "The exact lyrics being sung in this scene (for performance scenes)",
      "role": "performance" | "b-roll",
      "shot_type": "Extreme Close-Up" | "Close-Up" | "Medium Close-Up" | "Medium Shot" | "Medium Wide Shot" | "Long Shot" | "Wide Shot" | "Extreme Wide Shot" | "Over-the-Shoulder" | "Point of View" | "High Angle" | "Low Angle" | "Dutch Angle",  // USE FULL NAMES ONLY!
      "camera_movement": "static" | "pan" | "tilt" | "dolly" | "zoom" | "handheld" | "steadicam" | "crane" | "drone" | "tracking",
      "lens": "14mm" | "24mm" | "35mm" | "50mm" | "85mm" | "135mm",
      "visual_style": "cinematic" | "vibrant" | "muted" | "high-contrast" | "moody" | "warm" | "cool" | "saturated" | "desaturated",
      "lighting": "natural" | "studio" | "dramatic" | "soft" | "hard" | "mixed" | "golden-hour" | "blue-hour" | "neon",
      "color_temperature": "3200K" | "5000K" | "5600K",
      "description": "Detailed visual description for image generation including scene composition, artist action, mood, and specific details",
      "location": "Specific location description",
      "music_section": "intro" | "verse" | "pre-chorus" | "chorus" | "bridge" | "outro" | "breakdown",
      
      // üÜï WARDROBE (for performance scenes - CRITICAL for visual consistency)
      "wardrobe": {
        "outfit_description": "Complete description of what the artist is wearing",
        "colors": ["primary color", "secondary color"],
        "style": "urban/elegant/casual/streetwear/etc",
        "accessories": ["accessory1", "accessory2"],
        "hair_makeup": "Hairstyle and makeup description"
      },
      
      // üÜï VISUAL REFERENCES (for maintaining consistency across scenes)
      "visual_references": {
        "reference_scene_ids": ["scene-1", "scene-2"],  // Previous scenes to reference for consistency
        "key_visual_elements": ["element1", "element2"],  // Visual elements to carry forward
        "color_continuity": "Palette description for this scene"
      }
    }
  ]
}

üé• SHOT TYPE NAMES - USE FULL DESCRIPTIVE NAMES ONLY:

ALWAYS use the FULL NAME, NEVER abbreviations:
- "Extreme Close-Up" ‚Üí Eyes, lips, hands - maximum intimacy and emotion
- "Close-Up" ‚Üí Face and shoulders - intimate connection
- "Medium Close-Up" ‚Üí Head to chest - personal moments
- "Medium Shot" ‚Üí Waist up - standard performance
- "Medium Wide Shot" ‚Üí Knees up - movement with context
- "Long Shot" ‚Üí Full body - complete performance
- "Wide Shot" ‚Üí Artist in environment - establishing
- "Extreme Wide Shot" ‚Üí Vast environment - scale
- "Over-the-Shoulder" ‚Üí Perspective and connection
- "Point of View" ‚Üí First person perspective
- "High Angle" ‚Üí Vulnerability, looking down
- "Low Angle" ‚Üí Power, looking up
- "Dutch Angle" ‚Üí Tension, tilted frame

üö® CRITICAL: In your JSON response, the "shot_type" field MUST contain the FULL NAME:
Example: "shot_type": "Close-Up"  ‚úÖ CORRECT
Example: "shot_type": "Medium Shot"  ‚úÖ CORRECT
Example: "shot_type": "CU"  ‚ùå WRONG - Use full name!
Example: "shot_type": "MS"  ‚ùå WRONG - Use full name!

CRITICAL BALANCE RULES:
- For every scene with role "performance", create a scene with role "b-roll"
- Performance scenes: Artist singing, performing, playing instrument, lip-syncing
- B-roll scenes: Environmental shots, story elements, symbolic visuals, cityscapes, nature, objects, atmospheric scenes
- Example sequence: performance, b-roll, performance, b-roll, performance, b-roll...

SHOT VARIATION RULES:
- NEVER repeat the same shot_type in consecutive scenes
- Rotate through different shot types for visual dynamics
- Match shot intensity to music energy (chorus = dynamic shots, verse = intimate shots)
- Use varied camera movements and angles

üé≠ WARDROBE CONSISTENCY REQUIREMENTS (CRITICAL):
- ALL performance scenes MUST include wardrobe details
- Use the SAME outfit throughout if a visual concept is provided
- Be SPECIFIC: describe fabrics, fit, patterns, textures
- Include accessories in every performance scene for continuity
- Hair and makeup should remain consistent unless there's a narrative reason to change

üîó VISUAL REFERENCE SYSTEM (for image generation consistency):
- In scene 1-2: Establish the core visual elements
- From scene 3+: Reference previous scene IDs to maintain consistency
- Example: scene 5 references ["scene-1", "scene-3"] for wardrobe and location continuity
- Carry forward key visual elements: specific props, colors, lighting setups
- Build visual narrative: later scenes should feel connected to earlier ones

DESCRIPTION GUIDELINES:
- For PERFORMANCE: Describe artist action, expression, movement, wardrobe (detailed!), setting
- For B-ROLL: Describe environment, atmosphere, story elements, symbolic meaning
- Include color palette, lighting mood, and specific visual details
- Reference the lyrics being sung in performance scenes
- Be cinematically specific and evocative
- ALWAYS include wardrobe details in performance scenes`
          },
          {
            role: "user",
            content: userPrompt
          }
        ],
        temperature: 0.7,
        max_tokens: 12000,
        response_format: { type: "json_object" }
      })
    });
    
    if (!response.ok) {
      console.error("Error en respuesta de OpenRouter:", response.status, response.statusText);
      return generarGuionFallback(lyrics, targetSceneCount, audioDuration);
    }
    
    const data = await response.json();
    
    if (!data.choices || !data.choices[0] || !data.choices[0].message || !data.choices[0].message.content) {
      console.error("Respuesta inv√°lida de OpenRouter:", data);
      return generarGuionFallback(lyrics, targetSceneCount, audioDuration);
    }
    
    const scriptContent = data.choices[0].message.content;
    
    try {
      // Validar que sea JSON v√°lido y tenga la estructura esperada
      const parsed = JSON.parse(scriptContent);
      
      // Verificar que tenga la key "scenes" con un array
      if (parsed.scenes && Array.isArray(parsed.scenes)) {
        console.log(`‚úÖ Gui√≥n generado con ${parsed.scenes.length} escenas`);
        
        // Si no gener√≥ suficientes escenas, completar con fallback
        if (parsed.scenes.length < targetSceneCount) {
          console.warn(`‚ö†Ô∏è Solo se generaron ${parsed.scenes.length} de ${targetSceneCount} escenas. Completando...`);
          const fallbackScript = generarGuionFallback(lyrics, targetSceneCount, audioDuration);
          const fallbackParsed = JSON.parse(fallbackScript);
          
          // Agregar las escenas faltantes del fallback
          const missingCount = targetSceneCount - parsed.scenes.length;
          const additionalScenes = fallbackParsed.scenes.slice(0, missingCount).map((scene: any, idx: number) => ({
            ...scene,
            scene_id: parsed.scenes.length + idx + 1
          }));
          
          parsed.scenes = [...parsed.scenes, ...additionalScenes];
        }
        
        return JSON.stringify(parsed);
      } else {
        console.warn("El script no tiene la estructura esperada con 'scenes' array");
        return generarGuionFallback(lyrics, targetSceneCount, audioDuration);
      }
    } catch (error) {
      console.error("El script generado no es JSON v√°lido:", error);
      // Intento de extraer JSON si est√° mezclado con otro texto
      const jsonMatch = scriptContent.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        try {
          const parsed = JSON.parse(jsonMatch[0]);
          if (parsed.scenes && Array.isArray(parsed.scenes)) {
            return jsonMatch[0];
          }
        } catch (e) {
          console.error("No se pudo extraer JSON del contenido:", e);
        }
      }
      return generarGuionFallback(lyrics, targetSceneCount, audioDuration);
    }
  } catch (error) {
    console.error("Error generando guion de video musical:", error);
    // LIMITAR A 10 ESCENAS PARA PRUEBAS
    const calculatedScenes = Math.ceil((audioDuration || 40) / 4);
    const maxScenes = 10; // M√°ximo 10 escenas para pruebas
    return generarGuionFallback(lyrics, Math.min(calculatedScenes, maxScenes), audioDuration);
  }
}


/**
 * Genera un guion profesional como respaldo cuando la API falla
 * Usa el nuevo schema MusicVideoScene con balance 50/50
 * @param lyrics Letras de la canci√≥n
 * @param sceneCount N√∫mero exacto de escenas a generar (default: 10)
 * @param audioDuration Duraci√≥n total del audio en segundos
 */
function generarGuionFallback(
  lyrics: string, 
  sceneCount: number = 10, 
  audioDuration?: number
): string {
  console.log(`üé¨ Generando gui√≥n fallback con ${sceneCount} escenas (nuevo schema MusicVideoScene)`);
  
  // Dividir las letras en l√≠neas
  const lines = lyrics.split('\n').filter(line => line.trim().length > 0);
  const totalLines = lines.length;
  
  // Generar shot types variados usando el helper
  const shotSequence = generateVariedShotSequence(sceneCount, 2);
  
  // Generar duraciones aleatorias VARIADAS (2-6 segundos)
  const adjustedDurations: number[] = [];
  const minDuration = 2.0;
  const maxDuration = 6.0;
  
  for (let i = 0; i < sceneCount; i++) {
    const duration = minDuration + Math.random() * (maxDuration - minDuration);
    adjustedDurations.push(duration);
  }
  
  console.log(`üé¨ Duraciones VARIADAS: min=${Math.min(...adjustedDurations).toFixed(2)}s, max=${Math.max(...adjustedDurations).toFixed(2)}s, promedio=${(adjustedDurations.reduce((s, d) => s + d, 0) / sceneCount).toFixed(2)}s, total=${adjustedDurations.reduce((s, d) => s + d, 0).toFixed(2)}s`);
  
  // Generar exactamente sceneCount escenas
  const scenes: MusicVideoScene[] = [];
  const linesPerScene = Math.max(1, Math.floor(totalLines / sceneCount));
  
  // Acumular start_time correctamente
  let accumulatedTime = 0;
  
  for (let i = 0; i < sceneCount; i++) {
    // Calcular qu√© l√≠neas de letras corresponden a esta escena
    const startLine = Math.floor((i / sceneCount) * totalLines);
    const endLine = Math.min(Math.floor(((i + 1) / sceneCount) * totalLines), totalLines);
    const sceneLines = lines.slice(startLine, endLine);
    const lyricsText = sceneLines.join(' ').substring(0, 150);
    
    // Determinar tipo de secci√≥n musical
    let musicSection: MusicSection = MusicSection.VERSE;
    if (i === 0) musicSection = MusicSection.INTRO;
    else if (i === sceneCount - 1) musicSection = MusicSection.OUTRO;
    else if (i % 3 === 1) musicSection = MusicSection.CHORUS;
    else if (i % 4 === 2) musicSection = MusicSection.BRIDGE;
    
    // Balance 50/50: alternar entre performance y b-roll
    const role: SceneRole = i % 2 === 0 ? SceneRole.PERFORMANCE : SceneRole.BROLL;
    
    // Obtener shot type de la secuencia variada
    const shotType = shotSequence[i];
    
    // Seleccionar movimiento de c√°mara y lente seg√∫n energ√≠a
    const isHighEnergy = musicSection === MusicSection.CHORUS;
    const cameraMovements = [CameraMovement.HANDHELD, CameraMovement.STEADICAM, CameraMovement.DOLLY, CameraMovement.CRANE, CameraMovement.DRONE];
    const cameraMovement = cameraMovements[i % cameraMovements.length];
    
    const lens = isHighEnergy ? LensType.STANDARD : LensType.PORTRAIT;
    const visualStyle = isHighEnergy ? VisualStyle.VIBRANT : VisualStyle.CINEMATIC;
    const lighting = isHighEnergy ? LightingType.MIXED : LightingType.NATURAL;
    
    // Usar duraci√≥n aleatoria de la lista generada
    const sceneDuration = adjustedDurations[i];
    const start_time = accumulatedTime;
    
    // Generar descripci√≥n seg√∫n el rol
    let description: string;
    if (role === SceneRole.PERFORMANCE) {
      description = isHighEnergy 
        ? `Artist performing energetically, ${shotType} shot capturing dynamic movement and emotional expression. ${lyricsText}`
        : `Artist performing intimately, ${shotType} shot focusing on emotive lip sync and subtle movements. ${lyricsText}`;
    } else {
      // B-roll: escenas de historia/ambiente
      const brollScenes = [
        `Cinematic ${shotType} of urban landscape with artistic composition`,
        `${shotType} capturing environmental storytelling elements`,
        `Atmospheric ${shotType} of symbolic visual narrative`,
        `${shotType} showcasing contextual setting and mood`,
        `Story-driven ${shotType} with strong visual metaphor`
      ];
      description = brollScenes[i % brollScenes.length] + `. ${lyricsText}`;
    }
    
    // Crear escena con nuevo schema
    const scene: MusicVideoScene = {
      scene_id: `scene-${i + 1}`,
      start_time,
      duration: sceneDuration,
      role,
      shot_type: shotType,
      camera_movement: cameraMovement,
      lens,
      visual_style: visualStyle,
      lighting,
      color_temperature: isHighEnergy ? '5000K' : '3200K',
      description,
      lyrics_segment: lyricsText || `Segmento ${i + 1} de la canci√≥n`,
      location: role === SceneRole.PERFORMANCE ? 'performance space' : 'cinematic environment',
      music_section: musicSection,
      status: 'pending'
    };
    
    scenes.push(scene);
    
    // Incrementar el tiempo acumulado con la duraci√≥n de esta escena
    accumulatedTime += sceneDuration;
  }
  
  // Validar balance 50/50
  const balance = validateSceneBalance(scenes);
  console.log(`‚úÖ Balance de escenas: ${balance.message}`);
  
  // Crear script completo con estad√≠sticas
  const totalDuration = audioDuration || adjustedDurations.reduce((sum, d) => sum + d, 0);
  const script: MusicVideoScript = {
    id: `script-${Date.now()}`,
    title: 'Music Video Script',
    duration: totalDuration,
    scene_count: sceneCount,
    scenes,
    stats: {
      performance_count: scenes.filter(s => s.role === SceneRole.PERFORMANCE).length,
      broll_count: scenes.filter(s => s.role === SceneRole.BROLL).length,
      performance_ratio: balance.performance_ratio,
      shot_type_distribution: scenes.reduce((acc, s) => {
        acc[s.shot_type] = (acc[s.shot_type] || 0) + 1;
        return acc;
      }, {} as Record<ShotType, number>)
    },
    generated_at: Date.now(),
    generation_config: {
      audio_duration: audioDuration || 0,
      audio_transcription: lyrics,
      target_scene_count: sceneCount,
      performance_ratio: 0.5
    }
  };
  
  // Retornar en el formato correcto con la key "scenes"
  return JSON.stringify({ scenes: script.scenes }, null, 2);
  
  function extraerPalabrasClave(texto: string): string[] {
    // Lista de palabras emocionales comunes en canciones
    const palabrasEmocionales = [
      "love", "heart", "soul", "dream", "night", "light", "dark",
      "sky", "pain", "joy", "fire", "water", "earth", "wind",
      "eyes", "hands", "dance", "sing", "fall", "rise", "break",
      "build", "hope", "fear", "life", "death", "star", "sun",
      "moon", "ocean", "river", "mountain", "road", "journey"
    ];
    
    // Determinar posible g√©nero musical basado en palabras clave
    type GeneroKey = 'pop' | 'rock' | 'hip-hop' | 'reggaeton' | 'r&b' | 'electr√≥nica' | 'indie';
    type PalabrasGeneroType = {
      [K in GeneroKey]: string[];
    };
    
    const palabrasPorGenero: PalabrasGeneroType = {
      "pop": ["love", "party", "dance", "night", "feeling", "heart"],
      "rock": ["fight", "rebel", "freedom", "power", "wild", "alive"],
      "hip-hop": ["street", "hustle", "real", "flow", "grind", "beat"],
      "reggaeton": ["bailar", "cuerpo", "ritmo", "noche", "fiesta"],
      "r&b": ["soul", "touch", "slow", "feel", "smooth", "baby"],
      "electr√≥nica": ["beat", "night", "high", "sound", "energy", "pulse"],
      "indie": ["dream", "away", "mind", "wonder", "thought", "world"]
    };
    
    // Extraer palabras que coincidan con las listas
    const palabrasEncontradas: string[] = [];
    const palabrasDelTexto = texto.toLowerCase().split(/\s+/);
    
    // Primero palabras emocionales
    for (const palabra of palabrasDelTexto) {
      const palabraLimpia = palabra.replace(/[.,;!?()]/g, '');
      if (palabrasEmocionales.includes(palabraLimpia) && !palabrasEncontradas.includes(palabraLimpia)) {
        palabrasEncontradas.push(palabraLimpia);
      }
    }
    
    // Luego palabras por g√©nero
    for (const genero in palabrasPorGenero) {
      for (const palabra of palabrasPorGenero[genero as GeneroKey]) {
        if (texto.toLowerCase().includes(palabra) && !palabrasEncontradas.includes(palabra)) {
          palabrasEncontradas.push(palabra);
        }
      }
    }
    
    // Si no encontramos suficientes, agregar algunas palabras largas del texto
    if (palabrasEncontradas.length < 3) {
      for (const palabra of palabrasDelTexto) {
        const palabraLimpia = palabra.replace(/[.,;!?()]/g, '');
        if (palabraLimpia.length > 5 && !palabrasEncontradas.includes(palabraLimpia)) {
          palabrasEncontradas.push(palabraLimpia);
          if (palabrasEncontradas.length >= 3) break;
        }
      }
    }
    
    return palabrasEncontradas.slice(0, 5); // Limitar a 5 palabras clave
  }
}

function formatearTiempo(segundos: number): string {
  const minutos = Math.floor(segundos / 60);
  const segs = segundos % 60;
  return `${minutos.toString().padStart(2, '0')}:${segs.toString().padStart(2, '0')}`;
}

export async function analyzeImage(imageUrl: string) {
  try {
    // Verificar API key
    const apiKey = env.VITE_OPENROUTER_API_KEY;
    if (!apiKey) {
      throw new Error('OpenRouter API key is missing or undefined');
    }
    
    // Preparar headers para OpenRouter
    const headers = {
      "Authorization": `Bearer ${apiKey.trim()}`,
      "HTTP-Referer": window.location.origin,
      "X-Title": "Boostify Image Analysis",
      "Content-Type": "application/json"
    };
    
    // Crear el prompt
    const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
      method: "POST",
      headers,
      body: JSON.stringify({
        model: "google/gemini-2.0-flash-001",
        messages: [
          {
            role: "system",
            content: `You are an image analysis expert specialized in music artist branding. Analyze the image URL provided and return a JSON response with this structure:
{
  "style": "Description of overall visual style",
  "colors": ["List of dominant colors"],
  "mood": "Emotional impact/mood of the image",
  "branding": "Analysis of branding effectiveness",
  "recommendations": ["List of specific recommendations to improve the image"]
}`
          },
          {
            role: "user",
            content: `Analyze this image URL: ${imageUrl}`
          }
        ],
        temperature: 0.7,
        max_tokens: 1000,
        response_format: { type: "json_object" }
      })
    });
    
    if (!response.ok) {
      throw new Error(`API error: ${response.status} ${response.statusText}`);
    }
    
    const data = await response.json();
    
    if (!data.choices || !data.choices[0] || !data.choices[0].message || !data.choices[0].message.content) {
      throw new Error("Invalid API response format");
    }
    
    const content = data.choices[0].message.content;
    
    try {
      return JSON.parse(content);
    } catch (error) {
      console.error("Error parsing analysis JSON:", error);
      throw new Error("Invalid JSON format in analysis response");
    }
  } catch (error) {
    console.error("Error analyzing image:", error);
    return {
      style: "Unable to analyze image",
      colors: ["N/A"],
      mood: "N/A",
      branding: "Error analyzing image",
      recommendations: ["Try again with a different image"]
    };
  }
}

export async function transcribeWithAI(audioBase64: string) {
  try {
    const apiKey = env.VITE_OPENROUTER_API_KEY;
    if (!apiKey) {
      throw new Error('OpenRouter API key is missing or undefined');
    }
    
    const headers = {
      "Authorization": `Bearer ${apiKey.trim()}`,
      "HTTP-Referer": window.location.origin,
      "X-Title": "Boostify Audio Transcription",
      "Content-Type": "application/json"
    };
    
    const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
      method: "POST",
      headers,
      body: JSON.stringify({
        model: "google/gemini-2.0-flash-001",
        messages: [
          {
            role: "system",
            content: "You are an audio transcription assistant. Transcribe the audio accurately, capturing all spoken words. For music, describe the genre, tempo, instruments and mood."
          },
          {
            role: "user",
            content: `Transcribe this audio: ${audioBase64.substring(0, 100)}...`
          }
        ],
        temperature: 0.3,
        max_tokens: 1500
      })
    });
    
    if (!response.ok) {
      throw new Error(`API error: ${response.status} ${response.statusText}`);
    }
    
    const data = await response.json();
    
    if (!data.choices || !data.choices[0] || !data.choices[0].message || !data.choices[0].message.content) {
      throw new Error("Invalid API response format");
    }
    
    return data.choices[0].message.content;
  } catch (error) {
    console.error("Error during audio transcription:", error);
    return "Error transcribing audio: " + (error instanceof Error ? error.message : "Unknown error");
  }
}