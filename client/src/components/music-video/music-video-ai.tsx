import { useState, useEffect, useRef, useCallback, useMemo } from "react";
import { logger } from "@/lib/logger";
import { motion, AnimatePresence } from "framer-motion";
import { Button } from "../ui/button";
import { Input } from "../ui/input";
import { Label } from "../ui/label";
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from "../ui/select";
import { Textarea } from "../ui/textarea";
import { TimelineEditor } from "./timeline/TimelineEditor";
import { TimelineEditorCapCut } from "./timeline/TimelineEditorCapCut";
import type { TimelineClip } from "./timeline/TimelineEditor";
import { TimelineClipUnified, ensureCompatibleClip, TimelineItem } from "../timeline/TimelineClipUnified";
import { PreviewImagesModal } from "./PreviewImagesModal";
import { Slider } from "../ui/slider";
import { Card } from "../ui/card";
import Editor from "@monaco-editor/react";
import {
  Video, Loader2, Music2, Image as ImageIcon, Download, Play, Pause,
  ZoomIn, ZoomOut, SkipBack, FastForward, Rewind, Edit, RefreshCcw, Plus, RefreshCw,
  Film, CheckCircle2, Share, User, Upload, X, Check, Activity, ChevronUp, ChevronDown,
  Megaphone, Waves, HelpCircle, Sparkles, Scissors, Clock, Zap
} from "lucide-react";
import { useToast } from "../../hooks/use-toast";
import { ScrollArea } from "../ui/scroll-area";
import { Badge } from "../ui/badge";
import { cn } from "../../lib/utils";
import { Dialog, DialogContent } from "../ui/dialog";
import { Progress } from "../ui/progress";
import * as fal from "@fal-ai/serverless-client";
import { getStorage, ref, uploadBytes, getDownloadURL } from "firebase/storage";
import { collection, addDoc, getDocs, serverTimestamp } from "firebase/firestore";
import { db } from "../../firebase";
import { useAuth } from "../../hooks/use-auth";
import { AnalyticsDashboard } from './analytics-dashboard';
import { RadioGroup, RadioGroupItem } from "../ui/radio-group";
import { VideoGenerator } from "./video-generator";
import { ArtistCustomization } from "./artist-customization";
import { MusicianIntegration } from "./musician-integration";
import { MovementIntegration } from "./movement-integration";
import { LipSyncIntegration } from "./lip-sync-integration";
import { FinalRendering, type UpscaleOptions } from "./final-rendering";
import { ProgressSteps } from "./progress-steps";
import { EnhancedProgressSteps, Step } from "./enhanced-progress-steps";
import { 
  ParticleSystem, 
  AnimatedGradient,
  GlowEffect
} from "./animation-effects";
import { 
  analyzeImage, 
  generateVideoPromptWithRetry, 
  generateMusicVideoScript,
  generateMusicVideoConcept,
  generateThreeConceptProposals,
  type VideoPromptParams 
} from "../../lib/api/openrouter";
import { generateSceneImageWithGemini, type ImageGenerationParams } from "../../lib/api/gemini-nano-image-generator";
import { upscaleVideo } from "../../lib/api/video-service";
import { generateVideoScript as generateVideoScriptAPI } from "../../lib/api/openrouter";
import { batchGenerateMasterVariations, blendMasterAndVariations, detectMasterScenes } from "../../lib/api/master-scene-variations";
import { enrichScriptWithNarrative } from "../../lib/api/narrative-script-enricher";
import { FileText } from "lucide-react";
import fluxService, { FluxModel, FluxTaskType } from "../../lib/api/flux/flux-service";
import { FalModelSelector } from "./fal-model-selector";
import { PaymentSection } from "./payment-section";
import { MyGeneratedVideos } from "./my-generated-videos";
import { generateMusicVideoPrompts } from "../../lib/api/music-video-generator";
import { FAL_VIDEO_MODELS, generateVideoWithFAL, generateMultipleVideos } from "../../lib/api/fal-video-service";
import EnhancedProgressModal from "./enhanced-progress-modal";
import { CreativeOnboardingModal } from "./creative-onboarding-modal";
import { DirectorSelectionModal } from "./director-selection-modal";
import { ConceptSelectionModal } from "./concept-selection-modal";
import { applyLipSync } from "../../lib/api/fal-lipsync";
import { applyPixVerseLipsync, batchPixVerseLipsync, estimateLipsyncCost } from "../../lib/api/pixverse-lipsync";
import { musicVideoProjectService, type MusicVideoProject } from "../../lib/services/music-video-project-service";
import { musicVideoProjectServicePostgres, type MusicVideoProjectPostgres } from "../../lib/services/music-video-project-service-postgres";
import { ProjectManager } from "./project-manager";
import { VideoModelSelector } from "./video-model-selector";
import { getDirectorByName, getDirectorById, type DirectorProfile } from "../../data/directors";
import { uploadImageFromUrl } from "../../lib/firebase-storage";
import { QuickStartTemplates, type QuickStartTemplate } from "./quick-start-templates";
import { SmartSuggestionsPanel } from "./smart-suggestions-panel";
import { 
  detectPerformanceClips, 
  processPerformanceClips,
  getPerformanceSegments
} from "../../lib/services/performance-segment-service";
import {
  type SceneLipsyncConfig,
  batchProcessSceneLipsync
} from "../../lib/api/lipsync-scene-processor";
import { PaymentGateModal } from "./payment-gate-modal";
import { CharacterGenerationModalEnhanced } from "./character-generation-modal-enhanced";
import { analyzeFaceFeatures } from "../../lib/api/face-analyzer";
import { generateMasterCharacterMultiAngle, type MasterCharacterMultiAngle } from "../../lib/api/master-character-generator";
import { generateImagesInParallel, createParallelBatches } from "../../lib/api/parallel-image-generator";
import { EnhancedScenesGallery } from "./EnhancedScenesGallery";
import { SequentialImageGallery } from "./SequentialImageGallery";
import { ensureArtistProfile, saveSongToProfile, updateProfileImages } from "../../lib/auto-profile-service";

// Fal.ai configuration
fal.config({
  credentials: (import.meta as any).env.VITE_FAL_API_KEY,
});

/**
 * Retry with exponential backoff
 * @param fn Function to retry
 * @param maxRetries Maximum number of retries (default: 3)
 * @param baseDelay Base delay in ms (default: 1000)
 * @param onRetry Callback called on each retry attempt
 */
async function retryWithBackoff<T>(
  fn: () => Promise<T>,
  maxRetries: number = 3,
  baseDelay: number = 1000,
  onRetry?: (attempt: number, delay: number, error: Error) => void
): Promise<T> {
  let lastError: Error;
  
  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      return await fn();
    } catch (error) {
      lastError = error as Error;
      
      if (attempt < maxRetries) {
        const delay = baseDelay * Math.pow(2, attempt);
        logger.warn(`üîÑ Retry attempt ${attempt + 1}/${maxRetries} after ${delay}ms...`);
        
        if (onRetry) {
          onRetry(attempt + 1, delay, lastError);
        }
        
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }
  
  logger.error(`‚ùå All ${maxRetries} retry attempts failed`);
  throw lastError!;
}

// Transcribe audio using backend API (secure)
async function transcribeAudio(file: File) {
  try {
    const formData = new FormData();
    formData.append('audio', file);

    logger.info('üåê Fetching /api/audio/transcribe...');
    
    // Crear AbortController para timeout de 15 minutos (para archivos grandes)
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 900000); // 15 minutos
    
    try {
      const response = await fetch('/api/audio/transcribe', {
        method: 'POST',
        body: formData,
        signal: controller.signal,
        credentials: 'include' // Necesario para enviar cookies de sesi√≥n de Replit Auth
      });
      
      clearTimeout(timeoutId);
      logger.info('üìä Server response:', response.status, response.statusText);

      let data;
      try {
        data = await response.json();
        logger.info('üì¶ Data received:', data);
      } catch (parseError) {
        logger.error('‚ùå Error parsing response JSON:', parseError);
        throw new Error('El servidor no respondi√≥ correctamente. Por favor, intenta de nuevo.');
      }

      if (!response.ok || !data.success) {
        const errorMsg = data.error || `Error del servidor: ${response.status}`;
        logger.error('‚ùå Error in server response:', errorMsg);
        
        // Mejorar mensajes de error para el usuario
        if (errorMsg.includes('Connection error') || errorMsg.includes('ECONNRESET')) {
          throw new Error('Error de conexi√≥n con OpenAI. Por favor, intenta de nuevo. Si el problema persiste, verifica tu conexi√≥n a internet o intenta con un archivo de audio m√°s peque√±o.');
        } else if (errorMsg.includes('timeout') || errorMsg.includes('Timeout')) {
          throw new Error('La transcripci√≥n est√° tomando demasiado tiempo. Intenta con un archivo m√°s corto o intenta de nuevo.');
        } else {
          throw new Error(errorMsg);
        }
      }

      if (!data.transcription || !data.transcription.text) {
        logger.error('‚ùå Server response does not contain transcription');
        throw new Error('Transcription was not generated correctly');
      }

      return data.transcription.text;
    } catch (fetchError: any) {
      if (fetchError.name === 'AbortError') {
        throw new Error('La transcripci√≥n tard√≥ demasiado tiempo (m√°s de 15 minutos). Por favor, intenta con un archivo de audio m√°s corto.');
      }
      throw fetchError;
    }
  } catch (error) {
    logger.error("‚ùå Error in transcribeAudio:", error);
    if (error instanceof Error) {
      throw error;
    }
    throw new Error('Unknown error transcribing audio');
  }
}

const videoStyles = {
  moods: [
    "Energetic", "Melancholic", "Romantic", "Dramatic",
    "Mysterious", "Cheerful", "Epic", "Minimalist"
  ],
  colorPalettes: [
    "Vibrant", "Monochromatic", "Pastel", "Dark and Contrasted",
    "Warm", "Cool", "Retro", "Neon"
  ],
  characterStyles: [
    "Realistic", "Stylized", "Artistic", "Abstract",
    "Cinematic", "Documentary", "Surrealist", "Vintage"
  ],
  cameraFormats: [
    {
      name: "35mm Standard",
      description: "The classic cinema format, offers a natural and cinematic image"
    },
    {
      name: "IMAX",
      description: "High detail and visual breadth, ideal for epic scenes"
    },
    {
      name: "Super 8mm",
      description: "Vintage and grainy look, perfect for nostalgic scenes"
    },
    {
      name: "Anamorphic",
      description: "Panoramic format with characteristic lens flares"
    },
    {
      name: "PANAVISION",
      description: "High-end cinematic with distinctive bokeh"
    },
    {
      name: "Digital RAW",
      description: "Modern and sharp look with high dynamic range"
    }
  ]
};

const editingStyles = [
  {
    id: "phrases",
    name: "Phrase-based Editing",
    description: "Cuts synchronized with musical phrases",
    duration: { min: 4, max: 8 }
  },
  {
    id: "random_bars",
    name: "Random Bars",
    description: "Varied cuts following the rhythm",
    duration: { min: 2, max: 6 }
  },
  {
    id: "dynamic",
    name: "Dynamic",
    description: "Fast cuts in intense moments, slower in soft parts",
    duration: { min: 1.5, max: 4 }
  },
  {
    id: "slow",
    name: "Slow",
    description: "Long cuts and smooth transitions",
    duration: { min: 5, max: 10 }
  },
  {
    id: "cinematic",
    name: "Cinematic",
    description: "Movie style with variety of durations",
    duration: { min: 3, max: 8 }
  },
  {
    id: "music_video",
    name: "Music Video",
    description: "MTV style with fast and dynamic cuts",
    duration: { min: 1, max: 3 }
  },
  {
    id: "narrative",
    name: "Narrative",
    description: "Cuts that follow the story of the lyrics",
    duration: { min: 4, max: 7 }
  },
  {
    id: "experimental",
    name: "Experimental",
    description: "Unconventional cut patterns",
    duration: { min: 1, max: 6 }
  },
  {
    id: "rhythmic",
    name: "Rhythmic",
    description: "Precise cuts on each beat",
    duration: { min: 1, max: 2 }
  },
  {
    id: "minimalist",
    name: "Minimalist",
    description: "Few cuts, smooth transitions",
    duration: { min: 6, max: 12 }
  }
];

// We use the TimelineItem interface imported previously
// No need to import it again

// We use the TimelineItem interface imported to maintain compatibility
// We define a specific type for our application based on TimelineItem
type MusicVideoTimelineItem = TimelineItem;

const groups = [
  { id: 1, title: "Video", stackItems: true },
  { id: 2, title: "Transitions", stackItems: false },
  { id: 3, title: "Audio", stackItems: false }
];

const fallbackImage = "data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='100' height='100' viewBox='0 0 24 24' fill='none' stroke='%23888' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='3' width='18' height='18' rx='2' ry='2'/%3E%3Ccircle cx='8.5' cy='8.5' r='1.5'/%3E%3Cpolyline points='21 15 16 10 5 21'/%3E%3C/svg%3E";

interface Director {
  id: string;
  name: string;
  specialty: string;
  style: string;
  experience: string;
  rating: number;
  imageUrl?: string;
}

// üéØ BUSINESS LOGIC: Free tier limits
const FREE_SCENES_LIMIT = 10; // Free users get 10 scenes preview
const FULL_VIDEO_PRICE = 199; // Price in USD for full video generation

interface MusicVideoAIProps {
  preSelectedDirector?: DirectorProfile | null;
}

export function MusicVideoAI({ preSelectedDirector }: MusicVideoAIProps = {}) {
  const { toast } = useToast();
  const { user } = useAuth();
  const [selectedFile, setSelectedFile] = useState<File | null>(null);
  const [isTranscribing, setIsTranscribing] = useState(false);
  const [isGeneratingScript, setIsGeneratingScript] = useState(false);
  const [isGeneratingShots, setIsGeneratingShots] = useState(false);
  const [isGeneratingImages, setIsGeneratingImages] = useState(false);
  const [selectedImageModel, setSelectedImageModel] = useState<'gemini-2.5-flash' | 'gemini-pro-3.0'>('gemini-2.5-flash');
  const [transcription, setTranscription] = useState<string>("");
  const [timelineItems, setTimelineItems] = useState<TimelineItem[]>([]);
  const [selectedSceneId, setSelectedSceneId] = useState<number | null>(null);
  const [showLoadProjectDialog, setShowLoadProjectDialog] = useState(false);
  const [savedProjects, setSavedProjects] = useState<any[]>([]);
  
  // üé¨ VIDEO FORMAT: Store aspect ratio from onboarding (vertical/horizontal)
  const [videoAspectRatio, setVideoAspectRatio] = useState<'16:9' | '9:16' | '1:1'>('16:9');
  const [videoStylePreset, setVideoStylePreset] = useState<string>('realistic');
  
  // DEBUG: Monitor timeline changes
  useEffect(() => {
    logger.info(`üîç [TIMELINE STATE] Timeline updated: ${timelineItems.length} items`);
    if (timelineItems.length > 0) {
      logger.info('üîç [TIMELINE STATE] Timeline items:', timelineItems);
    }
  }, [timelineItems]);
  
  // Load saved projects when dialog opens
  useEffect(() => {
    if (showLoadProjectDialog && user?.uid) {
      musicVideoProjectServicePostgres.getUserProjects(user?.id)
        .then(projects => setSavedProjects(projects))
        .catch(error => {
          logger.error('Error loading projects:', error);
          toast({
            title: "Error",
            description: "Could not load projects",
            variant: "destructive"
          });
        });
    }
  }, [showLoadProjectDialog, user, toast]);

  // Pre-seleccionar director cuando viene desde DirectorsList
  // IMPORTANTE: NO cerramos el onboarding, solo pre-seleccionamos el director
  // El usuario debe pasar por todos los pasos (m√∫sica, im√°genes, director)
  useEffect(() => {
    if (preSelectedDirector) {
      logger.info('üé¨ [DIRECTOR PRE-SELECTED]', preSelectedDirector.name);
      
      // Convertir DirectorProfile a Director para compatibilidad con el estado existente
      const directorForState: Director = {
        id: preSelectedDirector.id,
        name: preSelectedDirector.name,
        specialty: preSelectedDirector.specialty,
        experience: preSelectedDirector.experience,
        style: preSelectedDirector.visual_style.description,
        rating: preSelectedDirector.rating,
        imageUrl: undefined
      };
      
      // Solo guardamos el director en el estado
      // El onboarding se abre normalmente y el usuario pasa por todos los pasos
      setVideoStyle(prev => ({
        ...prev,
        selectedDirector: directorForState
      }));
      
      toast({
        title: `Director ${preSelectedDirector.name} pre-seleccionado`,
        description: "Comienza subiendo tu m√∫sica e im√°genes",
      });
    }
  }, [preSelectedDirector, toast]);

  const [isExporting, setIsExporting] = useState(false);
  const [exportProgress, setExportProgress] = useState(0);
  const [exportStatus, setExportStatus] = useState<string>('');
  const [isPlaying, setIsPlaying] = useState(false);
  const [currentTime, setCurrentTime] = useState(0);
  const [zoomLevel, setZoomLevel] = useState(1);
  const [visibleTimeStart, setVisibleTimeStart] = useState<number>(0);
  const [visibleTimeEnd, setVisibleTimeEnd] = useState<number>(60000);
  const [hoveredShot, setHoveredShot] = useState<TimelineItem | null>(null);
  const [selectedShot, setSelectedShot] = useState<TimelineItem | null>(null);
  const [isEditingScript, setIsEditingScript] = useState(false);
  const [videoId, setVideoId] = useState<string>("");
  const [songTitle, setSongTitle] = useState<string>("");
  const [duration, setDuration] = useState<number>(0);
  const [scriptContent, setScriptContent] = useState<string>("");
  const [narrativeSummary, setNarrativeSummary] = useState<string>("");
  const playbackRef = useRef<NodeJS.Timeout | null>(null);
  const visualStyleRef = useRef<HTMLDivElement>(null);
  const timelineRef = useRef<HTMLDivElement>(null);
  const [videoStyle, setVideoStyle] = useState({
    mood: "",
    colorPalette: "",
    characterStyle: "",
    visualIntensity: 50,
    cameraFormat: "",
    narrativeIntensity: 50,
    referenceImage: null as string | null,
    styleDescription: "",
    styleReferenceUrl: "",
    selectedDirector: null as Director | null
  });
  const [selectedEditingStyle, setSelectedEditingStyle] = useState(editingStyles[0]);
  const storage = getStorage();
  const [isSaving, setIsSaving] = useState(false);
  const [audioBuffer, setAudioBuffer] = useState<AudioBuffer | undefined>(undefined);
  const [audioUrl, setAudioUrl] = useState<string | null>(null);
  const audioDuration = audioBuffer?.duration;
  const [transcriptionWithTimestamps, setTranscriptionWithTimestamps] = useState<{
    segments: Array<{
      start: number;
      end: number;
      text: string;
    }>;
  } | null>(null);
  const audioContext = useRef<AudioContext | null>(null);
  const audioSource = useRef<AudioBufferSourceNode | null>(null);
  const [currentStep, setCurrentStep] = useState<number>(1);
  const [seed, setSeed] = useState<number>(Math.floor(Math.random() * 1000000));
  const [isGeneratingVideo, setIsGeneratingVideo] = useState(false);
  const [directors, setDirectors] = useState<Director[]>([]);
  const [isUpscaling, setIsUpscaling] = useState(false);
  const [generatedVideoUrl, setGeneratedVideoUrl] = useState<string | null>(null);
  const [upscaledVideoUrl, setUpscaledVideoUrl] = useState<string | null>(null);
  
  // Estado para las 3 im√°genes de referencia del artista (para Nano Banana)
  const [artistReferenceImages, setArtistReferenceImages] = useState<string[]>([]);
  const [isUploadingReferences, setIsUploadingReferences] = useState(false);
  
  // Estados para sistema de pago y FAL
  const [isPaidVideo, setIsPaidVideo] = useState(false);
  // KLING O1 Reference-to-Video: Mantiene identidad consistente del artista en todas las escenas
  const [selectedFalModel, setSelectedFalModel] = useState<string>(FAL_VIDEO_MODELS.KLING_O1_STANDARD_REF2V.id);
  const [isGeneratingFullVideo, setIsGeneratingFullVideo] = useState(false);
  const [showMyVideos, setShowMyVideos] = useState(false);

  // Estados para progreso din√°mico
  const [showProgress, setShowProgress] = useState(false);
  const [currentProgressStage, setCurrentProgressStage] = useState<string>("transcription");
  const [progressPercentage, setProgressPercentage] = useState(0);
  const [progressMessage, setProgressMessage] = useState<string>("");

  // Estados para gesti√≥n de proyectos
  const [projectName, setProjectName] = useState<string>("Untitled Project");
  const [currentProjectId, setCurrentProjectId] = useState<string | undefined>(undefined);
  const [isSavingProject, setIsSavingProject] = useState(false);
  
  // Estados para auto-guardado y mejoras de flujo
  const [lastSavedAt, setLastSavedAt] = useState<Date | null>(null);
  const [hasUnsavedChanges, setHasUnsavedChanges] = useState(false);
  const [autoSaveEnabled, setAutoSaveEnabled] = useState(true);

  // Estados para generaci√≥n de videos - KLING O1 para consistencia de personajes
  const [selectedVideoModel, setSelectedVideoModel] = useState<string>(FAL_VIDEO_MODELS.KLING_O1_STANDARD_REF2V.id);
  const [isGeneratingVideos, setIsGeneratingVideos] = useState(false);
  const [videoGenerationProgress, setVideoGenerationProgress] = useState({ current: 0, total: 0 });
  
  // Estado para modal de onboarding
  const [showOnboarding, setShowOnboarding] = useState(true);
  const [showDirectorSelection, setShowDirectorSelection] = useState(false);
  const [showConceptSelection, setShowConceptSelection] = useState(false);
  const [selectedVisualStyle, setSelectedVisualStyle] = useState<string>("");

  // Estados para el modal de progreso de generaci√≥n de im√°genes
  const [generationProgress, setGenerationProgress] = useState({
    current: 0,
    total: 0,
    percentage: 0,
    currentPrompt: '',
    generatedImages: [] as Array<{ id: string; url: string; prompt: string }>,
    status: ''
  });
  
  // Estados para las 3 propuestas de concepto
  const [conceptProposals, setConceptProposals] = useState<any[]>([]);
  const [selectedConcept, setSelectedConcept] = useState<any | null>(null);
  const [isGeneratingConcepts, setIsGeneratingConcepts] = useState(false);
  
  // Estados para Master Character Generation
  const [masterCharacter, setMasterCharacter] = useState<any | null>(null);
  const [isGeneratingCharacter, setIsGeneratingCharacter] = useState(false);
  const [characterGenerationProgress, setCharacterGenerationProgress] = useState(0);
  const [characterGenerationStage, setCharacterGenerationStage] = useState("");
  const [showCharacterGeneration, setShowCharacterGeneration] = useState(false);
  const [characterGenerationComplete, setCharacterGenerationComplete] = useState(false);
  const [pendingConceptGeneration, setPendingConceptGeneration] = useState<{ transcription: string; director: DirectorProfile } | null>(null);
  
  // Lip-sync and performance segments states
  const [isProcessingLipSync, setIsProcessingLipSync] = useState(false);
  const [lipSyncProgress, setLipSyncProgress] = useState({ current: 0, total: 0, message: '' });
  const [performanceSegments, setPerformanceSegments] = useState<Map<number, any>>(new Map());
  
  // Estados para templates r√°pidos
  const [showQuickStartTemplates, setShowQuickStartTemplates] = useState(false);
  
  // Estados para batch operations
  const [selectedClipIds, setSelectedClipIds] = useState<number[]>([]);
  const [isBatchRegenerating, setIsBatchRegenerating] = useState(false);

  // Payment gate states
  const [showPaymentGate, setShowPaymentGate] = useState(false);
  const [isGeneratingRemaining, setIsGeneratingRemaining] = useState(false);
  const [hasUserPaid, setHasUserPaid] = useState(false);
  const [videoGenerationsCount, setVideoGenerationsCount] = useState(0);

  // Preview states
  const [showPreviewModal, setShowPreviewModal] = useState(false);
  const [previewImages, setPreviewImages] = useState<Array<{ id: string; url: string; prompt: string }>>([]);

  // Retry states
  const [retryAttempt, setRetryAttempt] = useState(0);
  const [isRetrying, setIsRetrying] = useState(false);
  const [retryMessage, setRetryMessage] = useState("");

  // Funci√≥n para generar 3 propuestas de concepto
  const generateConceptProposals = async () => {
    if (!transcription) {
      toast({
        title: "Error",
        description: "You need to transcribe the audio first to analyze the lyrics",
        variant: "destructive",
      });
      return;
    }

    if (!videoStyle.selectedDirector) {
      toast({
        title: "Error",
        description: "Select a director first",
        variant: "destructive",
      });
      return;
    }

    setIsGeneratingConcepts(true);
    setShowProgress(true);
    setCurrentProgressStage("script");
    setProgressPercentage(0);
    setProgressMessage("üé¨ Generating 3 creative proposals based on your song's lyrics...");

    try {
      logger.info("üé® [CONCEPTOS] Generando 3 propuestas CON contexto de letra...");
      logger.info("üìù [LYRICS] Transcripci√≥n disponible:", transcription.substring(0, 100) + '...');
      
      const audioDurationInSeconds = audioBuffer?.duration || undefined;
      
      const concepts = await generateThreeConceptProposals(
        transcription, // ‚úÖ La transcripci√≥n YA est√° completa
        videoStyle.selectedDirector.name,
        artistReferenceImages.length > 0 ? artistReferenceImages : undefined,
        audioDurationInSeconds,
        projectName || undefined, // artistName - para posters cinematogr√°ficos premium
        selectedFile?.name?.replace(/\.[^/.]+$/, "") || songTitle || undefined // songTitle
      );
      logger.info("‚úÖ [CONCEPTOS] 3 propuestas generadas con contexto completo");

      setConceptProposals(concepts);
      setProgressPercentage(100);
      
      // Cambiar a paso 1.7 para mostrar los conceptos
      setCurrentStep(1.7);
      
      toast({
        title: "‚úÖ Conceptos generados",
        description: "Elige el concepto que m√°s te guste para continuar",
      });

    } catch (error) {
      logger.error("Error generando conceptos:", error);
      toast({
        title: "Error",
        description: error instanceof Error ? error.message : "Error generando conceptos",
        variant: "destructive",
      });
    } finally {
      setIsGeneratingConcepts(false);
      setShowProgress(false);
      setProgressPercentage(0);
      setProgressMessage("");
    }
  };

  // Funci√≥n auxiliar para ejecutar la generaci√≥n del script autom√°ticamente
  const executeScriptGeneration = async (transcriptionText: string, buffer: AudioBuffer) => {
    logger.info('üîµ [EXEC SCRIPT] Funci√≥n executeScriptGeneration iniciada');
    logger.info('üîµ [EXEC SCRIPT] transcriptionText length:', transcriptionText.length);
    logger.info('üîµ [EXEC SCRIPT] buffer duration:', buffer.duration);
    
    try {
      logger.info('üìù [EXEC SCRIPT] Entrando en try block...');
      setIsTranscribing(false);
      setIsGeneratingScript(true);
      setShowProgress(true);  // ACTIVAR MODAL
      setCurrentProgressStage("script");
      setProgressPercentage(0);
      logger.info('üìä [EXEC SCRIPT] Estados actualizados: showProgress=true, isGeneratingScript=true, stage=script');
      
      // Progreso realista para generaci√≥n de script
      const startTime = Date.now();
      const estimatedDuration = 45000; // ~45 segundos
      
      const progressInterval = setInterval(() => {
        const elapsed = Date.now() - startTime;
        const estimatedProgress = Math.min(88, (elapsed / estimatedDuration) * 100);
        setProgressPercentage(estimatedProgress);
      }, 250);
      
      // üé¨ OBTENER PERFIL COMPLETO DEL DIRECTOR desde JSON
      let directorProfile: DirectorProfile | undefined = undefined;
      if (videoStyle.selectedDirector) {
        directorProfile = getDirectorByName(videoStyle.selectedDirector.name);
        if (directorProfile) {
          logger.info(`üé¨ [DIRECTOR] Perfil completo cargado: ${directorProfile.name}`);
          logger.info(`üìã [DIRECTOR] Estilo: ${directorProfile.visual_style.description}`);
        } else {
          logger.info(`‚ö†Ô∏è [DIRECTOR] No se encontr√≥ perfil JSON para ${videoStyle.selectedDirector.name}, usando datos b√°sicos`);
        }
      }
      
      const audioDurationInSeconds = buffer.duration;
      
      // üÜï Usar el concepto seleccionado por el usuario
      logger.info('üé® [CONCEPTO] Usando concepto seleccionado por el usuario...');
      const concept = selectedConcept;
      
      if (concept) {
        logger.info('‚úÖ [CONCEPTO] Concepto seleccionado:', concept);
      } else {
        logger.info('‚ö†Ô∏è [CONCEPTO] No hay concepto seleccionado, continuando sin √©l');
      }
      
      // PASO 2: Generar script usando el concepto como base Y perfil completo del director
      logger.info('üìù [SCRIPT] Generando script con concepto y perfil del director...');
      const scriptResponse = await generateMusicVideoScript(
        transcriptionText, 
        undefined, 
        directorProfile, // Ahora pasamos el perfil completo
        audioDurationInSeconds,
        undefined,
        concept
      );
      
      clearInterval(progressInterval);
      setProgressPercentage(100);
      await new Promise(resolve => setTimeout(resolve, 1000));
      
      try {
        const parsed = JSON.parse(scriptResponse);
        let scenesToUse = parsed.scenes || (Array.isArray(parsed) ? parsed : []);
        
        // üÜï ENRIQUECER SCRIPT CON CONTEXTO NARRATIVO
        if (scenesToUse.length > 0) {
          logger.info('üìñ [ENRICH] Enriqueciendo script con contexto narrativo...');
          const artistDesc = masterCharacter?.description || 'Professional artist';
          
          try {
            scenesToUse = await enrichScriptWithNarrative(
              transcriptionText,
              scenesToUse,
              directorProfile?.name || 'Creative Director',
              artistDesc,
              concept || null,
              buffer.duration,
              directorProfile || undefined  // üÜï Pasar perfil completo del director para cinematograf√≠a
            );
            logger.info('‚úÖ [ENRICH] Script enriquecido con narrativa y cinematograf√≠a DP');
          } catch (enrichError) {
            logger.warn('‚ö†Ô∏è [ENRICH] Error enriqueciendo narrativa, continuando con script original:', enrichError);
          }
        }
        
        const enrichedScript = { ...parsed, scenes: scenesToUse };
        setScriptContent(JSON.stringify(enrichedScript, null, 2));
      } catch (parseError) {
        setScriptContent(scriptResponse);
      }
      
      setCurrentStep(3);
      setIsGeneratingScript(false);
      logger.info('‚úÖ [EXEC SCRIPT] Script generado exitosamente, currentStep=3');
      
      // Continuar autom√°ticamente con la sincronizaci√≥n y generaci√≥n de im√°genes
      logger.info('üöÄ [FLUJO AUTOM√ÅTICO] Paso 3: Sincronizaci√≥n de timeline');
      logger.info('üéØ [SIGUIENTE] Llamando executeSyncAndImageGeneration...');
      await executeSyncAndImageGeneration(scriptResponse, buffer);
      logger.info('‚úÖ [FLUJO AUTOM√ÅTICO] executeSyncAndImageGeneration completado');
      
    } catch (error) {
      logger.error("‚ùå [EXEC SCRIPT] Error generating script:", error);
      toast({
        title: "Error",
        description: error instanceof Error ? error.message : "Error generating music video script",
        variant: "destructive",
      });
      setIsGeneratingScript(false);
      setShowProgress(false);  // Cerrar modal en caso de error
      setProgressPercentage(0);
      throw error; // Re-lanzar el error para detener el flujo
    }
  };

  // Funci√≥n auxiliar para sincronizar timeline y generar im√°genes autom√°ticamente
  const executeSyncAndImageGeneration = async (script: string, buffer: AudioBuffer) => {
    logger.info('üîµ [SYNC] Funci√≥n executeSyncAndImageGeneration iniciada');
    
    try {
      logger.info('‚è±Ô∏è [SYNC] Sincronizando timeline...');
      setCurrentProgressStage("timeline-prep");
      setProgressPercentage(0);
      logger.info('üìä [SYNC] Estados actualizados: stage=timeline-prep');
      
      // Sincronizar con timeline
      const parsedScript = JSON.parse(script);
      let scenes = [];
      if (parsedScript.scenes && Array.isArray(parsedScript.scenes)) {
        scenes = parsedScript.scenes;
      } else if (Array.isArray(parsedScript)) {
        scenes = parsedScript;
      }
      
      logger.info(`üîç [SYNC DEBUG] Scenes count: ${scenes.length}`);
      logger.info('üîç [SYNC DEBUG] Scenes data:', scenes);
      
      if (scenes.length > 0) {
        const segments = createSegmentsFromScenes(scenes, buffer.duration);
        logger.info(`üîç [SYNC DEBUG] Segments created: ${segments.length}`);
        logger.info('üîç [SYNC DEBUG] Segments data:', segments);
        
        setTimelineItems(segments);
        logger.info('‚úÖ [SYNC DEBUG] setTimelineItems called with', segments.length, 'items');
        
        setCurrentStep(4);
        
        // Scroll autom√°tico al m√≥dulo 4 "Estilo Visual"
        setTimeout(() => {
          visualStyleRef.current?.scrollIntoView({ 
            behavior: 'smooth', 
            block: 'center' 
          });
        }, 500);
      } else {
        logger.error('‚ùå [SYNC DEBUG] NO SCENES FOUND IN SCRIPT!');
      }
      
      setProgressPercentage(100);
      await new Promise(resolve => setTimeout(resolve, 1000));
      logger.info('‚úÖ [SYNC] Timeline sincronizado exitosamente');
      
      // üöÄ CONTINUAR AUTOM√ÅTICAMENTE CON GENERACI√ìN DE IM√ÅGENES
      // El estilo y director ya est√°n en el JSON del script, no necesita selecci√≥n manual
      logger.info('üöÄ [FLUJO AUTOM√ÅTICO] Disparando generaci√≥n de im√°genes autom√°ticamente...');
      toast({
        title: "Timeline sincronizado",
        description: "Generando im√°genes autom√°ticamente con los datos del guion...",
      });
      
      // Llamar a executeImageGeneration pasando el script
      await executeImageGeneration(script);
      
      logger.info('‚úÖ [FLUJO AUTOM√ÅTICO] Script ‚Üí Timeline ‚Üí Im√°genes completado');
      
    } catch (error) {
      logger.error("‚ùå [SYNC] Error in sync and image generation:", error);
      toast({
        title: "Error",
        description: error instanceof Error ? error.message : "Error synchronizing timeline",
        variant: "destructive",
      });
      setShowProgress(false);
      throw error;
    }
  };

  /**
   * üé§ MEJORADO: Procesa lip-sync usando PixVerse para clips de PERFORMANCE
   * 
   * NUEVO FLUJO:
   * 1. Detecta clips por shotCategory='PERFORMANCE' o criterios legacy
   * 2. Usa videoUrl existente de Kling O1 si est√° disponible
   * 3. Aplica PixVerse lip-sync (video-to-video) con audio segmentado
   * 4. Actualiza timeline con lipsyncVideoUrl
   */
  const executePerformanceLipSync = async (script: string, buffer: AudioBuffer) => {
    logger.info('üé§ [PIXVERSE LIP-SYNC] Iniciando procesamiento maestro de lip-sync');
    
    try {
      setIsProcessingLipSync(true);
      setCurrentProgressStage("lip-sync");
      setProgressPercentage(0);
      setShowProgress(true);
      
      const parsedScript = JSON.parse(script);
      let scenes = [];
      if (parsedScript.scenes && Array.isArray(parsedScript.scenes)) {
        scenes = parsedScript.scenes;
      } else if (Array.isArray(parsedScript)) {
        scenes = parsedScript;
      }
      
      // üéØ Detectar clips de performance (ahora usa shotCategory)
      const performanceClips = detectPerformanceClips({ scenes });
      
      logger.info(`üé§ [PIXVERSE] Detectados ${performanceClips.length} clips de PERFORMANCE para lip-sync`);
      
      if (performanceClips.length === 0) {
        logger.info('‚ÑπÔ∏è [PIXVERSE] No hay clips de performance, omitiendo lip-sync');
        toast({
          title: "Lip-Sync Omitido",
          description: "No se detectaron escenas de PERFORMANCE en el script",
        });
        setIsProcessingLipSync(false);
        setShowProgress(false);
        return;
      }
      
      // üí∞ Estimar costo
      const costEstimate = estimateLipsyncCost(performanceClips);
      logger.info(`üí∞ [PIXVERSE] Costo estimado: $${costEstimate.estimatedCost.toFixed(2)} (${costEstimate.totalSeconds}s @ $${costEstimate.costPerSecond}/s)`);
      
      toast({
        title: "üé§ Procesando Lip-Sync con PixVerse",
        description: `${performanceClips.length} escenas de performance (~$${costEstimate.estimatedCost.toFixed(2)})`,
      });
      
      // üé¨ Convertir performanceClips a SceneLipsyncConfig
      // IMPORTANTE: Incluir videoUrl si existe (de Kling O1)
      const sceneConfigs: SceneLipsyncConfig[] = performanceClips.map(clip => {
        // Buscar el timeline item correspondiente
        const timelineItem = timelineItems.find(item => {
          const itemSceneId = parseInt(item.id.toString().match(/(\d+)$/)?.[1] || '0');
          return itemSceneId === clip.id;
        });
        
        // Prioridad: videoUrl (Kling O1) > generatedImage > imageUrl > masterCharacter
        const videoUrl = timelineItem?.videoUrl || '';
        const imageUrl = (typeof timelineItem?.generatedImage === 'string' ? timelineItem.generatedImage : '') || 
                         timelineItem?.imageUrl || 
                         timelineItem?.firebaseUrl ||
                         masterCharacter?.imageUrl || 
                         '';
        
        logger.info(`üìã [SCENE ${clip.id}] videoUrl: ${videoUrl ? 'YES' : 'NO'}, imageUrl: ${imageUrl ? 'YES' : 'NO'}, shotCategory: ${clip.shotCategory || 'UNKNOWN'}`);
        
        return {
          sceneId: clip.id,
          imageUrl: imageUrl,
          videoUrl: videoUrl, // üÜï Pasar video de Kling O1 si existe
          startTime: clip.startTime,
          endTime: clip.endTime,
          duration: clip.duration,
          shotType: clip.shotType,
          shotCategory: clip.shotCategory // üÜï Pasar categor√≠a del script
        };
      });
      
      // Verificar que todas las escenas tengan video o imagen
      const missingMedia = sceneConfigs.filter(c => !c.videoUrl && !c.imageUrl);
      if (missingMedia.length > 0) {
        logger.warn(`‚ö†Ô∏è [PIXVERSE] ${missingMedia.length} escenas sin video ni imagen disponible`);
      }
      
      const userId = user?.uid || 'anonymous';
      
      // üé§ Procesar lip-sync por escena con PixVerse
      const results = await batchProcessSceneLipsync(
        sceneConfigs,
        buffer,
        userId,
        projectName || 'untitled',
        (current, total, message) => {
          logger.info(`üé§ [PIXVERSE Progress] ${current}/${total}: ${message}`);
          setLipSyncProgress({ current, total, message });
          const progress = (current / total) * 100;
          setProgressPercentage(Math.round(progress));
        }
      );
      
      logger.info(`‚úÖ [PIXVERSE] Procesados ${results.size} escenas con lip-sync`);
      
      // üîÑ Actualizar timeline con videos lip-synced
      setTimelineItems(prevItems => {
        return prevItems.map(item => {
          const sceneId = parseInt(item.id.toString().match(/(\d+)$/)?.[1] || '0');
          const lipsyncResult = results.get(sceneId);
          
          if (lipsyncResult?.success && lipsyncResult?.lipsyncVideoUrl) {
            logger.info(`üé• [PIXVERSE] Clip ${sceneId}: lip-sync aplicado exitosamente`);
            return {
              ...item,
              lipsyncVideoUrl: lipsyncResult.lipsyncVideoUrl,
              videoUrl: lipsyncResult.lipsyncVideoUrl, // Reemplazar video original con lip-synced
              lipsyncApplied: true,
              metadata: {
                ...item.metadata,
                hasLipSync: true,
                lipsyncProvider: 'pixverse',
                lipsyncVideoUrl: lipsyncResult.lipsyncVideoUrl,
                originalVideoUrl: item.videoUrl, // Preservar original
                lipsyncAppliedAt: new Date().toISOString()
              }
            };
          }
          
          return item;
        });
      });
      
      const successCount = Array.from(results.values()).filter(r => r.success).length;
      const failedCount = results.size - successCount;
      setProgressPercentage(100);
      
      toast({
        title: "‚úÖ PixVerse Lip-Sync Completado",
        description: `${successCount}/${results.size} escenas de PERFORMANCE sincronizadas${failedCount > 0 ? ` (${failedCount} fallidas)` : ''}`,
      });
      
      setIsProcessingLipSync(false);
      setShowProgress(false);
      
    } catch (error) {
      logger.error('‚ùå [PIXVERSE LIP-SYNC] Error:', error);
      toast({
        title: "Error en PixVerse Lip-Sync",
        description: error instanceof Error ? error.message : "Error procesando lip-sync con PixVerse",
        variant: "destructive",
      });
      setIsProcessingLipSync(false);
      setShowProgress(false);
    }
  };

  // Helper function to save project state to PostgreSQL
  const saveProjectState = async () => {
    if (!user?.email) {
      logger.warn('‚ö†Ô∏è No user email, cannot save project');
      return null;
    }

    try {
      const projectData = {
        userEmail: user.email,
        projectName: projectName || 'Untitled Project',
        script: scriptContent,
        timelineItems: JSON.stringify(timelineItems),
        audioUrl,
        artistReferenceImages: JSON.stringify(artistReferenceImages),
        status: 'partial',
        metadata: JSON.stringify({
          director: videoStyle.selectedDirector?.name,
          concept: selectedConcept,
          seed,
        })
      };

      const response = await fetch('/api/projects/save', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(projectData),
      });

      if (!response.ok) throw new Error('Failed to save project');

      const savedProject = await response.json();
      setCurrentProjectId(savedProject.id.toString());
      logger.info('‚úÖ Project saved:', savedProject.id);
      return savedProject;
    } catch (error) {
      logger.error('‚ùå Error saving project:', error);
      toast({
        title: "Warning",
        description: "Could not save project state",
        variant: "default",
      });
      return null;
    }
  };

  // Funci√≥n auxiliar para generar im√°genes autom√°ticamente
  const executeImageGeneration = async (script?: string, startFrom: number = 1) => {
    logger.info(`üîµ [IMG] Funci√≥n executeImageGeneration iniciada (startFrom: ${startFrom})`);
    
    try {
      logger.info('üé® [IMG] Generando im√°genes con IA...');
      setIsGeneratingImages(true);
      setIsGeneratingShots(true); // Activar modal de visualizaci√≥n en tiempo real
      setShowProgress(false); // Usar el modal de galer√≠a en vez del progress modal
      setCurrentProgressStage("images");
      setProgressPercentage(0);
      logger.info('üìä [IMG] Estados actualizados: isGeneratingShots=true (galer√≠a en tiempo real activada)');
      
      const scriptToUse = script || scriptContent;
      if (!scriptToUse) {
        throw new Error("No script content available");
      }
      
      logger.info('üìù [IMG] Script disponible, length:', scriptToUse.length);

      const parsedScript = JSON.parse(scriptToUse);
      let scenes = [];
      if (parsedScript.scenes && Array.isArray(parsedScript.scenes)) {
        scenes = parsedScript.scenes;
      } else if (Array.isArray(parsedScript)) {
        scenes = parsedScript;
      }
      
      if (scenes.length === 0) {
        throw new Error("The script has no valid scenes");
      }

      // Extraer informaci√≥n global del script para contexto
      const narrativeSummaryText = parsedScript.narrative_summary || '';
      const directorName = videoStyle.selectedDirector?.name || 'Cinematic Director';
      const conceptStory = selectedConcept?.story_concept || '';
      
      // Store narrative summary in state for TimelineEditor
      if (narrativeSummaryText) {
        setNarrativeSummary(narrativeSummaryText);
      }
      
      logger.info(`üé¨ [IMG] Context: Director=${directorName}, Concept=${conceptStory ? 'Yes' : 'No'}, Narrative=${narrativeSummaryText ? 'Yes' : 'No'}`);

      setProgressPercentage(10);

      const geminiScenes = scenes.map((scene: any) => {
        const shotType = scene.shot_type || "MS";
        const cameraMovement = scene.camera_movement || "static";
        const lens = scene.lens || "standard";
        const lighting = scene.lighting || "natural";
        const visualStyle = scene.visual_style || "cinematic";
        const description = scene.description || "";
        const location = scene.location || "performance space";
        const colorTemp = scene.color_temperature || "5000K";
        
        return {
          id: scene.scene_id || `scene-${Math.random()}`,
          scene: description,
          camera: `${lens} lens, ${shotType} shot, ${cameraMovement} movement`,
          lighting: `${lighting} lighting, ${colorTemp} color temperature`,
          style: `${visualStyle} style, ${location}`,
          movement: cameraMovement
        };
      });

      // LIMIT TO 10 IMAGES FOR TESTING - Faster iteration on narrative quality
      const MAX_IMAGES_FOR_TESTING = 10;
      const totalScenes = Math.min(geminiScenes.length, MAX_IMAGES_FOR_TESTING);
      
      // Always generate only 10 images for testing
      const imagesToGenerate = Math.min(10, totalScenes);
      const endAt = Math.min(10, totalScenes);
      
      logger.info(`üì∏ [IMG] Generation settings (TESTING MODE): startFrom=${startFrom}, endAt=${endAt}, total=${totalScenes}, maxAllowed=${MAX_IMAGES_FOR_TESTING}`);
      
      // Decidir qu√© endpoint usar basado en si hay im√°genes de referencia
      const hasReferenceImages = artistReferenceImages && artistReferenceImages.length > 0;
      
      logger.info(`üì∏ [IMG] Generaci√≥n SECUENCIAL iniciada. Total escenas: ${totalScenes}, Referencias: ${hasReferenceImages ? artistReferenceImages.length : 0}`);
      
      // üÜï MASTER SCENE VARIATIONS SYSTEM
      let masterImageUrls = new Map<string, string>();
      let scenesWithVariations: Map<string, any> = new Map();
      let masterSceneIds: string[] = [];
      
      // Inicializar el estado de progreso del modal
      setGenerationProgress({
        current: startFrom - 1,
        total: totalScenes,
        percentage: 0,
        currentPrompt: 'Iniciando generaci√≥n...',
        generatedImages: [],
        status: 'Preparando generaci√≥n de im√°genes...'
      });
      
      // Usar generaci√≥n SECUENCIAL - una imagen a la vez
      // üé¨ CRITICAL: Siempre usar el endpoint con m√∫ltiples referencias (funciona con array vac√≠o tambi√©n)
      const endpoint = '/api/gemini-image/generate-single-with-multiple-faces';
      
      let generatedCount = 0;
      
      // Generar im√°genes desde startFrom hasta endAt
      for (let i = startFrom - 1; i < endAt; i++) {
        const scene = geminiScenes[i];
        const sceneIndex = i + 1;
        
        logger.info(`üé® [IMG ${sceneIndex}/${totalScenes}] Generando imagen para escena...`);
        
        try {
          // Obtener la escena original del JSON con todos los campos narrativos
          const originalScene = scenes[i];
          
          // Construir prompt RICO EN NARRATIVA usando los nuevos campos
          const shotCategory = originalScene.shot_category || 'STORY';
          const narrativeContext = originalScene.narrative_context || '';
          const lyricConnection = originalScene.lyric_connection || '';
          const visualDescription = originalScene.visual_description || originalScene.description || scene.scene;
          const emotion = originalScene.emotion || originalScene.mood || '';
          const storyProgression = originalScene.story_progression || '';
          
          // Construir prompt cinematogr√°fico COMPLETO con narrativa y contexto global
          const prompt = `MUSIC VIDEO CONTEXT:
${narrativeSummaryText ? `Overall Story: ${narrativeSummaryText}` : ''}
${conceptStory ? `Concept: ${conceptStory}` : ''}
Director Style: ${directorName}

SCENE ${sceneIndex} - ${shotCategory} SHOT:
${visualDescription}

NARRATIVE:
${narrativeContext}

LYRIC CONNECTION:
${lyricConnection}

STORY ARC:
${storyProgression}

EMOTION: ${emotion}

TECHNICAL SPECS:
Camera: ${scene.camera}
Lighting: ${scene.lighting}
Style: ${scene.style}
Shot Type: ${originalScene.shot_type || 'medium-shot'}
Color Grading: ${originalScene.color_grading || 'cinematic'}
Location: ${originalScene.location || 'performance space'}

Professional music video frame, ${shotCategory === 'PERFORMANCE' ? 'featuring the artist performing/singing' : shotCategory === 'B-ROLL' ? 'cinematic b-roll visual WITHOUT the artist visible' : 'narrative story scene with characters/elements'}, high production quality, ${directorName} directorial style, cohesive with overall music video narrative.`;
          
          logger.info(`üìù [IMG ${sceneIndex}] Shot Category: ${shotCategory}, Emotion: ${emotion}`);
          
          // Detectar si debe usar referencia del artista usando los nuevos campos
          const useArtistReference = originalScene.use_artist_reference !== false; // Default true for backward compatibility
          const referenceUsage = originalScene.reference_usage || 
                                (shotCategory === 'PERFORMANCE' ? 'full_performance' : 'none');
          
          // Determinar si usar la imagen de referencia basado en la l√≥gica avanzada
          const shouldUseReference = useArtistReference && 
                                    (referenceUsage !== 'none') &&
                                    (masterCharacter || hasReferenceImages);
          
          const referenceToUse = shouldUseReference 
            ? (masterCharacter ? [masterCharacter.imageUrl] : artistReferenceImages)
            : undefined;
          
          logger.info(`üé≠ [SCENE ${sceneIndex}] Category: ${shotCategory}, Reference Usage: ${referenceUsage}, Using Reference: ${!!referenceToUse}`);
          
          const requestBody = { 
            prompt: prompt,
            sceneId: sceneIndex,
            referenceImagesBase64: referenceToUse || [],
            seed: seed + sceneIndex
          };
          
          // üîÑ RETRY: Usar retry con exponential backoff para mayor robustez
          const data = await retryWithBackoff(
            async () => {
              const response = await fetch(endpoint, {
                method: 'POST',
                headers: {
                  'Content-Type': 'application/json',
                },
                body: JSON.stringify(requestBody),
              });

              if (!response.ok) {
                const errorData = await response.json().catch(() => ({}));
                throw new Error(errorData.error || `HTTP ${response.status}`);
              }

              return await response.json();
            },
            3, // 3 reintentos
            2000, // 2 segundos de delay inicial
            (attempt, delay, error) => {
              // Callback para mostrar feedback visual
              setIsRetrying(true);
              setRetryAttempt(attempt);
              setRetryMessage(`Retrying scene ${sceneIndex}... Attempt ${attempt}/3 (${delay}ms delay)`);
              logger.warn(`üîÑ [IMG ${sceneIndex}] Retry ${attempt}/3: ${error.message}`);
            }
          );
          
          // Limpiar estado de retry despu√©s de √©xito
          setIsRetrying(false);
          setRetryAttempt(0);
          setRetryMessage("");
          
          const isValidImageUrl = data.imageUrl && 
                                  typeof data.imageUrl === 'string' && 
                                  (data.imageUrl.startsWith('http') || data.imageUrl.startsWith('data:image/'));
          
          // Fixed: Check if we got an image URL regardless of success field
          const hasValidUrl = isValidImageUrl && data.imageUrl;
          
          if (hasValidUrl) {
            generatedCount++;
            logger.info(`‚úÖ [IMG ${sceneIndex}/${totalScenes}] Image generated successfully`);
            
            // üíæ GUARDAR EN FIREBASE STORAGE para persistencia
            let permanentImageUrl = data.imageUrl;
            if (user?.uid) {
              try {
                logger.info(`üì§ [FIREBASE ${sceneIndex}] Subiendo imagen a Firebase Storage...`);
                permanentImageUrl = await uploadImageFromUrl(data.imageUrl, user?.id, projectName);
                logger.info(`‚úÖ [FIREBASE ${sceneIndex}] Imagen guardada permanentemente`);
                
                // üé® AUTO-PERFIL: Actualizar im√°genes de perfil con primera imagen de alta calidad
                if (sceneIndex === 1 || sceneIndex === 2) {
                  try {
                    const imageData = sceneIndex === 1 
                      ? { profileImageUrl: permanentImageUrl } // Primera imagen como foto de perfil
                      : { coverImageUrl: permanentImageUrl }; // Segunda imagen como banner
                    
                    await updateProfileImages({
                      ...imageData,
                      onlyIfEmpty: true // Solo actualizar si el usuario no tiene im√°genes
                    });
                    logger.info(`‚úÖ Imagen de perfil actualizada autom√°ticamente (escena ${sceneIndex})`);
                  } catch (profileImageError) {
                    // No bloqueamos el flujo
                    logger.warn('‚ö†Ô∏è Error actualizando imagen de perfil (no cr√≠tico):', profileImageError);
                  }
                }
              } catch (uploadError) {
                logger.warn(`‚ö†Ô∏è [FIREBASE ${sceneIndex}] Error subiendo a Firebase, usando URL temporal:`, uploadError);
              }
            }
            
            // Actualizar el progreso del modal
            setGenerationProgress(prev => ({
              ...prev,
              current: sceneIndex,
              total: totalScenes,
              percentage: Math.round((sceneIndex / totalScenes) * 100),
              currentPrompt: scene.scene || 'Generating...',
              generatedImages: [
                ...prev.generatedImages,
                {
                  id: `scene-${sceneIndex}`,
                  url: permanentImageUrl,
                  prompt: scene.scene || `Scene ${sceneIndex}`
                }
              ],
              status: `Generando imagen ${sceneIndex} de ${totalScenes}...`
            }));
            
            // Actualizar el timeline
            setTimelineItems(prevItems => {
              return prevItems.map(item => {
                const sceneNumberMatch = item.id.toString().match(/(\d+)$/);
                if (!sceneNumberMatch) return item;
                
                const itemSceneNumber = parseInt(sceneNumberMatch[1]);
                
                if (itemSceneNumber === sceneIndex) {
                  logger.info(`üñºÔ∏è [IMG ${sceneIndex}] ‚úÖ Actualizando timeline item ${item.id}`);
                  return {
                    ...item,
                    imageUrl: permanentImageUrl,
                    thumbnail: permanentImageUrl,
                    url: permanentImageUrl,
                    generatedImage: permanentImageUrl,
                    metadata: {
                      ...item.metadata,
                      isGeneratedImage: true,
                      isPerformanceScene: isPerformanceScene,
                      usesMasterCharacter: usesMasterCharacter,
                      masterCharacterUrl: usesMasterCharacter ? masterCharacter.imageUrl : undefined,
                      imageGeneratedAt: new Date().toISOString(),
                      scene_id: sceneIndex,
                      shot_type: item.shotType || item.metadata?.shot_type,
                      role: item.metadata?.role || 'performance'
                    }
                  };
                }
                
                return item;
              });
            });
            
            // üÜï GUARDAR URL PARA MASTER SCENE VARIATIONS
            if (!masterImageUrls.has(scene.scene_id || `scene-${sceneIndex}`)) {
              masterImageUrls.set(scene.scene_id || `scene-${sceneIndex}`, permanentImageUrl);
            }
            
            // üéØ PREVIEW: Mostrar modal despu√©s de 10 im√°genes (solo primera vez)
            if (sceneIndex === 10 && startFrom === 1 && !isAdmin && totalScenes > 10) {
              logger.info('üéØ [PREVIEW] 10 im√°genes completadas, mostrando modal de preview...');
              
              // üÜï GENERAR MASTER SCENE VARIATIONS
              if (masterImageUrls.size > 0) {
                logger.info(`üé¨ [VARIATIONS] Generando variaciones para ${masterImageUrls.size} escenas maestro...`);
                try {
                  scenesWithVariations = await batchGenerateMasterVariations(
                    scenes,
                    masterImageUrls,
                    (current, total, msg) => {
                      logger.info(`üé¨ [VARIATIONS] ${current}/${total}: ${msg}`);
                      setProgressPercentage(100 - (current / total) * 10);
                    }
                  );
                  logger.info(`‚úÖ [VARIATIONS] ${scenesWithVariations.size} escenas con variaciones`);
                  
                  // üÜï MEZCLAR MAESTROS CON VARIACIONES
                  if (scenesWithVariations.size > 0) {
                    scenes = blendMasterAndVariations(scenes, scenesWithVariations);
                    logger.info('‚úÖ [BLEND] Escenas maestro + variaciones mezcladas');
                  }
                } catch (variationError) {
                  logger.warn('‚ö†Ô∏è [VARIATIONS] Error generando variaciones, continuando sin ellas:', variationError);
                }
              }
              
              setPreviewImages(generationProgress.generatedImages.filter((_, idx) => idx < 10));
              setShowPreviewModal(true);
              setIsGeneratingImages(false);
              setIsGeneratingShots(false);
              return; // Detener generaci√≥n hasta que usuario apruebe
            }
            
            // Actualizar progreso general
            const progress = 30 + ((sceneIndex / totalScenes) * 60);
            setProgressPercentage(Math.round(progress));
            
          }
          
        } catch (error) {
          logger.error(`‚ùå [IMG ${sceneIndex}] Error en generaci√≥n:`, error);
          continue;
        }
        
        // No payment gate during image generation - let users generate all images
        // Payment gate will be shown when they want to render the final video
      }
      
      logger.info(`‚úÖ [IMG] Generaci√≥n completada: ${generatedCount} im√°genes generadas`);

      setProgressPercentage(100);
      await new Promise(resolve => setTimeout(resolve, 1000));
      
      // üé® NUEVO: Guardar im√°genes generadas en la galer√≠a del perfil del artista
      if (generatedCount > 0 && user?.email) {
        try {
          logger.info('üì∏ [GALLERY] Guardando im√°genes generadas en galer√≠a del perfil...');
          
          // Obtener el artistProfileId desde el proyecto guardado
          const projects = await musicVideoProjectServicePostgres.listProjects(user.email);
          const currentProject = projects.find(p => p.projectName === projectName);
          
          if (currentProject?.artistProfileId) {
            // Recopilar im√°genes generadas con metadata
            const sceneImages = timelineItems
              .filter(item => item.generatedImage || item.imageUrl)
              .map((item, index) => ({
                url: item.generatedImage || item.imageUrl || '',
                sceneNumber: index + 1,
                shotType: item.shotType || item.metadata?.shot_type || undefined,
                mood: item.metadata?.mood || undefined,
                timestamp: item.start || undefined,
                description: item.imagePrompt?.substring(0, 200) || `Scene ${index + 1}`
              }))
              .filter(img => img.url.length > 0);
            
            if (sceneImages.length > 0) {
              const { addSceneImagesToProfile } = await import('@/lib/api/artist-profile-service');
              
              const result = await addSceneImagesToProfile({
                artistProfileId: currentProject.artistProfileId,
                projectId: currentProject.id,
                sceneImages
              });
              
              if (result.success) {
                logger.info(`‚úÖ [GALLERY] ${result.imagesAdded} im√°genes agregadas a la galer√≠a del perfil`);
              }
            }
          }
        } catch (galleryError) {
          logger.warn('‚ö†Ô∏è [GALLERY] Error agregando im√°genes a la galer√≠a (no cr√≠tico):', galleryError);
        }
      }
      
      // Only process lip-sync if we've completed all images
      if (audioBuffer && user?.uid && generatedCount > 0 && endAt === totalScenes) {
        logger.info('üé§ [LIP-SYNC] Detectando clips de performance para lip-sync...');
        await executePerformanceLipSync(scriptToUse, audioBuffer);
      }
      
      // Mostrar mensaje de √©xito
      toast({
        title: "¬°Proceso Completado!",
        description: `${generatedCount + startFrom - 1} im√°genes generadas exitosamente`,
      });

      logger.info('‚úÖ [IMG] Im√°genes generadas exitosamente');
      
      setCurrentStep(5);
      setIsGeneratingImages(false);
      setIsGeneratingShots(false); // Cerrar modal de galer√≠a en tiempo real
      setShowProgress(false);
      setProgressPercentage(0);
      
      // Limpiar el estado de progreso
      setGenerationProgress({
        current: 0,
        total: 0,
        percentage: 0,
        currentPrompt: '',
        generatedImages: [],
        status: ''
      });
      
      // üìç SCROLL AUTOM√ÅTICO AL TIMELINE
      setTimeout(() => {
        timelineRef.current?.scrollIntoView({ 
          behavior: 'smooth', 
          block: 'center',
          inline: 'nearest'
        });
      }, 500);
      
    } catch (error) {
      logger.error("‚ùå [IMG] Error generating images:", error);
      toast({
        title: "Error",
        description: error instanceof Error ? error.message : "Error generating images",
        variant: "destructive",
      });
      setIsGeneratingImages(false);
      setIsGeneratingShots(false); // Cerrar modal en caso de error
      setShowProgress(false);
      setProgressPercentage(0);
    }
  };

  // Handle payment success - unlock full video generation
  const handlePaymentSuccess = async () => {
    logger.info('üí≥ [PAYMENT] Payment successful - unlocking full video generation');
    
    // Mark user as paid
    setHasUserPaid(true);
    
    // Close payment gate modal
    setShowPaymentGate(false);
    
    toast({
      title: "üéâ Payment Successful!",
      description: "Generating your complete music video now...",
    });
    
    // Start generating remaining scenes
    await handleGenerateRemainingScenes();
  };
  
  /**
   * üé¨ FULL VIDEO: Generates remaining scenes after payment
   */
  const handleGenerateRemainingScenes = async () => {
    if (!scriptContent || !audioBuffer) {
      toast({
        title: "Error",
        description: "Missing script or audio data",
        variant: "destructive",
      });
      return;
    }
    
    setIsGeneratingRemaining(true);
    
    try {
      // Parse full script
      const parsedScript = JSON.parse(scriptContent);
      let allScenes = parsedScript.scenes || [];
      
      // Get scenes starting from FREE_SCENES_LIMIT + 1
      const remainingScenes = allScenes.slice(FREE_SCENES_LIMIT);
      
      logger.info(`üé¨ [FULL VIDEO] Generating ${remainingScenes.length} remaining scenes...`);
      
      toast({
        title: "üé¨ Generating Full Video",
        description: `Creating ${remainingScenes.length} remaining scenes...`,
      });
      
      // Create remaining segments
      const remainingSegments = createSegmentsFromScenes(remainingScenes, audioBuffer.duration);
      
      // Add to existing timeline items
      setTimelineItems(prev => [...prev, ...remainingSegments]);
      
      // Generate images for remaining segments
      setIsGeneratingShots(true);
      
      for (let i = 0; i < remainingSegments.length; i++) {
        const item = remainingSegments[i];
        
        setGenerationProgress({
          current: i + 1,
          total: remainingSegments.length,
          percentage: Math.round(((i + 1) / remainingSegments.length) * 100),
          currentPrompt: item.imagePrompt || '',
          generatedImages: [],
          status: `Generating scene ${FREE_SCENES_LIMIT + i + 1}...`
        });
        
        try {
          const imageUrl = await generateImageForSegment(item);
          
          if (imageUrl) {
            setTimelineItems(prev => prev.map(timelineItem =>
              timelineItem.id === item.id
                ? { ...timelineItem, generatedImage: imageUrl, firebaseUrl: imageUrl }
                : timelineItem
            ));
          }
        } catch (error) {
          logger.error(`Error generating scene ${item.id}:`, error);
        }
        
        // Rate limit
        await new Promise(resolve => setTimeout(resolve, 1000));
      }
      
      logger.info('‚úÖ [FULL VIDEO] All images generated, starting video conversion...');
      
      // Auto-convert all remaining scenes to videos
      await handleAutoConvertToVideos();
      
      toast({
        title: "üéâ Full Video Complete!",
        description: "Your complete music video is ready for export!",
      });
      
    } catch (error) {
      logger.error('‚ùå Error generating remaining scenes:', error);
      toast({
        title: "Error",
        description: "Failed to generate remaining scenes",
        variant: "destructive",
      });
    } finally {
      setIsGeneratingRemaining(false);
      setIsGeneratingShots(false);
    }
  };

  // Handle preview approval - continue generating remaining images
  const handlePreviewApprove = async () => {
    logger.info('‚úÖ [PREVIEW] User approved, continuing generation...');
    setShowPreviewModal(false);
    
    toast({
      title: "Preview Approved!",
      description: "Continuing generation for remaining images...",
    });
    
    // Continue from image 11
    await executeImageGeneration(scriptContent, 11);
  };

  // Handle preview rejection - stop and allow adjustments
  const handlePreviewReject = () => {
    logger.info('‚ùå [PREVIEW] User rejected, stopping generation');
    setShowPreviewModal(false);
    setIsGeneratingImages(false);
    setIsGeneratingShots(false);
    
    toast({
      title: "Generation Stopped",
      description: "You can adjust settings and try again",
    });
  };

  // Funci√≥n para manejar el resultado del onboarding
  const handleOnboardingComplete = useCallback(async (
    audioFile: File, 
    referenceImages: string[], 
    artistName: string,
    songName: string,
    aspectRatio: string,
    videoStyle: string,
    conceptBrief?: string
  ) => {
    logger.info('üéâ Onboarding completed:', {
      audio: audioFile.name,
      imagesCount: referenceImages.length,
      artistName,
      songName,
      aspectRatio,
      videoStyle,
      conceptBrief: conceptBrief || 'No concept provided'
    });
    
    // Set artist name, song name, reference images, and audio file
    setProjectName(`${artistName} - ${songName}`);
    setArtistReferenceImages(referenceImages);
    setSelectedFile(audioFile);
    
    // üé¨ STORE VIDEO FORMAT: Save aspect ratio for all generators
    setVideoAspectRatio(aspectRatio as '16:9' | '9:16' | '1:1');
    setVideoStylePreset(videoStyle);
    logger.info(`üìê Video format set: ${aspectRatio} (${aspectRatio === '9:16' ? 'VERTICAL' : aspectRatio === '1:1' ? 'SQUARE' : 'HORIZONTAL'})`);
    
    // Store concept brief if provided
    if (conceptBrief) {
      logger.info('üí° Concept Brief:', conceptBrief);
    }
    
    // Preparar el audio buffer
    const reader = new FileReader();
    reader.onload = async (e) => {
      if (e.target?.result instanceof ArrayBuffer) {
        if (!audioContext.current) {
          audioContext.current = new AudioContext();
        }
        const buffer = await audioContext.current.decodeAudioData(e.target.result);
        setAudioBuffer(buffer);
      }
    };
    reader.readAsArrayBuffer(audioFile);
    
    // Cerrar el modal de onboarding y mostrar el modal de selecci√≥n de director
    setShowOnboarding(false);
    setShowDirectorSelection(true);
    
    logger.info('‚úÖ [ONBOARDING COMPLETADO] Mostrando modal de selecci√≥n de director');
  }, []);

  // Handler para cuando se selecciona director y estilo
  /**
   * Handler para aplicar template r√°pido
   */
  const handleTemplateSelection = useCallback((template: QuickStartTemplate) => {
    logger.info('üì¶ Aplicando template:', template.name);
    
    // Buscar director por nombre
    const director = getDirectorByName(template.director.name);
    
    if (director) {
      setVideoStyle(prev => ({
        ...prev,
        mood: template.visualStyle.mood,
        colorPalette: template.visualStyle.colorPalette,
        cameraFormat: template.visualStyle.cameraFormat,
        visualIntensity: template.visualStyle.visualIntensity,
        selectedDirector: {
          id: director.id,
          name: director.name,
          specialty: director.specialty,
          style: director.visual_style?.description || template.director.style,
          experience: director.experience || 'Professional',
          rating: director.rating
        }
      }));
      
      // Aplicar estilo de edici√≥n
      const editingStyle = editingStyles.find(s => s.id === template.editingStyle.id);
      if (editingStyle) {
        setSelectedEditingStyle(editingStyle);
      }
      
      toast({
        title: "Template aplicado",
        description: `Configuraci√≥n "${template.name}" lista para usar`,
      });
      
      logger.info('‚úÖ Template aplicado exitosamente');
    } else {
      toast({
        title: "Error",
        description: "No se pudo encontrar el director del template",
        variant: "destructive"
      });
    }
  }, [toast]);

  // Handler para generar master character con soporte multi-√°ngulo y casting
  const handleGenerateMasterCharacter = useCallback(async () => {
    if (artistReferenceImages.length === 0) {
      logger.info('‚ö†Ô∏è No reference images available, skipping character generation');
      return null;
    }

    logger.info('üé≠ Starting Master Character generation with multi-angle support...');
    setIsGeneratingCharacter(true);
    setShowCharacterGeneration(true);
    setCharacterGenerationProgress(0);
    setCharacterGenerationStage("Analyzing facial features...");

    try {
      const directorStyle = videoStyle.selectedDirector?.visual_style?.description || "Cinematic professional style";
      
      const masterChar = await generateMasterCharacterMultiAngle(
        artistReferenceImages,
        directorStyle,
        (stage, progress) => {
          setCharacterGenerationStage(stage);
          setCharacterGenerationProgress(progress);
        }
      );

      logger.info('‚úÖ Master Character generated with multi-angle support:', {
        angles: masterChar.mainCharacter.angles.length,
        castMembers: masterChar.casting.length
      });

      setCharacterGenerationProgress(100);
      setCharacterGenerationStage("‚úÖ Character and casting generation complete!");
      await new Promise(resolve => setTimeout(resolve, 800));
      setIsGeneratingCharacter(false);
      setCharacterGenerationComplete(true);

      toast({
        title: "Character Profiles Ready",
        description: "Master character with 4 angles + 4 cast members generated",
      });

      setMasterCharacter(masterChar);
      return masterChar;

    } catch (error) {
      logger.error('‚ùå Error generating master character:', error);
      setIsGeneratingCharacter(false);
      setShowCharacterGeneration(false);

      toast({
        title: "Error",
        description: error instanceof Error ? error.message : "Error generating character",
        variant: "destructive",
      });

      return null;
    }
  }, [artistReferenceImages, videoStyle.selectedDirector?.visual_style?.description, toast]);

  const handleDirectorSelection = useCallback(async (director: DirectorProfile, style: string) => {
    logger.info('üé¨ Director seleccionado:', director.name, '| Estilo:', style);
    
    // Guardar director y estilo
    setVideoStyle(prev => ({
      ...prev,
      selectedDirector: director as any // Type compatibility fix
    }));
    setSelectedVisualStyle(style);
    
    // Cerrar modal de director
    setShowDirectorSelection(false);
    
    // Iniciar transcripci√≥n si a√∫n no se ha hecho
    if (!transcription && selectedFile) {
      logger.info('üé§ Iniciando transcripci√≥n autom√°tica...');
      setIsTranscribing(true);
      setShowProgress(true);
      setCurrentProgressStage("transcription");
      setProgressPercentage(0);
      setProgressMessage("üéµ Step 1/2: Analyzing song lyrics to understand the context...");
      
      // Progreso realista basado en el tama√±o del archivo
      const startTime = Date.now();
      const fileSizeMB = selectedFile.size / 1024 / 1024;
      const estimatedDuration = fileSizeMB * 10 * 1000; // ~10 seg por MB
      
      const progressInterval = setInterval(() => {
        const elapsed = Date.now() - startTime;
        const estimatedProgress = Math.min(92, (elapsed / estimatedDuration) * 100);
        setProgressPercentage(estimatedProgress);
      }, 200);
      
      try {
        const transcriptionText = await transcribeAudio(selectedFile);
        logger.info('‚úÖ Transcripci√≥n completada, length:', transcriptionText.length, 'characters');
        clearInterval(progressInterval);
        setProgressPercentage(100);
        await new Promise(resolve => setTimeout(resolve, 800));
        setTranscription(transcriptionText);
        setCurrentStep(1.5);
        
        // üé® AUTO-PERFIL: Guardar canci√≥n autom√°ticamente en perfil del artista
        try {
          logger.info('üé® Guardando canci√≥n en perfil del artista...');
          
          // Get genre from director or use default
          const genre = videoStyle.selectedDirector?.name || 'Music Video';
          
          // Ensure profile exists
          const profileResult = await ensureArtistProfile(genre);
          if (profileResult.success) {
            logger.info('‚úÖ Perfil verificado/creado:', profileResult.profile?.slug);
            
            // Save song to Firestore
            const songResult = await saveSongToProfile({
              title: projectName || selectedFile.name.replace(/\.[^/.]+$/, ''),
              audioUrl: audioUrl || '',
              lyrics: transcriptionText,
              genre: genre,
              duration: audioDuration,
              fileName: selectedFile.name,
              format: selectedFile.type
            });
            
            if (songResult.success) {
              logger.info('‚úÖ Canci√≥n guardada autom√°ticamente:', songResult.song?.id);
              logger.info('üîó Ver perfil en: /artist/' + profileResult.profile?.slug);
            }
          }
        } catch (autoProfileError) {
          // No bloqueamos el flujo si falla el auto-perfil
          logger.warn('‚ö†Ô∏è Error en auto-perfil (no cr√≠tico):', autoProfileError);
        }
        
        // ‚úÖ TRANSCRIPCI√ìN COMPLETADA - Ahora s√≠ generar conceptos con contexto
        setProgressMessage("‚úÖ Lyrics analyzed! Now generating creative proposals...");
        setProgressPercentage(0);
        
        // ‚ö° OPTIMIZACI√ìN: Generar conceptos INMEDIATAMENTE (sin esperar Master Character)
        // El Master Character se generar√° en PARALELO en background
        logger.info('üé® Generando 3 conceptos creativos CON contexto de letra (SIN esperar Master Character)...');
        setProgressMessage("üé¨ Generating 3 creative proposals based on your lyrics...");
        
        // Generar conceptos en paralelo con Master Character (si hay im√°genes)
        const conceptsPromise = handleGenerateConcepts(transcriptionText, director);
        
        // Generar Master Character en BACKGROUND (no bloquea conceptos)
        if (artistReferenceImages.length > 0) {
          logger.info('üé≠ Generando Master Character en PARALELO (background)...');
          handleGenerateMasterCharacter().catch(err => {
            logger.warn('‚ö†Ô∏è Master Character fall√≥ (no cr√≠tico):', err);
          });
        }
        
        // Esperar SOLO a conceptos (mucho m√°s r√°pido)
        await conceptsPromise;
        
      } catch (err) {
        logger.error("‚ùå Error transcribing audio:", err);
        clearInterval(progressInterval);
        toast({
          title: "Error de transcripci√≥n",
          description: err instanceof Error ? err.message : "Error al transcribir el audio",
          variant: "destructive",
        });
        setIsTranscribing(false);
        setShowProgress(false);
        setProgressPercentage(0);
        setProgressMessage("");
        // Volver al modal de selecci√≥n
        setShowDirectorSelection(true);
      }
    } else if (transcription) {
      // If transcription exists, generate Master Character FIRST, then WAIT for user to click Next
      logger.info('‚úÖ [TRANSCRIPCI√ìN] Ya existe - generando Character PRIMERO');
      
      // üé≠ PASO 1: GENERATE MASTER CHARACTER FIRST
      if (artistReferenceImages.length > 0) {
        logger.info('üé≠ Generating Master Character FIRST (with artist + casting)...');
        setShowProgress(false);
        setCharacterGenerationComplete(false);
        // Guardar datos para generar conceptos CUANDO usuario clickee Siguiente
        setPendingConceptGeneration({ transcription, director });
        await handleGenerateMasterCharacter();
        logger.info('‚úÖ Master Character generated - waiting for user to click Next...');
      }
    }
  }, [transcription, artistReferenceImages, selectedFile, videoStyle, audioContext, audioUrl, toast, audioBuffer, projectName, selectedVisualStyle]);























  const handleGenerateConcepts = useCallback(async (transcriptionText: string, director: DirectorProfile) => {
    logger.info('üé¨ [CONCEPTOS] Iniciando generaci√≥n con contexto completo de letra');
    logger.info('üìù [LYRICS CONTEXT] Letra disponible:', transcriptionText.substring(0, 100) + '...');
    
    setIsGeneratingConcepts(true);
    setShowProgress(true);
    setCurrentProgressStage("concepts");
    setProgressMessage("üé¨ Generating 3 creative proposals based on your song's story...");
    
    try {
      const audioDurationInSeconds = audioBuffer ? audioBuffer.duration : 180;
      
      // üé® USAR IM√ÅGENES DEL MASTER CHARACTER GENERADO (ahora siempre existen)
      // El Master Character se genera ANTES de los conceptos, por eso siempre debe estar disponible
      const characterImages = masterCharacter 
        ? [
            masterCharacter.mainCharacter.angles[0]?.url, // frontal
            masterCharacter.mainCharacter.angles[1]?.url, // left-profile
            masterCharacter.mainCharacter.angles[2]?.url, // right-profile
            masterCharacter.mainCharacter.angles[3]?.url  // three-quarter
          ].filter(Boolean)
        : artistReferenceImages;
      
      const characterReference = characterImages.length > 0 ? characterImages : undefined;
      
      if (characterReference) {
        logger.info(`üé≠ [REFERENCIAS] Usando im√°genes del Master Character generado (${characterReference.length} √°ngulos)`);
        logger.info('üì∏ √Ångulos disponibles:', {
          frontal: masterCharacter?.mainCharacter.angles[0]?.url ? '‚úÖ' : '‚ùå',
          leftProfile: masterCharacter?.mainCharacter.angles[1]?.url ? '‚úÖ' : '‚ùå',
          rightProfile: masterCharacter?.mainCharacter.angles[2]?.url ? '‚úÖ' : '‚ùå',
          threeQuarter: masterCharacter?.mainCharacter.angles[3]?.url ? '‚úÖ' : '‚ùå'
        });
      } else {
        logger.info('‚ö†Ô∏è [REFERENCIAS] No hay im√°genes del Master Character disponibles');
      }
      
      logger.info('ü§ñ [AI] Llamando a generateThreeConceptProposals con letra completa...');
      const concepts = await generateThreeConceptProposals(
        transcriptionText, // ‚úÖ CR√çTICO: La letra YA est√° transcrita aqu√≠
        director.name,
        characterReference,
        audioDurationInSeconds,
        projectName || undefined, // artistName - para posters cinematogr√°ficos premium
        selectedFile?.name?.replace(/\.[^/.]+$/, "") || songTitle || undefined // songTitle
      );
      logger.info('‚úÖ [CONCEPTOS] 3 propuestas generadas con contexto de letra');
      
      logger.info('‚úÖ Conceptos generados:', concepts.length);
      
      // üé¨ GENERAR POSTERS DE HOLLYWOOD PROGRESIVAMENTE
      // Mostrar conceptos inmediatamente y generar posters mientras el usuario los ve
      setProgressMessage("Generando posters cinematogr√°ficos estilo Hollywood...");
      
      // Inicializar conceptos CON DETALLES COMPLETOS (mejorado para mostrar m√°s info)
      const conceptsInitial = concepts.map((concept: any, index: number) => ({
        ...concept,
        coverImage: null,
        isGenerating: true,
        artistName: projectName || 'Artist Name',
        songTitle: selectedFile?.name?.replace(/\.[^/.]+$/, "") || 'Song Title',
        // üìù CONCEPTOS MEJORADOS - Mostrar detalles completos
        detailedDescription: concept.detailed_description || concept.description || '',
        visualTheme: concept.visual_theme || '',
        cameraWork: concept.camera_angles || concept.cinematography || 'Dynamic camera movements',
        editingStyle: concept.editing_style || 'Fast-paced cuts with creative transitions',
        characterRole: concept.character_description || 'Lead performer',
        lighting: concept.lighting_setup || 'Cinematic lighting with color grading',
        locationDetails: concept.setting || concept.location || 'Various locations',
        emotionalArc: concept.emotional_arc || 'Building intensity throughout',
        specialEffects: concept.special_effects || 'Subtle visual effects',
        paceAndRhythm: concept.pacing || 'Synced to beat drops and verses'
      }));
      
      setConceptProposals(conceptsInitial);
      setIsGeneratingConcepts(false);
      setShowProgress(false);
      
      // Mostrar modal INMEDIATAMENTE para que el usuario vea el progreso
      setShowConceptSelection(true);
      
      // ‚ö° Generar TODOS los posters EN PARALELO para m√°xima velocidad
      logger.info(`üé¨ Iniciando generaci√≥n de ${concepts.length} posters en PARALELO...`);
      
      const posterPromises = concepts.map(async (concept: any, index: number) => {
        try {
          logger.info(`üé¨ Generando poster Hollywood ${index + 1}/3...`);
          
          // Crear prompt mejorado y detallado para poster cinematogr√°fico
          const posterPrompt = `HOLLYWOOD MUSIC VIDEO POSTER DESIGN

Title: "${concept.title || `Concept ${index + 1}`}"

VISUAL CONCEPT:
${concept.detailed_description || concept.description || concept.visual_theme || 'Dynamic music video poster'}

STORY ELEMENTS:
${concept.story_concept || 'Engaging narrative visual'}

ATMOSPHERE & MOOD:
${concept.emotional_arc || 'Cinematic and impactful'}

DIRECTOR STYLE: ${director.name}'s signature style with:
- ${concept.visual_theme || 'Professional cinematography'}
- ${concept.lighting || 'Cinematic lighting'}
- ${concept.camera_work || 'Dynamic camera angles'}

CHARACTER: ${concept.character_description || 'Lead performer as the focal point'}

COLOR GRADING: ${concept.color_grading || 'Bold cinematic color palette'}

DESIGN REQUIREMENTS:
- Professional Hollywood-style movie poster
- High-impact visual composition
- Text-ready layout (blank space for title area)
- Photorealistic rendering
- 4K resolution ready for print
- Commercial music video aesthetics
- Catchy and memorable visual`;
          
          const response = await fetch('/api/gemini-image/generate-hollywood-poster', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ 
              conceptTitle: concept.title || `Concepto ${index + 1}`,
              conceptDescription: posterPrompt,
              artistReferenceImages: characterReference || [],
              directorName: director.name,
              conceptIndex: index + 1,
              totalConcepts: concepts.length
            })
          });
          
          if (!response.ok) {
            throw new Error(`HTTP ${response.status}: Failed to generate poster`);
          }
          
          const data = await response.json();
          
          if (data.success && data.imageUrl) {
            logger.info(`‚úÖ Poster Hollywood ${index + 1} generado exitosamente`);
            
            // Subir a Firebase Storage si hay usuario
            let posterUrl = data.imageUrl;
            if (user?.uid) {
              try {
                posterUrl = await uploadImageFromUrl(data.imageUrl, user?.id, `${projectName}/concept-posters`);
                logger.info(`‚úÖ Poster ${index + 1} guardado en Firebase Storage`);
              } catch (uploadError) {
                logger.warn(`‚ö†Ô∏è Error subiendo poster ${index + 1} a Firebase:`, uploadError);
              }
            }
            
            // ‚ö° ACTUALIZAR UI INMEDIATAMENTE (Progressive loading!)
            setConceptProposals((prev: any[]) => {
              const updated = [...prev];
              updated[index] = {
                ...updated[index],
                coverImage: posterUrl,
                isGenerating: false
              };
              return updated;
            });
            
            toast({
              title: `Poster ${index + 1}/3 listo`,
              description: `"${concept.title || `Concepto ${index + 1}`}" generado en HD`,
            });
            
            return { success: true, index };
          } else {
            throw new Error(data.error || 'No image URL returned');
          }
        } catch (error) {
          logger.error(`‚ùå Error generando poster Hollywood ${index + 1}:`, error);
          
          // Marcar como fallido pero continuar con los dem√°s
          setConceptProposals((prev: any[]) => {
            const updated = [...prev];
            updated[index] = {
              ...updated[index],
              coverImage: null,
              isGenerating: false,
              error: true
            };
            return updated;
          });
          
          toast({
            title: `Poster ${index + 1} - Error`,
            description: `Reintentando...`,
            variant: "destructive",
          });
          
          return { success: false, index };
        }
      });
      
      // Ejecutar todos en paralelo y esperar a que terminen
      const posterResults = await Promise.all(posterPromises);
      const successCount = posterResults.filter(r => r.success).length;
      
      logger.info(`‚úÖ Proceso de generaci√≥n de posters completado: ${successCount}/3 exitosos`);
      
    } catch (err) {
      logger.error("‚ùå Error generando conceptos:", err);
      toast({
        title: "Error",
        description: err instanceof Error ? err.message : "Error generando conceptos",
        variant: "destructive",
      });
      setIsGeneratingConcepts(false);
      setShowProgress(false);
      // Volver al modal de director
      setShowDirectorSelection(true);
    }
  }, [audioBuffer, artistReferenceImages, toast, projectName, selectedFile, seed, user, uploadImageFromUrl]);

  // Handler para cuando se selecciona un concepto
  const handleConceptSelection = useCallback(async (concept: any) => {
    logger.info('üé® Concepto seleccionado:', concept.title || 'Concepto');
    
    setSelectedConcept(concept);
    
    // ‚ö° CIERRE INMEDIATO DEL MODAL
    setShowConceptSelection(false);
    
    // üé¨ MOSTRAR PROGRESO INMEDIATAMENTE
    setShowProgress(true);
    setCurrentProgressStage("script");
    setProgressMessage("Generando gui√≥n cinematogr√°fico...");
    
    // üöÄ TRABAJO PESADO EN BACKGROUND (no bloquea la UI)
    // Usar Promise.then() para no bloquear el cierre del modal
    Promise.resolve().then(async () => {
      try {
        // Guardar concepto en la base de datos EN BACKGROUND
        if (user?.email) {
          try {
            logger.info('üíæ [BG] Guardando concepto seleccionado en base de datos...');
            
            const projectData = {
              userEmail: user.email!,
              projectName: projectName || `Video ${Date.now()}`,
              audioUrl: selectedFile?.name || '',
              audioDuration: audioBuffer?.duration,
              transcription: transcription,
              timelineItems: timelineItems,
              selectedDirector: videoStyle.selectedDirector,
              videoStyle: videoStyle,
              artistReferenceImages: artistReferenceImages,
              selectedConcept: concept,
              generatedConcepts: conceptProposals,
              status: 'generating_script' as const,
              progress: {
                scriptGenerated: false,
                imagesGenerated: 0,
                totalImages: 0,
                videosGenerated: 0,
                totalVideos: 0
              }
            };
            
            const savedProject = await musicVideoProjectServicePostgres.saveProject(projectData);
            logger.info('‚úÖ [BG] Concepto guardado en base de datos');
            
            // üé® Crear perfil de artista autom√°ticamente EN BACKGROUND
            if (savedProject?.project?.id) {
              logger.info('üë§ [BG] Creando perfil de artista autom√°ticamente...');
              
              const { createArtistProfileFromVideo } = await import('@/lib/api/artist-profile-service');
              
              // Extraer im√°genes de conceptos para la galer√≠a
              const conceptImages = conceptProposals
                .filter(c => c.coverImage)
                .map(c => ({
                  url: c.coverImage || '',
                  type: 'concept-poster',
                  description: c.title || 'Music Video Concept'
                }));
              
              const profileResult = await createArtistProfileFromVideo({
                projectId: savedProject.project.id,
                userEmail: user.email!,
                creatorUserId: user.id,
                artistName: projectName || 'AI Generated Artist',
                songName: selectedFile?.name?.replace(/\.[^/.]+$/, '') || undefined,
                selectedConcept: concept,
                lyrics: transcription || undefined,
                referenceImages: artistReferenceImages,
                conceptImages: conceptImages
              });
              
              if (profileResult.success) {
                logger.info('‚úÖ [BG] Perfil de artista creado:', profileResult.profile?.artistName);
                toast({
                  title: "‚ú® Perfil de Artista Creado",
                  description: `Se ha creado autom√°ticamente el perfil para "${profileResult.profile?.artistName}"`,
                });
              } else {
                logger.warn('‚ö†Ô∏è [BG] No se pudo crear el perfil autom√°tico, continuando');
              }
            }
            
          } catch (error) {
            logger.error('‚ùå [BG] Error guardando concepto:', error);
            // Continuar de todas formas - no es cr√≠tico
          }
        }
        
        // Proceder a generar el script completo y las im√°genes
        logger.info('üìú Generando script final basado en el concepto...');
        
        if (transcription && audioBuffer) {
          await executeScriptGeneration(transcription, audioBuffer);
        } else {
          logger.error('‚ùå No hay transcripci√≥n o audioBuffer disponible');
          toast({
            title: "Error",
            description: "Falta transcripci√≥n o audio para continuar",
            variant: "destructive",
          });
          setShowProgress(false);
        }
        
      } catch (error) {
        logger.error('‚ùå Error en procesamiento de concepto:', error);
        setShowProgress(false);
      }
    }).catch(error => {
      logger.error('‚ùå Error en promesa de background:', error);
      setShowProgress(false);
    });
    
  }, [executeScriptGeneration, user, projectName, selectedFile, audioBuffer, transcription, timelineItems, videoStyle, artistReferenceImages, conceptProposals, toast]);

  const handleFileChange = useCallback((event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      if (file.size > 50 * 1024 * 1024) {
        toast({
          title: "Error",
          description: "File must be smaller than 50MB",
          variant: "destructive",
        });
        return;
      }

      if (!file.type.startsWith("audio/")) {
        toast({
          title: "Error",
          description: "Please upload a valid audio file (MP3)",
          variant: "destructive",
        });
        return;
      }

      setSelectedFile(file);
      setTranscription("");
      setTimelineItems([]);
      setCurrentTime(0);
      setIsPlaying(false);

      const reader = new FileReader();
      reader.onload = async (e) => {
        if (e.target?.result instanceof ArrayBuffer) {
          if (!audioContext.current) {
            audioContext.current = new AudioContext();
          }
          const buffer = await audioContext.current.decodeAudioData(e.target.result);
          setAudioBuffer(buffer);

          // Use OpenAI for transcription
          logger.info('üé§ Starting file transcription:', file.name, `(${(file.size / 1024 / 1024).toFixed(2)} MB)`);
          setIsTranscribing(true);
          setShowProgress(true);
          setCurrentProgressStage("transcription");
          setProgressPercentage(0);
          
          // Progreso realista basado en el tama√±o del archivo
          const startTime = Date.now();
          const fileSizeMB = file.size / 1024 / 1024;
          // Estimar tiempo: ~8-12 segundos por MB de audio
          const estimatedDuration = fileSizeMB * 10 * 1000;
          
          const progressInterval = setInterval(() => {
            const elapsed = Date.now() - startTime;
            const estimatedProgress = Math.min(92, (elapsed / estimatedDuration) * 100);
            setProgressPercentage(estimatedProgress);
          }, 200);
          
          try {
            logger.info('üì§ Sending file to server for transcription...');
            const transcriptionText = await transcribeAudio(file);
            logger.info('‚úÖ Transcription completed, length:', transcriptionText.length, 'characters');
            clearInterval(progressInterval);
            setProgressPercentage(100);
            await new Promise(resolve => setTimeout(resolve, 1000));
            setTranscription(transcriptionText);
            setCurrentStep(1.5);
            
            setShowProgress(false);
            setIsTranscribing(false);
            setProgressPercentage(0);
            
            logger.info('‚úÖ [TRANSCRIPCI√ìN COMPLETADA] Usuario puede ahora seleccionar director');
            
            toast({
              title: "‚úÖ Transcripci√≥n completada",
              description: "Ahora puedes seleccionar un director y estilo para continuar",
            });
            
          } catch (err) {
            logger.error("‚ùå Error transcribing audio:", err);
            clearInterval(progressInterval);
            toast({
              title: "Transcription error",
              description: err instanceof Error ? err.message : "Error transcribing audio. Please try again.",
              variant: "destructive",
            });
            setIsTranscribing(false);
            setShowProgress(false);
            setProgressPercentage(0);
          }
        }
      };
      reader.readAsArrayBuffer(file);
    }
  }, [toast]);

  // Function to handle artist reference image upload
  const handleReferenceImageUpload = useCallback(async (event: React.ChangeEvent<HTMLInputElement>) => {
    const files = event.target.files;
    if (!files || files.length === 0) return;

    // Validate that no more than 10 images are uploaded in total
    if (artistReferenceImages.length + files.length > 10) {
      toast({
        title: "Error",
        description: "You can only upload a maximum of 10 reference images",
        variant: "destructive",
      });
      return;
    }

    setIsUploadingReferences(true);

    try {
      const newImages: string[] = [];
      
      for (let i = 0; i < files.length && artistReferenceImages.length + newImages.length < 10; i++) {
        const file = files[i];
        
        // Validate file type
        if (!file.type.startsWith('image/')) {
          toast({
            title: "Error",
            description: `${file.name} is not a valid image`,
            variant: "destructive",
          });
          continue;
        }

        // Validate size (maximum 5MB per image)
        if (file.size > 5 * 1024 * 1024) {
          toast({
            title: "Error",
            description: `${file.name} exceeds the maximum size of 5MB`,
            variant: "destructive",
          });
          continue;
        }

        // Convert image to base64
        const base64 = await new Promise<string>((resolve, reject) => {
          const reader = new FileReader();
          reader.onload = () => resolve(reader.result as string);
          reader.onerror = reject;
          reader.readAsDataURL(file);
        });

        newImages.push(base64);
      }

      setArtistReferenceImages([...artistReferenceImages, ...newImages]);
      
      toast({
        title: "Success",
        description: `${newImages.length} reference image(s) added (${artistReferenceImages.length + newImages.length}/10)`,
      });
    } catch (error) {
      logger.error("Error loading reference images:", error);
      toast({
        title: "Error",
        description: "Error processing reference images",
        variant: "destructive",
      });
    } finally {
      setIsUploadingReferences(false);
    }
  }, [artistReferenceImages, toast]);

  // Function to remove a reference image
  const removeReferenceImage = useCallback((index: number) => {
    setArtistReferenceImages(prev => prev.filter((_, i) => i !== index));
    toast({
      title: "Image removed",
      description: `Reference image ${index + 1} removed`,
    });
  }, [toast]);

  const generateScriptFromTranscription = async () => {
    if (!transcription) {
      toast({
        title: "Error",
        description: "You need to transcribe the audio first",
        variant: "destructive",
      });
      return;
    }

    setIsGeneratingScript(true);
    setShowProgress(true);
    setCurrentProgressStage("script");
    setProgressPercentage(0);
    
    // Progreso realista para generaci√≥n de script completo
    const startTime = Date.now();
    const estimatedDuration = 60000; // ~60 segundos para script completo
    
    const progressInterval = setInterval(() => {
      const elapsed = Date.now() - startTime;
      const estimatedProgress = Math.min(85, (elapsed / estimatedDuration) * 100);
      setProgressPercentage(estimatedProgress);
    }, 300);
    
    try {
      // Call API to generate the script
      toast({
        title: "Processing",
        description: "Generating script based on song lyrics...",
      });

      // üé¨ OBTENER PERFIL COMPLETO DEL DIRECTOR desde JSON
      let directorProfile: DirectorProfile | undefined = undefined;
      if (videoStyle.selectedDirector) {
        directorProfile = getDirectorByName(videoStyle.selectedDirector.name);
        if (directorProfile) {
          logger.info(`üé¨ [DIRECTOR] Perfil completo cargado: ${directorProfile.name}`);
        }
      }
      
      // Pass audio duration to generate scenes every ~4 seconds
      const audioDurationInSeconds = audioBuffer?.duration || undefined;
      
      // ÔøΩ PASO 1: Usar concepto seleccionado por el usuario O generar uno nuevo
      let conceptToUse = selectedConcept;
      
      if (!conceptToUse) {
        // Si no hay concepto seleccionado, generar uno nuevo basado en la letra
        logger.info('üé® [CONCEPTO] No hay concepto seleccionado, generando uno nuevo basado en la letra...');
        conceptToUse = await generateMusicVideoConcept(
          transcription,
          artistReferenceImages.length > 0 ? artistReferenceImages : undefined,
          audioDurationInSeconds
        );
        
        if (conceptToUse) {
          logger.info('‚úÖ [CONCEPTO] Concepto generado y guardado en estado');
          setSelectedConcept(conceptToUse); // üÜï Guardar para uso posterior
        } else {
          logger.warn('‚ö†Ô∏è [CONCEPTO] No se pudo generar concepto, el script se generar√° sin contexto visual');
        }
      } else {
        logger.info('üé® [CONCEPTO] Usando concepto seleccionado por el usuario:', conceptToUse.title || conceptToUse.story_concept?.substring(0, 50));
      }
      
      // üìù PASO 2: Generar script usando LETRA + CONCEPTO + DIRECTOR
      // El script debe conectar cada escena con el segmento de letra correspondiente
      logger.info('üìù [SCRIPT] Generando script conectando LETRA ‚Üî CONCEPTO ‚Üî ESCENAS...');
      logger.info(`   - Letra: ${transcription.substring(0, 100)}...`);
      logger.info(`   - Concepto: ${conceptToUse?.story_concept?.substring(0, 80) || 'Sin concepto'}...`);
      logger.info(`   - Director: ${directorProfile?.name || 'Creative Director'}`);
      
      const scriptResponse = await generateMusicVideoScript(
        transcription, 
        undefined, 
        directorProfile, // Perfil completo del director
        audioDurationInSeconds,
        undefined,
        conceptToUse // üÜï Pasar el concepto correcto (seleccionado o generado)
      );
      
      clearInterval(progressInterval);
      setProgressPercentage(100);
      await new Promise(resolve => setTimeout(resolve, 500));
      
      // Try to format JSON for better visualization
      try {
        // Check if it's already a valid JSON string, and parse it to format it
        const parsed = JSON.parse(scriptResponse);
        setScriptContent(JSON.stringify(parsed, null, 2));
      } catch (parseError) {
        // If it can't be parsed, use the response directly
        logger.warn("Could not format script JSON, using direct response", parseError);
        setScriptContent(scriptResponse);
      }
      
      // Mark this step as completed
      setCurrentStep(3);
      
      toast({
        title: "Success",
        description: "Music video script generated correctly",
      });
    } catch (error) {
      logger.error("Error generating script:", error);
      clearInterval(progressInterval);
      toast({
        title: "Error",
        description: error instanceof Error ? error.message : "Error generating music video script",
        variant: "destructive",
      });
    } finally {
      setIsGeneratingScript(false);
      setShowProgress(false);
      setProgressPercentage(0);
    }
  };

  const syncAudioWithTimeline = async () => {
    if (!audioBuffer) return;

    if (!scriptContent) {
      toast({
        title: "Error",
        description: "You must first generate the music video script",
        variant: "destructive",
      });
      return;
    }

    setIsGeneratingShots(true);
    try {
      let segments: TimelineItem[] = [];
      
      // Create segments based on JSON script scenes
      try {
        const parsedScript = JSON.parse(scriptContent);
        
        // Verify script format and extract scenes
        let scenes = [];
        if (parsedScript.scenes && Array.isArray(parsedScript.scenes)) {
          // New format: { scenes: [...] }
          scenes = parsedScript.scenes;
        } else if (Array.isArray(parsedScript) && parsedScript.length > 0 && parsedScript[0].scene_id) {
          // Old format: direct array of scenes
          scenes = parsedScript;
        }
        
        // üéØ FREE TIER LIMIT: Limit scenes to FREE_SCENES_LIMIT for unpaid users
        const totalScenes = scenes.length;
        if (!hasUserPaid && scenes.length > FREE_SCENES_LIMIT) {
          logger.info(`üé¨ [FREE TIER] Limiting ${totalScenes} scenes to ${FREE_SCENES_LIMIT} for free preview`);
          scenes = scenes.slice(0, FREE_SCENES_LIMIT);
          
          toast({
            title: "üé¨ Free Preview Mode",
            description: `Creating ${FREE_SCENES_LIMIT} of ${totalScenes} scenes. Pay $${FULL_VIDEO_PRICE} to unlock the full video!`,
          });
        }
        
        // Check if we have valid scenes
        if (scenes.length > 0) {
          segments = createSegmentsFromScenes(scenes, audioBuffer.duration);
          toast({
            title: "Synchronizing",
            description: `Creating ${segments.length} scenes based on the cinematic script`,
          });
        } else {
          throw new Error("The script does not contain valid scenes");
        }
      } catch (e) {
        logger.error("Error parsing script:", e);
        throw new Error("Could not process the script. Please, generate the script again.");
      }
      
      if (segments && segments.length > 0) {
        // ‚úÖ VERIFICAR Y REPORTAR PROMPTS DEL SCRIPT JSON
        const segmentsWithPrompts = segments.filter(s => s.imagePrompt && s.imagePrompt.length > 20);
        logger.info(`üìä RESUMEN DE SINCRONIZACI√ìN:`);
        logger.info(`   Total de escenas: ${segments.length}`);
        logger.info(`   Escenas con prompts: ${segmentsWithPrompts.length}`);
        logger.info(`   Prompts √∫nicos detectados: ${new Set(segments.map(s => s.imagePrompt)).size}`);
        
        if (segmentsWithPrompts.length > 0) {
          logger.info(`üìù Primeros 3 prompts del guion:`);
          segmentsWithPrompts.slice(0, 3).forEach((s, i) => {
            logger.info(`   ${i + 1}. ${s.imagePrompt?.substring(0, 80)}...`);
          });
        }
        
        setTimelineItems(segments);
        setCurrentStep(4);

        toast({
          title: "Success",
          description: `${segments.length} scenes synchronized with ${segmentsWithPrompts.length} cinematic prompts`,
        });
      } else {
        throw new Error("No segments detected in the script");
      }
    } catch (error) {
      logger.error("Error synchronizing audio:", error);
      toast({
        title: "Error",
        description: error instanceof Error ? error.message : "Error synchronizing audio with timeline",
        variant: "destructive",
      });
    } finally {
      setIsGeneratingShots(false);
    }
  };

  /**
   * üé¨ MEJORADO: Crea segmentos del timeline preservando TODOS los campos narrativos del script
   * Esto permite que generateImageForSegment use el contexto completo para regenerar im√°genes
   * @param scenes - Escenas del script JSON
   * @param totalDuration - Duraci√≥n total del audio
   */
  const createSegmentsFromScenes = (scenes: any[], totalDuration: number): TimelineItem[] => {
    const segments: TimelineItem[] = [];
    
    scenes.forEach((scene, index) => {
      // READ start_time and duration directly from the script JSON
      // DO NOT calculate equal durations - use the random values (3-4 sec) from JSON
      const startTime = (scene.start_time || 0) * 1000; // Convert seconds to milliseconds
      const duration = (scene.duration || 3.5) * 1000; // Duration in milliseconds (default 3.5s)
      const endTime = startTime + duration;
      
      // Support both 'id' and 'scene_id' for compatibility
      // Convert "scene-1" to 1, "scene-2" to 2, etc.
      let sceneId = index + 1; // Default fallback
      if (scene.id) {
        const match = scene.id.toString().match(/\d+/);
        sceneId = match ? parseInt(match[0]) : index + 1;
      } else if (scene.scene_id) {
        const match = scene.scene_id.toString().match(/\d+/);
        sceneId = match ? parseInt(match[0]) : index + 1;
      }
      
      // Construir prompt cinematogr√°fico completo desde todos los campos del JSON
      const cinematicPrompt = scene.visual_description || 
                               `${scene.shot_type || 'medium-shot'} of ${scene.description || scene.lyrics || 'scene'}, ${scene.lighting || 'dramatic lighting'}, ${scene.color_grading || 'cinematic colors'}, ${scene.mood || 'emotional'} atmosphere, ${scene.location || 'location'}, ${scene.camera_movement || 'smooth camera movement'}`;
      
      logger.info(`üé¨ Creating clip ${sceneId}: start=${scene.start_time}s, duration=${scene.duration}s`);
      logger.info(`üìù Prompt: ${cinematicPrompt.substring(0, 100)}...`);
      logger.info(`üé≠ Shot Category: ${scene.shot_category || 'STORY'}, Use Reference: ${scene.use_artist_reference !== false}`);
      
      segments.push({
        id: sceneId, // CRITICAL: Use numeric ID for React keys
        type: 'image', // Image type for proper display
        group: 1,
        title: scene.title || `Scene ${scene.scene_id || scene.scene_number}`,
        start_time: startTime,
        end_time: endTime,
        duration: duration,
        shotType: scene.shot_type || scene.camera?.lens || 'MS', // Shot type from JSON
        description: scene.visual_description || scene.description || `Scene ${scene.scene_id || scene.scene_number}`,
        imagePrompt: cinematicPrompt, // ‚úÖ CORREGIDO: Usa visual_description del backend
        thumbnail: '', // Will be assigned when image is generated
        imageUrl: '', // Will be assigned when image is generated
        
        // üé¨ NUEVOS CAMPOS: Control de referencia del artista
        useArtistReference: scene.use_artist_reference !== false, // Default true for backward compatibility
        referenceUsage: scene.reference_usage || (scene.shot_category === 'PERFORMANCE' ? 'full_performance' : 
                                                   scene.shot_category === 'B-ROLL' ? 'none' : 'story_character'),
        shotCategory: scene.shot_category || 'STORY', // PERFORMANCE | B-ROLL | STORY
        
        // üé≠ NUEVOS CAMPOS: Contexto narrativo para regeneraci√≥n inteligente
        narrativeContext: scene.narrative_context || '',
        lyricConnection: scene.lyric_connection || '',
        visualDescription: scene.visual_description || scene.description || '',
        emotion: scene.emotion || scene.mood || scene.emotional_tone || '',
        storyProgression: scene.story_progression || '',
        musicSection: scene.section || '', // intro, verse, chorus, bridge, outro
        
        // üé• NUEVOS CAMPOS: Especificaciones t√©cnicas de c√°mara
        cameraMovement: scene.camera_movement || 'static',
        lens: scene.lens || 'standard',
        lighting: scene.lighting || 'natural',
        colorGrading: scene.color_grading || 'cinematic',
        location: scene.location || 'performance space',
        lyricsSegment: scene.lyrics || '', // Letra correspondiente
        
        mood: scene.mood || scene.emotional_tone || 'neutral',
        transition: scene.transition || 'cut',
        
        itemProps: {
          style: {
            background: `hsl(${(index * 30) % 360}, 70%, 50%)`,
            border: '1px solid rgba(255,255,255,0.3)',
            borderRadius: '4px',
            color: 'white'
          }
        },
        metadata: {
          scene_id: scene.scene_id,
          section: scene.section,
          shot_type: scene.shot_type || scene.camera?.lens,
          role: scene.role,
          camera: scene.camera,
          lighting: scene.lighting,
          environment: scene.environment,
          performance: scene.performance,
          sound: scene.sound,
          emotional_tone: scene.emotional_tone,
          transition: scene.transition,
          production_notes: scene.production_notes,
          // üÜï Preserve original script fields for debugging
          _original_shot_category: scene.shot_category,
          _original_use_artist_reference: scene.use_artist_reference,
          _original_reference_usage: scene.reference_usage
        }
      });
    });
    
    logger.info(`‚úÖ ${segments.length} clips created from JSON with FULL narrative context`);
    
    // üìä Log resumen de categor√≠as de escenas
    const categories = segments.reduce((acc, s) => {
      const cat = s.shotCategory || 'UNKNOWN';
      acc[cat] = (acc[cat] || 0) + 1;
      return acc;
    }, {} as Record<string, number>);
    logger.info(`üìä Shot categories breakdown: ${JSON.stringify(categories)}`);
    
    // üé§ VALIDACI√ìN: Verificar conexi√≥n LETRA ‚Üî ESCENAS
    const scenesWithLyrics = segments.filter(s => s.lyricsSegment && s.lyricsSegment.trim().length > 0);
    const scenesWithLyricConnection = segments.filter(s => s.lyricConnection && s.lyricConnection.trim().length > 0);
    const scenesWithNarrative = segments.filter(s => s.narrativeContext && s.narrativeContext.trim().length > 0);
    
    logger.info(`üé§ [VALIDATION] Lyrics Integration:`);
    logger.info(`   - Scenes with lyrics segment: ${scenesWithLyrics.length}/${segments.length}`);
    logger.info(`   - Scenes with lyric_connection: ${scenesWithLyricConnection.length}/${segments.length}`);
    logger.info(`   - Scenes with narrative_context: ${scenesWithNarrative.length}/${segments.length}`);
    
    if (scenesWithLyrics.length < segments.length * 0.5) {
      logger.warn(`‚ö†Ô∏è [VALIDATION] Less than 50% of scenes have lyrics - script may not be well connected to the song`);
    }
    
    // Log primeras 3 escenas para debug
    logger.info(`üé¨ [SAMPLE] First 3 scenes narrative summary:`);
    segments.slice(0, 3).forEach((s, i) => {
      logger.info(`   Scene ${i+1}: "${s.lyricsSegment?.substring(0, 40) || 'No lyrics'}..." ‚Üí "${s.lyricConnection?.substring(0, 50) || 'No connection'}..."`);
    });
    
    return segments;
  };

  // New function: Generate full video with payment (30 scenes + FAL)
  const handleGenerateFullVideoWithPayment = async () => {
    if (!transcription || !audioBuffer || !user) {
      toast({
        title: "Error",
        description: "You need transcription, loaded audio and be authenticated",
        variant: "destructive",
      });
      return;
    }

    setIsGeneratingFullVideo(true);
    
    try {
      // Step 1: Generate script with 30 prompts
      toast({
        title: "Generating complete script",
        description: "Creating 30 cinematic scenes...",
      });
      
      const fullScript = await generateMusicVideoPrompts(
        transcription,
        audioBuffer.duration,
        true, // isPaid = true (30 scenes)
        videoStyle.selectedDirector ? {
          name: videoStyle.selectedDirector.name,
          specialty: videoStyle.selectedDirector.specialty,
          style: videoStyle.selectedDirector.style
        } : undefined,
        selectedEditingStyle
      );
      
      logger.info(`‚úÖ Script generated: ${fullScript.total_scenes} scenes`);
      
      // Step 2: Generate images for each scene using Gemini/Flux
      toast({
        title: "Generating images",
        description: `Generating ${fullScript.total_scenes} images with AI...`,
      });
      
      const imagePromises = fullScript.scenes.map(async (scene, index) => {
        try {
          // Use Flux to generate the image
          const result = await fluxService.generateImage({
            prompt: scene.prompt,
            width: 1280,
            height: 720,
            guidance_scale: 3.5,
            steps: 30
          });
          
          logger.info(`‚úÖ Image ${index + 1}/${fullScript.total_scenes} generated`);
          // FluxTaskResult.images is string[] not objects with url
          return result.images?.[0] || '';
        } catch (error) {
          logger.error(`Error generating image ${index + 1}:`, error);
          throw error;
        }
      });
      
      const imageUrls = await Promise.all(imagePromises);
      
      toast({
        title: "Images generated",
        description: `${imageUrls.length} images successfully created`,
      });
      
      // Step 3: Generate videos with FAL
      const isReferenceModel = selectedFalModel.includes('reference-to-video');
      toast({
        title: "Generating videos",
        description: isReferenceModel && artistReferenceImages.length > 0
          ? `Converting ${imageUrls.length} images to video with O1 Reference-to-Video (consistent artist identity)...`
          : `Converting ${imageUrls.length} images to video with ${selectedFalModel}...`,
      });
      
      const scenesWithImages = fullScript.scenes.map((scene, index) => ({
        prompt: scene.prompt,
        imageUrl: imageUrls[index]
      }));
      
      // Pasar im√°genes de referencia del artista para modelos O1
      const videoResults = await generateMultipleVideos(
        selectedFalModel,
        scenesWithImages,
        isReferenceModel && artistReferenceImages.length > 0 ? artistReferenceImages : undefined
      );
      
      const successCount = videoResults.filter(r => r.success).length;
      
      toast({
        title: "Videos generated",
        description: `${successCount}/${videoResults.length} videos successfully generated`,
      });
      
      // Step 4: Save to database
      const videoData = {
        user_id: user?.id,
        song_name: selectedFile?.name || "Music Video",
        video_url: null, // Will be updated when final video is compiled
        thumbnail_url: imageUrls[0],
        duration: audioBuffer.duration,
        is_paid: true,
        amount: 19900, // $199.00 in cents
        status: 'completed',
        metadata: {
          scenes: fullScript.total_scenes,
          model: selectedFalModel,
          video_urls: videoResults.map(r => r.videoUrl)
        }
      };
      
      const response = await fetch('/api/videos/save', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(videoData)
      });
      
      if (!response.ok) {
        throw new Error('Error saving video to database');
      }
      
      const savedVideo = await response.json();
      
      toast({
        title: "Full video generated!",
        description: "Your music video has been saved to your account",
      });
      
      // Update states
      setIsPaidVideo(true);
      setShowMyVideos(true);
      
    } catch (error) {
      logger.error('Error generating full video:', error);
      toast({
        title: "Error",
        description: error instanceof Error ? error.message : "Error generating full video",
        variant: "destructive",
      });
    } finally {
      setIsGeneratingFullVideo(false);
    }
  };

  const generateVideoScriptFromAudio = async () => {
    if (!transcription || timelineItems.length === 0) return;

    setIsGeneratingScript(true);
    try {
      // Extraemos informaci√≥n de los cortes actuales en el timeline
      const timelineInfo = timelineItems.map((item, index) => ({
        id: item.id,
        start_time: item.start_time,
        end_time: item.end_time,
        duration: item.duration
      }));

      // Calculamos duraci√≥n exacta y n√∫mero total de segmentos
      const totalSegments = timelineItems.length;
      const totalDuration = audioBuffer?.duration || 0;

      const prompt = `As a professional music video director, I need you to analyze this song and create a detailed script, perfectly synchronized with the already identified musical cuts.

SONG LYRICS:
${transcription}

TOTAL DURATION: ${totalDuration.toFixed(2)} seconds

MUSICAL CUTS INFORMATION:
${JSON.stringify(timelineInfo, null, 2)}

STRICT SYNCHRONIZATION REQUIREMENTS:
1. You must create EXACTLY ${totalSegments} script segments, one for each predefined musical cut.
2. Each segment must correspond with a specific section of the lyrics that matches the exact time of the cut.
3. If a cut spans an instrumental period without lyrics, specify it is an instrumental moment and describe what should be shown.

SPECIFIC INSTRUCTIONS:
1. LYRICS AND MUSIC ANALYSIS:
   - For each cut, identify what exact part of the lyrics fits its duration
   - Describe the precise musical elements occurring during that cut
   - Point out any changes in rhythm, tone, or instrumentation

2. SYNCHRONIZED VISUAL SCRIPT CREATION:
   - For each segment, relate the scene exactly with the corresponding part of the lyrics
   - Each visual description must reflect the literal or metaphorical meaning of that specific part of the lyrics
   - The shot type and mood must be appropriate for the specific moment of the song

REQUIRED STRUCTURE (exact JSON):
{
  "segments": [
    {
      "id": number (must match the cut ID),
      "timeStart": number (start time in seconds, must match the cut),
      "timeEnd": number (end time in seconds, must match the cut),
      "lyrics": "EXACT part of the lyrics occurring during this time cut",
      "musical_elements": "precise description of musical elements during this cut",
      "description": "detailed visual description that faithfully represents this specific part of the lyrics",
      "imagePrompt": "detailed and specific prompt to generate an image capturing this scene",
      "shotType": "specific shot type (close-up, medium shot, wide shot, etc.)",
      "mood": "precise mood based on this specific part of the lyrics and music",
      "transition": "type of transition to the next segment"
    }
  ]
}

CRUCIAL:
- Each segment must have an ID that exactly matches the ID of the corresponding musical cut
- Start and end times must exactly match the provided musical cuts
- Image prompts must SPECIFICALLY reflect the lyrics content in that exact cut
- The description must explicitly explain how the scene relates to that specific part of the lyrics

COMPLETE SONG LYRICS:
${transcription}`;

      // Validate that the prompt is a text string
      if (typeof prompt !== 'string') {
        throw new Error("The prompt must be a text string");
      }
      
      // Call API to generate script with type validation
      const jsonContent: string = await generateVideoScriptAPI(prompt);

      try {
        // Validate and process response
        let scriptResult;
        try {
          if (typeof jsonContent === 'string') {
            scriptResult = JSON.parse(jsonContent);
          } else {
            throw new Error("The response is not a valid text string");
          }
        } catch (parseError) {
          // Try to extract valid JSON if it's within quotes, markdown, etc.
          const error = parseError as Error;
          logger.error("Error parsing JSON:", error.message);
          
          // Verify jsonContent is a string before using regex
          if (typeof jsonContent === 'string') {
            // Extract a valid JSON object from the response
            try {
              const regex = /\{[\s\S]*"segments"[\s\S]*\}/;
              const match = jsonContent.match(regex);
              if (match && match[0]) {
                scriptResult = JSON.parse(match[0]);
              } else {
                throw new Error("Could not find valid JSON with segments");
              }
            } catch (regexError) {
              logger.error("Error searching for JSON with regex:", regexError);
              throw new Error("Could not extract valid JSON from response");
            }
          } else {
            throw new Error("The response is not a valid text string");
          }
        }

        if (!scriptResult || !scriptResult.segments || !Array.isArray(scriptResult.segments)) {
          throw new Error("Invalid script format: segments array not found");
        }

        // Create a map to search segments by ID efficiently
        const segmentMap = new Map();
        scriptResult.segments.forEach((segment: { id?: number; }) => {
          if (segment && segment.id !== undefined) {
            segmentMap.set(segment.id, segment);
          }
        });

        // Update each timeline element with script information
        const updatedItems = timelineItems.map(item => {
          const scriptSegment = segmentMap.get(item.id);
          
          if (scriptSegment) {
            return {
              ...item,
              description: `Lyrics: "${scriptSegment.lyrics || 'Instrumental'}"\n\nMusic: ${scriptSegment.musical_elements || 'N/A'}\n\nScene: ${scriptSegment.description || 'N/A'}`,
              imagePrompt: `${scriptSegment.imagePrompt || ''} The scene represents these precise lyrics: "${scriptSegment.lyrics || 'Instrumental'}" with musical elements: ${scriptSegment.musical_elements || 'main rhythm'}`,
              shotType: scriptSegment.shotType || 'Medium shot',
              transition: scriptSegment.transition || 'Direct cut',
              mood: scriptSegment.mood || 'Neutral'
            };
          }
          return item;
        });

        setTimelineItems(updatedItems);
        setCurrentStep(4);

        // Save complete script for reference
        setScriptContent(JSON.stringify(scriptResult, null, 2));

        toast({
          title: "Success",
          description: "Synchronized script generated correctly with all musical cuts",
        });

      } catch (parseError) {
        const error = parseError as Error;
        logger.error("Error parsing response:", error);
        logger.error("Response content:", jsonContent);
        throw new Error("Error processing script response: " + error.message);
      }

    } catch (error) {
      logger.error("Error generating script:", error);
      toast({
        title: "Error generating script",
        description: error instanceof Error ? error.message : "Error generating synchronized video script",
        variant: "destructive",
      });
    } finally {
      setIsGeneratingScript(false);
    }
  };

  /**
   * üé¨ MEJORADO: Genera una imagen para un segmento usando prompts ricos en narrativa
   * Usa campos del script para coherencia visual y decide si incluir referencia del artista
   * @param item - El segmento del timeline con campos enriquecidos del script
   * @returns Promise<string> URL de imagen generada o null si hay error
   */
  const generateImageForSegment = async (item: TimelineItem): Promise<string | null> => {
    if (!item.imagePrompt && !item.visualDescription) {
      logger.warn(`Segment ${item.id} has no prompt to generate image`);
      return null;
    }

    try {
      logger.info(`üé® [RICH IMG] Generando imagen para segmento ${item.id}...`);
      
      // üé¨ Construir prompt RICO EN NARRATIVA usando todos los campos del script
      const richPrompt = buildRichCinematicPrompt(item);
      
      // üé≠ Determinar si usar referencia del artista basado en campos del script
      const shouldUseArtistReference = determineArtistReferenceUsage(item);
      
      logger.info(`üé≠ [SCENE ${item.id}] Category: ${item.shotCategory || 'UNKNOWN'}, ` +
                  `Reference Usage: ${item.referenceUsage || 'default'}, ` +
                  `Using Reference: ${shouldUseArtistReference}`);

      // Preparar referencias si corresponde
      let referenceImages: string[] | undefined = undefined;
      if (shouldUseArtistReference) {
        if (masterCharacter?.imageUrl) {
          referenceImages = [masterCharacter.imageUrl];
        } else if (artistReferenceImages.length > 0) {
          referenceImages = artistReferenceImages;
        }
      }
      
      // Build image generation params with enriched context
      const geminiParams: ImageGenerationParams = {
        prompt: richPrompt,
        shotType: item.shotType || 'MS',
        cinematicStyle: item.visualDescription ? 'narrative-driven' : (videoStyle.characterStyle || 'cinematic'),
        mood: item.emotion || item.mood || videoStyle.mood || 'neutral',
        duration: item.duration || 2,
        sceneNumber: typeof item.id === 'string' ? parseInt(item.id, 10) : (item.id as number),
        referenceImages: referenceImages, // Pasar referencias condicionalmente
        directorStyle: videoStyle.selectedDirector?.name || 'Cinematic Director'
      };

      logger.info(`üìù Rich Prompt (${item.shotCategory || 'scene'}): ${richPrompt.substring(0, 150)}...`);
      
      // Usar el endpoint correcto seg√∫n si hay referencias
      let result;
      if (referenceImages && referenceImages.length > 0) {
        // Usar endpoint con referencias faciales
        const response = await fetch('/api/gemini-image/generate-single-with-multiple-faces', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            prompt: richPrompt,
            referenceImagesBase64: referenceImages,
            sceneId: item.id,
            scene: {
              shotCategory: item.shotCategory,
              referenceUsage: item.referenceUsage,
              emotion: item.emotion
            }
          })
        });
        
        if (!response.ok) {
          throw new Error(`HTTP ${response.status}`);
        }
        result = await response.json();
        result = { success: !!result.imageUrl, imageUrl: result.imageUrl, error: result.error };
      } else {
        // Generar sin referencias (B-roll puro)
        result = await generateSceneImageWithGemini(geminiParams);
      }

      if (!result.success || !result.imageUrl) {
        throw new Error(result.error || 'Error generating image');
      }

      logger.info(`‚úÖ Imagen generada exitosamente: ${result.imageUrl.substring(0, 100)}`);

      // Upload to Firebase for persistence
      if (user?.id) {
        logger.info(`üì§ Subiendo imagen a Firebase Storage...`);
        const permanentUrl = await uploadImageFromUrl(result.imageUrl, user.id, projectName);
        logger.info(`‚úÖ Imagen guardada permanentemente en Firebase Storage`);
        return permanentUrl;
      } else {
        logger.warn(`‚ö†Ô∏è No user ID - using temporary URL`);
        return result.imageUrl;
      }

    } catch (error) {
      logger.error(`‚ùå Error generando imagen para segmento ${item.id}:`, error);
      return null;
    }
  };
  
  /**
   * üé¨ Construye un prompt cinematogr√°fico RICO usando todos los campos narrativos del script
   */
  const buildRichCinematicPrompt = (item: TimelineItem): string => {
    const parts: string[] = [];
    
    // 1. Descripci√≥n visual principal (lo m√°s importante)
    const mainDescription = item.visualDescription || item.imagePrompt || item.description || '';
    parts.push(mainDescription);
    
    // 2. Contexto narrativo si existe
    if (item.narrativeContext) {
      parts.push(`Story context: ${item.narrativeContext}`);
    }
    
    // 3. Conexi√≥n con la letra
    if (item.lyricConnection) {
      parts.push(`Lyric connection: ${item.lyricConnection}`);
    }
    
    // 4. Especificaciones t√©cnicas de c√°mara
    const cameraSpecs: string[] = [];
    if (item.shotType) cameraSpecs.push(`${item.shotType} shot`);
    if (item.cameraMovement) cameraSpecs.push(`${item.cameraMovement} movement`);
    if (item.lens) cameraSpecs.push(`${item.lens} lens`);
    if (cameraSpecs.length > 0) {
      parts.push(`Camera: ${cameraSpecs.join(', ')}`);
    }
    
    // 5. Iluminaci√≥n y color
    if (item.lighting) {
      parts.push(`Lighting: ${item.lighting}`);
    }
    if (item.colorGrading) {
      parts.push(`Color grade: ${item.colorGrading}`);
    }
    
    // 6. Emoci√≥n de la escena
    if (item.emotion) {
      parts.push(`Emotion: ${item.emotion}`);
    }
    
    // 7. Ubicaci√≥n
    if (item.location) {
      parts.push(`Location: ${item.location}`);
    }
    
    // 8. Contexto de tipo de escena
    const shotCategory = item.shotCategory || 'STORY';
    if (shotCategory === 'PERFORMANCE') {
      parts.push('Music video performance scene with artist singing/performing');
    } else if (shotCategory === 'B-ROLL') {
      parts.push('Cinematic b-roll visual, atmospheric and artistic, no people in focus');
    } else {
      parts.push('Narrative story scene with strong visual storytelling');
    }
    
    // 9. Calidad profesional
    parts.push('Professional music video quality, cinematic composition, broadcast-ready');
    
    return parts.join('. ');
  };
  
  /**
   * üé≠ Determina si se debe usar la referencia del artista basado en campos del script
   */
  const determineArtistReferenceUsage = (item: TimelineItem): boolean => {
    // Si el script especifica expl√≠citamente NO usar referencia
    if (item.useArtistReference === false) {
      return false;
    }
    
    // Si reference_usage es 'none', no usar referencia
    if (item.referenceUsage === 'none') {
      return false;
    }
    
    // B-ROLL puro normalmente no necesita referencia del artista
    if (item.shotCategory === 'B-ROLL' && !item.useArtistReference) {
      return false;
    }
    
    // Para PERFORMANCE siempre usar referencia
    if (item.shotCategory === 'PERFORMANCE') {
      return true;
    }
    
    // Para STORY, depende del reference_usage
    if (item.shotCategory === 'STORY') {
      return item.referenceUsage === 'story_character' || item.useArtistReference === true;
    }
    
    // Tipos espec√≠ficos que requieren referencia
    const typesRequiringReference = ['full_performance', 'detail_shot', 'alternate_angle', 'story_character'];
    if (item.referenceUsage && typesRequiringReference.includes(item.referenceUsage)) {
      return true;
    }
    
    // Default: usar referencia si est√° disponible (backward compatibility)
    return true;
  };

  /**
   * Waits for image generation to complete in Flux API via polling
   * @param taskId ID of the image generation task
   * @returns URL of generated image or null if it fails
   */
  const waitForFluxImageGeneration = async (taskId: string): Promise<string | null> => {
    const maxAttempts = 40; // Maximum number of attempts to check status
    const pollingInterval = 1500; // Interval between checks (1.5 seconds)
    let attempts = 0;

    // Function to make a single check attempt
    const checkStatus = async (): Promise<string | null> => {
      const statusResult = await fluxService.checkTaskStatus(taskId);
      
      logger.info(`Task ${taskId} status:`, statusResult.status);
      
      if (statusResult.success && statusResult.status === 'completed' && statusResult.images && statusResult.images.length > 0) {
        return statusResult.images[0];
      } else if (!statusResult.success || statusResult.status === 'failed') {
        throw new Error(`Image generation failed: ${statusResult.error || 'Unknown error'}`);
      }
      
      return null; // Still processing
    };

    // Polling loop
    while (attempts < maxAttempts) {
      try {
        const result = await checkStatus();
        if (result) {
          return result; // Image successfully generated
        }
        
        // Wait before next attempt
        await new Promise(resolve => setTimeout(resolve, pollingInterval));
        attempts++;
      } catch (error) {
        logger.error('Error checking generation status:', error);
        return null;
      }
    }

    logger.error(`Timeout expired after ${attempts} attempts for task ${taskId}`);
    return null;
  };

  /**
   * Regenerates the image for a specific segment
   * @param item - The timeline segment whose image will be regenerated
   */
  const regenerateImage = async (item: TimelineItem) => {
    if (!item.imagePrompt) {
      toast({
        title: "Error",
        description: "This segment has no prompt to generate image",
        variant: "destructive",
      });
      return;
    }

    try {
      const imageUrl = await generateImageForSegment(item);
      
      if (imageUrl) {
        const updatedItems = timelineItems.map(timelineItem =>
          timelineItem.id === item.id
            ? { ...timelineItem, generatedImage: imageUrl }
            : timelineItem
        );
        setTimelineItems(updatedItems);

        toast({
          title: "Image regenerated",
          description: "The image has been successfully regenerated",
        });
      } else {
        throw new Error("Could not generate image");
      }
    } catch (error) {
      logger.error("Error regenerating image:", error);
      toast({
        title: "Error",
        description: error instanceof Error ? error.message : "Error regenerating image",
        variant: "destructive",
      });
    }
  };

  /**
   * Regenerate image for a specific clip following the script
   */
  const handleRegenerateImageFromTimeline = async (clipId: number) => {
    const item = timelineItems.find(item => item.id === clipId);
    if (!item) {
      toast({
        title: "Error",
        description: "Scene not found in timeline",
        variant: "destructive",
      });
      return;
    }

    if (!scriptContent) {
      toast({
        title: "Error",
        description: "You need a script first to regenerate the image",
        variant: "destructive",
      });
      return;
    }

    try {
      // Extract scene number from item id
      const sceneMatch = item.id.toString().match(/(\d+)$/);
      if (!sceneMatch) {
        throw new Error("Could not identify scene number");
      }
      
      const sceneNumber = parseInt(sceneMatch[1]);
      
      // Get scene data from script
      const parsedScript = JSON.parse(scriptContent);
      const scenes = parsedScript.scenes || parsedScript;
      const scene = scenes[sceneNumber - 1];
      
      if (!scene) {
        throw new Error("Scene not found in script");
      }

      toast({
        title: "Regenerating image",
        description: `Generating new image for scene ${sceneNumber}...`,
      });

      // Build CONTEXT-RICH prompt using the SAME enriched format as initial generation
      const shotCategory = scene.shot_category || 'STORY';
      const narrativeContext = scene.narrative_context || '';
      const lyricConnection = scene.lyric_connection || '';
      const visualDescription = scene.visual_description || scene.description || scene.scene;
      const emotion = scene.emotion || scene.mood || '';
      const storyProgression = scene.story_progression || '';
      
      // Extract global context from parsed script
      const narrativeSummary = parsedScript.narrative_summary || '';
      const directorName = videoStyle.selectedDirector?.name || 'Cinematic Director';
      const conceptStory = selectedConcept?.story_concept || '';
      
      // Build enriched prompt matching initial generation
      const prompt = `MUSIC VIDEO CONTEXT:
${narrativeSummary ? `Overall Story: ${narrativeSummary}` : ''}
${conceptStory ? `Concept: ${conceptStory}` : ''}
Director Style: ${directorName}

SCENE ${sceneNumber} - ${shotCategory} SHOT:
${visualDescription}

NARRATIVE:
${narrativeContext}

LYRIC CONNECTION:
${lyricConnection}

STORY ARC:
${storyProgression}

EMOTION: ${emotion}

TECHNICAL SPECS:
Camera: ${scene.camera_movement || 'static'}, ${scene.shot_type || 'medium-shot'}
Lighting: ${scene.lighting || 'natural lighting'}
Style: ${scene.visual_style || 'cinematic'}
Shot Type: ${scene.shot_type || 'medium-shot'}
Color Grading: ${scene.color_grading || 'cinematic'}
Location: ${scene.location || 'performance space'}

Professional music video frame, ${shotCategory === 'PERFORMANCE' ? 'featuring the artist performing/singing' : shotCategory === 'B-ROLL' ? 'cinematic b-roll visual WITHOUT the artist visible' : 'narrative story scene with characters/elements'}, high production quality, ${directorName} directorial style, cohesive with overall music video narrative.`;
      
      logger.info(`üîÑ [REGENERATE] Using enriched prompt for scene ${sceneNumber} with category: ${shotCategory}`);
      
      const hasReferenceImages = artistReferenceImages && artistReferenceImages.length > 0;
      
      // Determine if should use artist reference using the advanced logic
      const useArtistReference = scene.use_artist_reference !== false; // Default true for backward compatibility
      const referenceUsage = scene.reference_usage || 
                            (shotCategory === 'PERFORMANCE' ? 'full_performance' : 'none');
      
      const shouldUseReference = useArtistReference && 
                                (referenceUsage !== 'none') &&
                                (masterCharacter || hasReferenceImages);
      
      const referenceToUse = shouldUseReference 
        ? (masterCharacter ? [masterCharacter.imageUrl] : artistReferenceImages)
        : undefined;
      
      logger.info(`üîÑ [REGENERATE ${sceneNumber}] Reference Usage: ${referenceUsage}, Using Reference: ${!!referenceToUse}`);
      
      const endpoint = shouldUseReference
        ? '/api/gemini-image/generate-single-with-multiple-faces'
        : '/api/gemini-image/generate-batch';

      const requestBody = shouldUseReference
        ? { 
            prompt: prompt,
            sceneId: sceneNumber,
            referenceImagesBase64: referenceToUse,
            seed: seed + sceneNumber
          }
        : { scenes: [{ scene: prompt, camera: '', lighting: '', style: '' }] };

      const response = await fetch(endpoint, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(requestBody),
      });

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}));
        throw new Error(errorData.error || `Server error: ${response.statusText}`);
      }

      const data = await response.json();
      
      if (data.success && data.imageUrl) {
        // Upload to Firebase Storage
        let permanentImageUrl = data.imageUrl;
        if (user?.uid) {
          try {
            permanentImageUrl = await uploadImageFromUrl(data.imageUrl, user?.id, projectName);
          } catch (uploadError) {
            logger.warn('Error uploading to Firebase, using temporary URL:', uploadError);
          }
        }

        // Update timeline
        setTimelineItems(prevItems => 
          prevItems.map(timelineItem =>
            timelineItem.id === item.id
              ? {
                  ...timelineItem,
                  imageUrl: permanentImageUrl,
                  thumbnail: permanentImageUrl,
                  url: permanentImageUrl,
                  generatedImage: permanentImageUrl,
                  metadata: {
                    ...timelineItem.metadata,
                    isGeneratedImage: true,
                    imageGeneratedAt: new Date().toISOString(),
                  }
                }
              : timelineItem
          )
        );

        toast({
          title: "Image regenerated!",
          description: `Scene ${sceneNumber} has been successfully regenerated`,
        });
      } else {
        throw new Error(data.error || 'Failed to generate image');
      }
    } catch (error) {
      logger.error("Error regenerating image:", error);
      toast({
        title: "Error",
        description: error instanceof Error ? error.message : "Error regenerating image",
        variant: "destructive",
      });
    }
  };

  /**
   * Generate video from a specific clip image
   */
  const handleGenerateVideoFromTimeline = async (clipId: number) => {
    const item = timelineItems.find(item => item.id === clipId);
    if (!item) {
      toast({
        title: "Error",
        description: "Scene not found in timeline",
        variant: "destructive",
      });
      return;
    }

    const imageUrl = item.imageUrl || item.generatedImage || item.thumbnail;
    if (!imageUrl) {
      toast({
        title: "Error",
        description: "This scene has no image to convert to video",
        variant: "destructive",
      });
      return;
    }

    try {
      const sceneMatch = item.id.toString().match(/(\d+)$/);
      const sceneNumber = sceneMatch ? parseInt(sceneMatch[1]) : 0;

      toast({
        title: "Generating video",
        description: `Converting scene ${sceneNumber} image to video...`,
      });

      // Use FAL AI to generate video from image
      const videoPrompt = item.imagePrompt || item.title || 'Dynamic camera movement';
      
      // Para modelos O1 reference-to-video, pasar las im√°genes de referencia del artista
      const isReferenceModel = selectedFalModel.includes('reference-to-video');
      
      const response = await generateVideoWithFAL(selectedFalModel, {
        imageUrl: imageUrl as string,
        prompt: videoPrompt,
        duration: String(Math.floor(item.duration || 3)) as "5" | "10",
        // Pasar im√°genes de referencia del artista para consistencia (solo O1 reference-to-video)
        referenceImages: isReferenceModel && artistReferenceImages.length > 0 
          ? artistReferenceImages 
          : undefined
      });

      if (response && response.videoUrl) {
        // Update timeline with video
        setTimelineItems(prevItems =>
          prevItems.map(timelineItem =>
            timelineItem.id === item.id
              ? {
                  ...timelineItem,
                  videoUrl: response.videoUrl,
                  metadata: {
                    ...timelineItem.metadata,
                    videoGenerated: true,
                    videoGeneratedAt: new Date().toISOString(),
                  }
                }
              : timelineItem
          )
        );

        toast({
          title: "Video generated!",
          description: `Scene ${sceneNumber} has been successfully converted to video`,
        });
      } else {
        throw new Error('Failed to generate video');
      }
    } catch (error) {
      logger.error("Error generating video:", error);
      toast({
        title: "Error",
        description: error instanceof Error ? error.message : "Error generating video",
        variant: "destructive",
      });
    }
  };

  /**
   * Guardar proyecto en PostgreSQL
   */
  const handleSaveProject = async () => {
    logger.info('üîç [SAVE] Verificando autenticaci√≥n:', { 
      user: user ? 'exists' : 'null', 
      uid: user?.uid || 'undefined',
      email: user?.email || 'undefined'
    });
    
    if (!user) {
      logger.error('‚ùå [SAVE] Usuario no autenticado');
      toast({
        title: "Autenticaci√≥n requerida",
        description: "Por favor inicia sesi√≥n para guardar tu proyecto.",
        variant: "destructive"
      });
      return;
    }
    
    const userEmail = user.email || user?.id;
    
    logger.info('‚úÖ [SAVE] Usuario autenticado:', user.email);

    if (!projectName.trim()) {
      toast({
        title: "Project name required",
        description: "Please enter a name for your project",
        variant: "destructive"
      });
      return;
    }

    setIsSavingProject(true);
    try {
      const imagesGenerated = timelineItems.filter(item => item.generatedImage || item.firebaseUrl).length;
      const videosGenerated = timelineItems.filter(item => item.videoUrl || item.lipsyncVideoUrl).length;
      
      const result = await musicVideoProjectServicePostgres.saveProject({
        userEmail: userEmail,
        projectName,
        audioUrl: audioUrl || undefined,
        audioDuration: audioBuffer?.duration,
        transcription: transcription || undefined,
        scriptContent: scriptContent || undefined,
        timelineItems,
        selectedDirector: videoStyle.selectedDirector ? {
          id: videoStyle.selectedDirector.id || '',
          name: videoStyle.selectedDirector.name || '',
          specialty: videoStyle.selectedDirector.specialty || '',
          style: videoStyle.selectedDirector.style || '',
          experience: videoStyle.selectedDirector.experience || ''
        } : undefined,
        videoStyle: {
          cameraFormat: videoStyle.cameraFormat,
          mood: videoStyle.mood,
          characterStyle: videoStyle.characterStyle,
          colorPalette: videoStyle.colorPalette,
          visualIntensity: videoStyle.visualIntensity,
          narrativeIntensity: videoStyle.narrativeIntensity,
          selectedDirector: videoStyle.selectedDirector
        },
        artistReferenceImages,
        selectedEditingStyle: {
          id: selectedEditingStyle.id,
          name: selectedEditingStyle.name,
          description: selectedEditingStyle.description,
          duration: selectedEditingStyle.duration
        },
        status: videosGenerated === timelineItems.length && timelineItems.length > 0 ? "completed" : 
                imagesGenerated > 0 ? "generating_images" :
                scriptContent ? "generating_script" : "draft",
        progress: {
          scriptGenerated: !!scriptContent,
          imagesGenerated,
          totalImages: timelineItems.length,
          videosGenerated,
          totalVideos: timelineItems.length
        }
      });

      setCurrentProjectId(String(result.project.id));
      toast({
        title: "Project saved",
        description: `"${projectName}" has been ${result.isNew ? 'created' : 'updated'} successfully`
      });
    } catch (error) {
      logger.error('Error saving project:', error);
      toast({
        title: "Error saving project",
        description: "Could not save your project",
        variant: "destructive"
      });
    } finally {
      setIsSavingProject(false);
    }
  };

  /**
   * Cargar proyecto desde PostgreSQL
   */
  const handleLoadProject = async (projectId: string) => {
    if (!user?.uid) return;
    
    try {
      const project = await musicVideoProjectServicePostgres.getProject(Number(projectId));
      if (!project) {
        toast({
          title: "Error",
          description: "Project not found",
          variant: "destructive"
        });
        return;
      }

      setProjectName(project.projectName);
      setCurrentProjectId(String(project.id));
      setAudioUrl(project.audioUrl || null);
      setTranscription(project.transcription || "");
      setScriptContent(project.scriptContent || "");
      setTimelineItems(project.timelineItems);
      setArtistReferenceImages(project.artistReferenceImages || []);
      
      if (project.videoStyle) {
        setVideoStyle(project.videoStyle as any);
      }
      
      if (project.selectedEditingStyle) {
        const editingStyle = editingStyles.find(s => s.id === project.selectedEditingStyle?.id);
        if (editingStyle) {
          setSelectedEditingStyle(editingStyle);
        }
      }
      
      toast({
        title: "Project loaded",
        description: `"${project.projectName}" has been loaded successfully`
      });
    } catch (error) {
      logger.error('Error loading project:', error);
      toast({
        title: "Error loading project",
        description: "Could not load the project",
        variant: "destructive"
      });
    }
  };

  /**
   * Auto-guardado silencioso (sin toast)
   */
  const handleAutoSave = useCallback(async () => {
    if (!user || !projectName.trim() || !hasUnsavedChanges || !autoSaveEnabled) {
      return;
    }

    logger.info('üîÑ Auto-guardando proyecto...');
    
    const userEmail = user.email || user?.id;
    
    try {
      const imagesGenerated = timelineItems.filter(item => item.generatedImage || item.firebaseUrl).length;
      const videosGenerated = timelineItems.filter(item => item.videoUrl || item.lipsyncVideoUrl).length;
      
      const result = await musicVideoProjectServicePostgres.saveProject({
        userEmail: userEmail,
        projectName,
        audioUrl: audioUrl || undefined,
        audioDuration: audioBuffer?.duration,
        transcription: transcription || undefined,
        scriptContent: scriptContent || undefined,
        timelineItems,
        selectedDirector: videoStyle.selectedDirector ? {
          id: videoStyle.selectedDirector.id || '',
          name: videoStyle.selectedDirector.name || '',
          specialty: videoStyle.selectedDirector.specialty || '',
          style: videoStyle.selectedDirector.style || '',
          experience: videoStyle.selectedDirector.experience || ''
        } : undefined,
        videoStyle: {
          cameraFormat: videoStyle.cameraFormat,
          mood: videoStyle.mood,
          characterStyle: videoStyle.characterStyle,
          colorPalette: videoStyle.colorPalette,
          visualIntensity: videoStyle.visualIntensity,
          narrativeIntensity: videoStyle.narrativeIntensity,
          selectedDirector: videoStyle.selectedDirector
        },
        artistReferenceImages,
        selectedEditingStyle: {
          id: selectedEditingStyle.id,
          name: selectedEditingStyle.name,
          description: selectedEditingStyle.description,
          duration: selectedEditingStyle.duration
        },
        status: videosGenerated === timelineItems.length && timelineItems.length > 0 ? "completed" : 
                imagesGenerated > 0 ? "generating_images" :
                scriptContent ? "generating_script" : "draft",
        progress: {
          scriptGenerated: !!scriptContent,
          imagesGenerated,
          totalImages: timelineItems.length,
          videosGenerated,
          totalVideos: timelineItems.length
        }
      });

      setCurrentProjectId(String(result.project.id));
      setLastSavedAt(new Date());
      setHasUnsavedChanges(false);
      logger.info('‚úÖ Auto-guardado completado');
    } catch (error) {
      logger.error('‚ùå Error en auto-guardado:', error);
    }
  }, [user, projectName, hasUnsavedChanges, autoSaveEnabled, timelineItems, audioUrl, audioBuffer, transcription, scriptContent, videoStyle, artistReferenceImages, selectedEditingStyle]);

  /**
   * Detectar cambios no guardados
   */
  useEffect(() => {
    if (timelineItems.length > 0 || transcription || scriptContent) {
      setHasUnsavedChanges(true);
    }
  }, [timelineItems, transcription, scriptContent]);

  /**
   * Auto-guardado cada 30 segundos
   */
  useEffect(() => {
    if (!autoSaveEnabled) return;

    const autoSaveInterval = setInterval(() => {
      handleAutoSave();
    }, 30000); // 30 segundos

    return () => clearInterval(autoSaveInterval);
  }, [handleAutoSave, autoSaveEnabled]);

  /**
   * Atajos de teclado globales
   */
  useEffect(() => {
    const handleKeyDown = (e: KeyboardEvent) => {
      // Ctrl/Cmd + S: Guardar
      if ((e.ctrlKey || e.metaKey) && e.key === 's') {
        e.preventDefault();
        handleSaveProject();
      }
      
      // Ctrl/Cmd + O: Abrir proyecto
      if ((e.ctrlKey || e.metaKey) && e.key === 'o') {
        e.preventDefault();
        setShowLoadProjectDialog(true);
      }
    };

    window.addEventListener('keydown', handleKeyDown);
    return () => window.removeEventListener('keydown', handleKeyDown);
  }, [handleSaveProject]);

  /**
   * Actualizar estado de guardado cuando se guarda manualmente
   */
  useEffect(() => {
    if (!isSavingProject && currentProjectId) {
      setLastSavedAt(new Date());
      setHasUnsavedChanges(false);
    }
  }, [isSavingProject, currentProjectId]);

  /**
   * Batch regenerate images - Regenerar m√∫ltiples im√°genes seleccionadas
   */
  const handleBatchRegenerateImages = useCallback(async () => {
    if (selectedClipIds.length === 0) {
      toast({
        title: "No hay clips seleccionados",
        description: "Selecciona al menos un clip para regenerar",
        variant: "destructive"
      });
      return;
    }

    setIsBatchRegenerating(true);
    
    try {
      let successCount = 0;
      let failCount = 0;

      for (const clipId of selectedClipIds) {
        const item = timelineItems.find(i => i.id === clipId);
        if (!item) continue;

        try {
          logger.info(`üîÑ Regenerando imagen ${clipId}...`);
          
          const promptToUse = item.imagePrompt || item.description || `Scene ${clipId}`;
          
          const response = await fetch('/api/gemini-image/generate-simple', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              prompt: promptToUse,
              seed: Math.floor(Math.random() * 1000000)
            })
          });

          if (!response.ok) throw new Error('Failed to generate image');
          
          const data = await response.json();
          
          if (data.success && data.imageUrl) {
            let permanentImageUrl = data.imageUrl;
            
            if (user?.uid) {
              try {
                permanentImageUrl = await uploadImageFromUrl(data.imageUrl, user?.id, projectName);
              } catch (error) {
                logger.warn('Error uploading to Firebase, using temporary URL:', error);
              }
            }
            
            setTimelineItems(prevItems =>
              prevItems.map(prevItem =>
                prevItem.id === clipId
                  ? {
                      ...prevItem,
                      generatedImage: permanentImageUrl,
                      firebaseUrl: permanentImageUrl,
                      metadata: {
                        ...prevItem.metadata,
                        isGeneratedImage: true
                      }
                    }
                  : prevItem
              )
            );
            
            successCount++;
          } else {
            throw new Error('No image URL returned');
          }
        } catch (error) {
          logger.error(`Error regenerating clip ${clipId}:`, error);
          failCount++;
        }
      }

      toast({
        title: "Regeneraci√≥n completada",
        description: `${successCount} im√°genes regeneradas exitosamente${failCount > 0 ? `, ${failCount} fallaron` : ''}`,
      });

      // Limpiar selecci√≥n
      setSelectedClipIds([]);
    } catch (error) {
      logger.error('Error in batch regeneration:', error);
      toast({
        title: "Error",
        description: "Error al regenerar im√°genes",
        variant: "destructive"
      });
    } finally {
      setIsBatchRegenerating(false);
    }
  }, [selectedClipIds, timelineItems, user, projectName, toast]);

  /**
   * Generar video individual para una escena
   */
  const handleGenerateIndividualVideo = async (modelId: string, sceneId?: number) => {
    if (!sceneId) {
      toast({
        title: "Error",
        description: "Please select a scene from the timeline",
        variant: "destructive"
      });
      return;
    }
    
    const scene = timelineItems.find(item => item.id === sceneId);
    if (!scene || (!scene.generatedImage && !scene.imageUrl && !scene.firebaseUrl)) {
      toast({
        title: "Cannot generate video",
        description: "Scene must have a generated image first",
        variant: "destructive"
      });
      return;
    }

    const imageUrl = (scene.generatedImage || scene.imageUrl || scene.firebaseUrl || '') as string;

    setIsGeneratingVideos(true);
    try {
      const prompt = scene.imagePrompt || scene.description || "Cinematic video animation";
      
      const result = await generateVideoWithFAL(modelId, {
        prompt,
        imageUrl,
        duration: "5",
        aspectRatio: "16:9"
      });

      if (result.success && result.videoUrl) {
        const updatedItems = timelineItems.map(item =>
          item.id === sceneId
            ? { ...item, videoUrl: result.videoUrl }
            : item
        );
        setTimelineItems(updatedItems);

        toast({
          title: "Video generated",
          description: `Video for scene ${sceneId} has been generated successfully`
        });
      } else {
        throw new Error(result.error || "Failed to generate video");
      }
    } catch (error) {
      logger.error('Error generating video:', error);
      toast({
        title: "Error generating video",
        description: error instanceof Error ? error.message : "Could not generate video",
        variant: "destructive"
      });
    } finally {
      setIsGeneratingVideos(false);
    }
  };

  /**
   * Generar videos para todas las escenas
   */
  const handleGenerateAllVideos = async (modelId: string) => {
    const scenesWithImages = timelineItems.filter(item => item.generatedImage);
    
    if (scenesWithImages.length === 0) {
      toast({
        title: "No images to animate",
        description: "Please generate images first",
        variant: "destructive"
      });
      return;
    }

    setIsGeneratingVideos(true);
    setVideoGenerationProgress({ current: 0, total: scenesWithImages.length });

    try {
      const scenes = scenesWithImages.map(item => ({
        prompt: item.imagePrompt || item.description || "Cinematic video animation",
        imageUrl: (item.generatedImage || item.firebaseUrl || "") as string
      }));

      const results = await generateMultipleVideos(modelId, scenes);

      let successCount = 0;
      const updatedItems = [...timelineItems];

      results.forEach((result, index) => {
        setVideoGenerationProgress({ current: index + 1, total: scenesWithImages.length });
        
        if (result.success && result.videoUrl) {
          const originalScene = scenesWithImages[index];
          const itemIndex = updatedItems.findIndex(item => item.id === originalScene.id);
          if (itemIndex !== -1) {
            updatedItems[itemIndex] = {
              ...updatedItems[itemIndex],
              videoUrl: result.videoUrl
            };
            successCount++;
          }
        }
      });

      setTimelineItems(updatedItems);
      
      toast({
        title: "Videos generated",
        description: `Successfully generated ${successCount} out of ${scenesWithImages.length} videos`
      });
    } catch (error) {
      logger.error('Error generating videos:', error);
      toast({
        title: "Error generating videos",
        description: error instanceof Error ? error.message : "Could not generate videos",
        variant: "destructive"
      });
    } finally {
      setIsGeneratingVideos(false);
      setVideoGenerationProgress({ current: 0, total: 0 });
    }
  };

  // Calculamos un estimado de duraci√≥n antes de generar los clips
  // para evitar la dependencia circular
  const estimatedDuration = useMemo(() => {
    // Si tenemos audioBuffer, usamos su duraci√≥n como fuente principal
    if (audioBuffer) {
      return audioBuffer.duration;
    }
    
    // Si tenemos items de timeline, calculamos la duraci√≥n en base a ellos
    if (timelineItems.length > 0) {
      const lastItem = timelineItems[timelineItems.length - 1];
      return (lastItem.end_time - timelineItems[0].start_time) / 1000; // Convertir a segundos
    }
    
    // Duraci√≥n predeterminada si no hay otras fuentes
    return 180; // 3 minutos por defecto
  }, [audioBuffer, timelineItems]);

  // Auto-guardar proyecto cada 5 segundos cuando hay cambios
  useEffect(() => {
    if (user?.uid && projectName && timelineItems.length > 0 && audioUrl) {
      musicVideoProjectService.autoSave(
        user?.id,
        projectName,
        {
          audioUrl,
          timelineItems,
          artistReferences: artistReferenceImages,
          editingStyle: selectedEditingStyle.id,
          duration: estimatedDuration
        },
        currentProjectId
      );
    }
  }, [user?.uid, projectName, timelineItems, audioUrl, artistReferenceImages, selectedEditingStyle, currentProjectId, estimatedDuration]);

  const generateTimelineItems = useCallback((shots: { duration?: string; shotType: string; description: string; imagePrompt?: string; transition?: string }[]) => {
    const baseTime = Date.now();
    let currentTime = baseTime;

    const items = shots.map((shot, index) => {
      const duration = shot.duration ? parseFloat(shot.duration) * 1000 : Math.floor(Math.random() * (5000 - 1000) + 1000);
      const item: TimelineItem = {
        id: index + 1,
        group: 1,
        title: shot.shotType,
        start_time: currentTime,
        end_time: currentTime + duration,
        description: shot.description,
        shotType: shot.shotType,
        imagePrompt: shot.imagePrompt,
        generatedImage: undefined,
        duration: duration,
        transition: shot.transition || "cut",
        // Campos necesarios para compatibilidad con TimelineClip
        start: (currentTime - baseTime) / 1000,
        type: 'image',
        thumbnail: undefined,
        mood: 'neutral'
      };
      currentTime += duration;
      return item;
    });

    setTimelineItems(items);
    setVisibleTimeStart(baseTime);
    setVisibleTimeEnd(currentTime);
    setZoomLevel(1);
  }, []);

  const handleTimeChange = (visibleTimeStart: number, visibleTimeEnd: number) => {
    setVisibleTimeStart(visibleTimeStart);
    setVisibleTimeEnd(visibleTimeEnd);
  };

  const togglePlayback = useCallback(() => {
    if (!audioBuffer || !audioContext.current) return;

    if (isPlaying) {
      audioSource.current?.stop();
      setIsPlaying(false);
    } else {
      const source = audioContext.current.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(audioContext.current.destination);
      source.start(0, currentTime / 1000);
      audioSource.current = source;
      setIsPlaying(true);
    }
  }, [isPlaying, audioBuffer, currentTime]);

  const handleZoomIn = () => {
    setZoomLevel(prev => Math.min(prev * 1.5, 10));
  };

  const handleZoomOut = () => {
    setZoomLevel(prev => Math.max(prev / 1.5, 0.1));
  };

  const handleReset = () => {
    if (timelineItems.length > 0) {
      setCurrentTime(timelineItems[0].start_time);
      setIsPlaying(false);
    }
  };

  const handleSkipForward = () => {
    if (timelineItems.length > 0) {
      const currentIndex = timelineItems.findIndex(item => item.start_time > currentTime);
      if (currentIndex !== -1) {
        setCurrentTime(timelineItems[currentIndex].start_time);
      }
    }
  };

  const handleSkipBackward = () => {
    if (timelineItems.length > 0) {
      const currentIndex = timelineItems.findIndex(item => item.end_time > currentTime) - 1;
      if (currentIndex >= 0) {
        setCurrentTime(timelineItems[currentIndex].start_time);
      } else {
        setCurrentTime(timelineItems[0].start_time);
      }
    }
  };

  const saveToFirebase = async (item: TimelineItem) => {
    if (!item.generatedImage) return null;

    try {
      // Make sure generatedImage is a valid URL (string)
      const imageUrl = typeof item.generatedImage === 'string' ? item.generatedImage : '';
      if (!imageUrl) return null;
      
      const response = await fetch(imageUrl);
      const blob = await response.blob();

      const storageRef = ref(storage, `videos/${Date.now()}_${item.id}.jpg`);
      await uploadBytes(storageRef, blob);
      const url = await getDownloadURL(storageRef);

      return url;
    } catch (error) {
      logger.error("Error saving to Firebase:", error);
      return null;
    }
  };

  /**
   * Generates images for all segments that have prompts
   * Processes segments in parallel in batches to optimize time
   */
  const generateShotImages = async () => {
    if (timelineItems.length === 0) {
      toast({
        title: "Error",
        description: "No segments to generate images",
        variant: "destructive",
      });
      return;
    }

    // Verify there are generated prompts
    const itemsWithoutPrompts = timelineItems.filter(item => !item.imagePrompt).length;
    if (itemsWithoutPrompts === timelineItems.length) {
      toast({
        title: "Error",
        description: "Segments have no prompts to generate images",
        variant: "destructive",
      });
      return;
    }

    if (itemsWithoutPrompts > 0) {
      toast({
        title: "Warning",
        description: `${itemsWithoutPrompts} segments have no prompts and will be skipped`,
        variant: "default",
      });
    }

    setIsGeneratingShots(true);
    
    // ‚úÖ ELIMINADO L√çMITE: Generar im√°genes para TODOS los segmentos con prompts
    const items = timelineItems
      .filter(item => item.imagePrompt && !item.generatedImage);
    
    logger.info(`üé® Generando im√°genes para ${items.length} segmentos (de ${timelineItems.length} totales)`);

    if (items.length === 0) {
      toast({
        title: "Information",
        description: "All segments already have generated images",
      });
      setIsGeneratingShots(false);
      return;
    }
    
    // Advertir si hay muchas im√°genes por generar
    if (items.length > 20) {
      logger.info(`‚è±Ô∏è Generando ${items.length} im√°genes - esto puede tomar varios minutos...`);
    }

    // Inicializar progreso
    setGenerationProgress({
      current: 0,
      total: items.length,
      percentage: 0,
      currentPrompt: items[0]?.imagePrompt || '',
      generatedImages: [],
      status: 'Preparando generaci√≥n...'
    });

    try {
      let successCount = 0;
      let failCount = 0;

      // Process in batches of 2 to balance speed and stability
      const batchSize = 2;
      
      for (let i = 0; i < items.length; i += batchSize) {
        const currentBatch = items.slice(i, i + batchSize);
        
        try {
          // Actualizar estado antes de procesar el batch
          const batchNumber = Math.floor(i/batchSize) + 1;
          const totalBatches = Math.ceil(items.length/batchSize);
          
          setGenerationProgress(prev => ({
            ...prev,
            status: `Procesando lote ${batchNumber} de ${totalBatches}...`,
            currentPrompt: currentBatch[0]?.imagePrompt || ''
          }));

          // Generate images for current batch - SECUENCIALMENTE para mostrar progreso en tiempo real
          const results = [];
          
          for (let batchIndex = 0; batchIndex < currentBatch.length; batchIndex++) {
            const item = currentBatch[batchIndex];
            const globalIndex = i + batchIndex;
            
            try {
              // Actualizar progreso ANTES de generar
              setGenerationProgress(prev => ({
                ...prev,
                status: `Generando imagen ${globalIndex + 1} de ${items.length}...`,
                currentPrompt: item.imagePrompt || ''
              }));

              // Generar la imagen (ahora retorna URL permanente de Firebase)
              const imageUrl = await generateImageForSegment(item);
              
              // Actualizar timeline inmediatamente con URL permanente
              setTimelineItems(prev => prev.map(timelineItem => 
                timelineItem.id === item.id 
                  ? { 
                      ...timelineItem, 
                      generatedImage: imageUrl as string,
                      firebaseUrl: imageUrl as string  // Tambi√©n guardar en firebaseUrl para persistencia
                    } 
                  : timelineItem
              ));
              
              successCount++;
              
              // Actualizar galer√≠a del modal INMEDIATAMENTE
              setGenerationProgress(prev => ({
                ...prev,
                current: successCount,
                percentage: Math.round((successCount / items.length) * 100),
                status: `‚úÖ Imagen ${globalIndex + 1} completada`,
                generatedImages: [...prev.generatedImages, {
                  id: String(item.id),
                  url: imageUrl as string,
                  prompt: item.imagePrompt || ''
                }]
              }));
              
              results.push({
                id: item.id,
                success: true,
                url: imageUrl,
                prompt: item.imagePrompt || ''
              });
              
              // Peque√±a pausa para que el usuario vea la imagen aparecer
              await new Promise(resolve => setTimeout(resolve, 500));
              
            } catch (error) {
              logger.error(`Error in generation for segment ${item.id}:`, error);
              failCount++;
              
              results.push({
                id: item.id,
                success: false,
                error: error instanceof Error ? error.message : "Unknown error",
                prompt: item.imagePrompt || ''
              });
            }
          }
          
          // Wait between batches to avoid rate limits
          if (i + batchSize < items.length) {
            await new Promise(resolve => setTimeout(resolve, 2000));
          }
        } catch (batchError) {
          logger.error(`Error processing batch ${Math.floor(i/batchSize) + 1}:`, batchError);
          failCount++;
        }
      }

      // Mostrar resultado final
      if (successCount > 0) {
        toast({
          title: "Proceso completado",
          description: `Se generaron ${successCount} de ${items.length} im√°genes ${failCount > 0 ? `(${failCount} fallaron)` : ''}`,
        });
        
        if (successCount >= 1) { // Mostrar vista previa incluso si solo se gener√≥ una imagen
          // Generar ID √∫nico para este video
          const videoId = `video_${Date.now()}`;
          
          // Guardar el videoId en el estado para usarlo en la generaci√≥n del video
          setVideoId(videoId);
          
          // Calcular duraci√≥n total en segundos
          const calculateTotalDuration = () => {
            if (timelineItems.length === 0) return 0;
            const lastItem = timelineItems[timelineItems.length - 1];
            return lastItem.end_time / 1000; // Convertir a segundos
          };
          
          // Extraer palabras clave del primer segmento o usar etiquetas predeterminadas
          const extractTags = () => {
            const firstSegment = timelineItems[0];
            if (firstSegment && firstSegment.description) {
              return firstSegment.description
                .split(' ')
                .filter(word => word.length > 5)
                .slice(0, 5);
            }
            return ['m√∫sica', 'video', 'artista', 'canci√≥n', 'generado'];
          };
          
          // Crear un documento de video en Firestore para futuras referencias
          try {
            const videoRef = collection(db, 'videos');
            await addDoc(videoRef, {
              id: videoId,
              userId: user?.uid,
              title: songTitle || 'Video Musical Generado',
              status: 'preview', // Inicialmente solo vista previa
              createdAt: serverTimestamp(),
              updatedAt: serverTimestamp(),
              duration: duration || calculateTotalDuration(),
              thumbnailUrl: timelineItems.find(item => item.generatedImage)?.generatedImage || '',
              tags: extractTags(),
            });
          } catch (error) {
            logger.error('Error guardando informaci√≥n del video:', error);
          }
          
          setCurrentStep(5); // Avanzar al siguiente paso
          
          // üé¨ AUTO-CONVERT: After generating images, auto-convert to videos for free preview
          if (!hasUserPaid && successCount >= FREE_SCENES_LIMIT) {
            logger.info('üé¨ [FREE PREVIEW] Starting auto-conversion to videos...');
            toast({
              title: "üé¨ Creating Video Preview",
              description: "Converting your images to video clips with lipsync...",
            });
            
            // Auto-start video conversion for free preview
            setTimeout(() => {
              handleAutoConvertToVideos();
            }, 2000);
          }
        }
      } else {
        toast({
          title: "Error",
          description: "No se pudo generar ninguna imagen",
          variant: "destructive",
        });
      }

    } catch (error) {
      logger.error("Error en el proceso de generaci√≥n:", error);
      toast({
        title: "Error general",
        description: error instanceof Error ? error.message : "Error en el proceso de generaci√≥n de im√°genes",
        variant: "destructive",
      });
    } finally {
      setIsGeneratingShots(false);
    }
  };
  
  /**
   * üé¨ AUTO-CONVERT: Converts free preview images to videos with lipsync
   * - PERFORMANCE scenes get PixVerse lipsync
   * - B-ROLL and STORY scenes get Kling video generation
   */
  const handleAutoConvertToVideos = async () => {
    const itemsWithImages = timelineItems.filter(item => item.generatedImage || item.firebaseUrl);
    
    if (itemsWithImages.length === 0) {
      logger.warn('‚ö†Ô∏è No images to convert to videos');
      return;
    }
    
    setIsGeneratingVideos(true);
    setVideoGenerationProgress({ current: 0, total: itemsWithImages.length });
    
    logger.info(`üé¨ [AUTO-CONVERT] Converting ${itemsWithImages.length} images to videos...`);
    logger.info(`üìê Aspect ratio: ${videoAspectRatio}`);
    
    try {
      // Detect PERFORMANCE clips for lipsync
      const performanceClips = detectPerformanceClips(itemsWithImages);
      const brollAndStoryClips = itemsWithImages.filter(item => 
        item.shotCategory !== 'PERFORMANCE' || !performanceClips.includes(item)
      );
      
      logger.info(`üé§ Performance clips for lipsync: ${performanceClips.length}`);
      logger.info(`üé¨ B-roll/Story clips for video: ${brollAndStoryClips.length}`);
      
      let processedCount = 0;
      
      // Process PERFORMANCE clips: First generate video, then apply lipsync
      if (performanceClips.length > 0 && audioUrl) {
        setLipSyncProgress({ current: 0, total: performanceClips.length, message: 'Processing performance scenes with lipsync...' });
        
        for (const clip of performanceClips) {
          try {
            const imageUrl = clip.generatedImage || clip.firebaseUrl || clip.imageUrl;
            if (!imageUrl) continue;
            
            // Get segment duration in seconds
            const segmentDuration = (clip.duration || 3500) / 1000;
            
            // STEP 1: Generate video from image using Kling (for consistent character)
            logger.info(`üé¨ [PERF ${clip.id}] Step 1: Generating video from image...`);
            const videoResult = await generateVideoWithFAL(selectedVideoModel, {
              imageUrl: imageUrl,
              prompt: `${clip.imagePrompt || clip.visualDescription || 'Artist performing'}, singing, emotional performance`,
              aspectRatio: videoAspectRatio,
              duration: segmentDuration
            });
            
            if (!videoResult.success || !videoResult.videoUrl) {
              logger.error(`‚ùå Video generation failed for clip ${clip.id}`);
              continue;
            }
            
            // STEP 2: Apply PixVerse lipsync to the generated video
            logger.info(`üé§ [PERF ${clip.id}] Step 2: Applying PixVerse lipsync...`);
            const lipsyncResult = await applyPixVerseLipsync({
              videoUrl: videoResult.videoUrl, // Use the generated VIDEO, not image
              audioUrl: audioUrl
            });
            
            // Use lipsync result if successful, otherwise use original video
            const finalVideoUrl = (lipsyncResult.success && lipsyncResult.videoUrl) 
              ? lipsyncResult.videoUrl 
              : videoResult.videoUrl;
            
            // Update timeline item with video URL
            setTimelineItems(prev => prev.map(item =>
              item.id === clip.id
                ? { 
                    ...item, 
                    generatedVideo: finalVideoUrl, 
                    type: 'video' as const,
                    hasLipsync: lipsyncResult.success 
                  }
                : item
            ));
            
            processedCount++;
            setVideoGenerationProgress({ current: processedCount, total: itemsWithImages.length });
            setLipSyncProgress({ current: processedCount, total: performanceClips.length, message: `Processed ${processedCount} performance scenes` });
            
          } catch (error) {
            logger.error(`‚ùå Performance processing failed for clip ${clip.id}:`, error);
          }
        }
      }
      
      // Process B-ROLL and STORY clips with Kling video generation (no lipsync needed)
      for (const clip of brollAndStoryClips) {
        try {
          const imageUrl = clip.generatedImage || clip.firebaseUrl || clip.imageUrl;
          if (!imageUrl) continue;
          
          // Generate video from image using Kling
          const videoResult = await generateVideoWithFAL(selectedVideoModel, {
            imageUrl: imageUrl,
            prompt: clip.imagePrompt || clip.visualDescription || 'Cinematic video with subtle movement',
            aspectRatio: videoAspectRatio,
            duration: (clip.duration || 3500) / 1000
          });
          
          if (videoResult.success && videoResult.videoUrl) {
            setTimelineItems(prev => prev.map(item =>
              item.id === clip.id
                ? { ...item, generatedVideo: videoResult.videoUrl, type: 'video' as const }
                : item
            ));
            processedCount++;
            setVideoGenerationProgress({ current: processedCount, total: itemsWithImages.length });
          }
        } catch (error) {
          logger.error(`‚ùå Video generation failed for clip ${clip.id}:`, error);
        }
      }
      
      logger.info(`‚úÖ [AUTO-CONVERT] Completed: ${processedCount}/${itemsWithImages.length} videos created`);
      
      // Show payment gate after free preview is complete
      if (!hasUserPaid && processedCount > 0) {
        toast({
          title: "üé¨ Preview Ready!",
          description: `${processedCount} video clips created. Unlock the full video for $${FULL_VIDEO_PRICE}!`,
        });
        
        // Delay then show payment gate
        setTimeout(() => {
          setShowPaymentGate(true);
        }, 3000);
      }
      
    } catch (error) {
      logger.error('‚ùå Auto-convert failed:', error);
      toast({
        title: "Error",
        description: "Failed to convert images to videos",
        variant: "destructive",
      });
    } finally {
      setIsGeneratingVideos(false);
    }
  };

  /**
   * Exporta el video generado usando Shotstack API para renderizado real
   * @returns Promise<string> URL del video generado en Firebase Storage
   */
  const handleExportVideo = async (): Promise<string | null> => {
    if (!timelineItems.length || !audioBuffer) {
      toast({
        title: "Error",
        description: "No hay suficientes elementos para exportar el video",
        variant: "destructive",
      });
      return null;
    }
    
    // Verificar que todos los segmentos tengan im√°genes o videos generados
    const validItems = timelineItems.filter(item => 
      item.generatedVideo || item.firebaseVideoUrl || item.generatedImage || item.firebaseUrl
    );
    
    if (validItems.length === 0) {
      toast({
        title: "Error",
        description: "No hay elementos generados para exportar",
        variant: "destructive",
      });
      return null;
    }
    
    setIsExporting(true);
    setExportProgress(0);
    setExportStatus('Preparando clips...');
    
    try {
      // 1. Asegurar que todas las im√°genes est√©n en Firebase
      logger.log('üì§ [EXPORT] Guardando assets en Firebase...');
      const savePromises = timelineItems.map(async (item) => {
        // Priorizar video sobre imagen
        if (item.generatedVideo || item.firebaseVideoUrl) {
          return {
            id: item.id,
            videoUrl: item.firebaseVideoUrl || item.generatedVideo,
            imageUrl: undefined,
            start: item.startTime / 1000, // Convertir ms a segundos
            duration: item.duration / 1000,
          };
        }
        
        // Si no hay video, usar imagen
        if (item.generatedImage && !item.firebaseUrl) {
          const url = await saveToFirebase(item);
          return {
            id: item.id,
            videoUrl: undefined,
            imageUrl: url || item.generatedImage,
            start: item.startTime / 1000,
            duration: item.duration / 1000,
          };
        }
        
        return {
          id: item.id,
          videoUrl: undefined,
          imageUrl: item.firebaseUrl || item.generatedImage,
          start: item.startTime / 1000,
          duration: item.duration / 1000,
        };
      });
      
      const clips = await Promise.all(savePromises);
      setExportProgress(10);
      setExportStatus('Iniciando renderizado...');
      
      // 2. Iniciar renderizado con Shotstack
      logger.log('üé¨ [EXPORT] Iniciando renderizado con Shotstack...');
      const renderResponse = await fetch('/api/video-rendering/start', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          projectId: currentProjectId ? parseInt(currentProjectId) : undefined,
          userId: user?.uid,
          clips: clips.filter(c => c.videoUrl || c.imageUrl),
          audioUrl: audioUrl || undefined,
          audioDuration: estimatedDuration / 1000,
          resolution: '1080p',
          quality: 'high',
          aspectRatio: videoAspectRatio,
        }),
      });
      
      const renderData = await renderResponse.json();
      
      if (!renderData.success || !renderData.renderId) {
        throw new Error(renderData.error || 'Error al iniciar renderizado');
      }
      
      const renderId = renderData.renderId;
      logger.log(`‚úÖ [EXPORT] Renderizado iniciado: ${renderId}`);
      setExportProgress(20);
      setExportStatus('Procesando video...');
      
      // 3. Polling para verificar estado del renderizado
      const pollInterval = 3000; // 3 segundos
      const maxAttempts = 120; // Max 6 minutos (120 * 3s)
      let attempts = 0;
      
      const checkStatus = async (): Promise<string | null> => {
        while (attempts < maxAttempts) {
          attempts++;
          
          const statusResponse = await fetch(
            `/api/video-rendering/status/${renderId}?projectId=${currentProjectId}&userId=${user?.uid}`
          );
          const statusData = await statusResponse.json();
          
          if (!statusData.success) {
            if (statusData.status === 'failed') {
              throw new Error('El renderizado fall√≥');
            }
            // Continuar polling si hay error temporal
          }
          
          // Actualizar progreso
          const progress = statusData.progress || 0;
          setExportProgress(20 + Math.round(progress * 0.7)); // 20-90%
          
          switch (statusData.status) {
            case 'queued':
              setExportStatus('En cola de renderizado...');
              break;
            case 'processing':
              setExportStatus(`Renderizando video... ${progress}%`);
              break;
            case 'done':
              setExportProgress(100);
              setExportStatus('¬°Video listo!');
              // Devolver URL de Firebase (o Shotstack si Firebase fall√≥)
              return statusData.firebaseUrl || statusData.url;
            case 'failed':
              throw new Error('El renderizado fall√≥');
          }
          
          // Esperar antes de siguiente verificaci√≥n
          await new Promise(resolve => setTimeout(resolve, pollInterval));
        }
        
        throw new Error('Timeout: El renderizado tard√≥ demasiado');
      };
      
      const finalVideoUrl = await checkStatus();
      
      if (!finalVideoUrl) {
        throw new Error('No se recibi√≥ URL del video');
      }
      
      logger.log(`üéâ [EXPORT] Video exportado exitosamente: ${finalVideoUrl}`);
      
      toast({
        title: "¬°Exportaci√≥n completada!",
        description: "Tu video est√° listo para descargar",
      });
      
      setCurrentStep(6); // Marcar como completado
      
      return finalVideoUrl;
      
    } catch (error) {
      logger.error("Error exportando video:", error);
      toast({
        title: "Error en exportaci√≥n",
        description: error instanceof Error ? error.message : "Error al exportar el video",
        variant: "destructive",
      });
      return null;
    } finally {
      setIsExporting(false);
      setExportProgress(0);
      setExportStatus('');
    }
  };

  const handleScriptChange = (value: string | undefined) => {
    if (!value) return;
    setScriptContent(value);
    try {
      const scriptData = JSON.parse(value);
      
      // Extraer las escenas del formato correcto
      let scenesData = [];
      if (scriptData.scenes && Array.isArray(scriptData.scenes)) {
        // Nuevo formato: { scenes: [...] }
        scenesData = scriptData.scenes;
      } else if (scriptData.segments && Array.isArray(scriptData.segments)) {
        // Formato intermedio
        scenesData = scriptData.segments;
      } else if (scriptData.shots && Array.isArray(scriptData.shots)) {
        // Formato antiguo
        scenesData = scriptData.shots;
      }
      
      // Compatibilidad con diferentes formatos de script
      if (scriptData.shots && Array.isArray(scriptData.shots)) {
        // Formato anterior
        generateTimelineItems(scriptData.shots);
      } else if (scenesData.length > 0) {
        // Nuevo formato de script desde generateMusicVideoScript
        const shotItems = scenesData.map((segment: any) => ({
          shotType: segment.tipo_plano || segment.shotType || "Plano medio",
          description: segment.descripci√≥n_visual || segment.description || "",
          imagePrompt: segment.imagePrompt || "",
          transition: segment.transici√≥n || segment.transition || "corte directo",
          duration: typeof segment.duration === 'number' ? String(segment.duration) : "3"
        }));
        generateTimelineItems(shotItems);
      } else if (scriptData.segmentos && Array.isArray(scriptData.segmentos)) {
        // Formato en espa√±ol
        const shotItems = scriptData.segmentos.map((segmento: any) => ({
          shotType: segmento.tipo_plano || "Plano medio",
          description: segmento.descripci√≥n_visual || "",
          imagePrompt: `Escena musical: ${segmento.descripci√≥n_visual || ""}. Estilo: ${segmento.mood || "neutral"}`,
          transition: segmento.transici√≥n || "corte directo",
          duration: typeof segmento.duration === 'number' ? String(segmento.duration) : "3"
        }));
        generateTimelineItems(shotItems);
      } else {
        logger.warn("Formato de script no reconocido:", scriptData);
      }
    } catch (error) {
      logger.error("Error parsing script:", error);
      toast({
        title: "Error de formato",
        description: "El script no tiene un formato JSON v√°lido",
        variant: "destructive"
      });
    }
  };

  const itemRenderer = useCallback(({ item, itemContext, getItemProps }: any) => (
    <div
      {...getItemProps()}
      className="relative h-full cursor-pointer group"
      onMouseEnter={() => setHoveredShot(item)}
      onMouseLeave={() => setHoveredShot(null)}
      onClick={() => setSelectedShot(item)}
    >
      <div className={cn(
        "absolute inset-0 bg-card rounded-md border overflow-hidden",
        "transition-all duration-200 ease-in-out",
        currentTime >= item.start_time && currentTime < item.end_time ? "ring-2 ring-orange-500" : "",
        selectedShot?.id === item.id ? "ring-2 ring-blue-500" : "",
        "hover:scale-[1.02] hover:z-10"
      )}>
        <div className="absolute inset-0">
          <img
            src={item.generatedImage || item.firebaseUrl || fallbackImage}
            alt={item.description}
            className="w-full h-full object-cover"
          />
          <div className="absolute inset-0 bg-black/40 p-2 flex flex-col justify-between opacity-0 group-hover:opacity-100 transition-opacity">
            <div>
              <p className="text-xs font-medium text-white truncate">
                {item.shotType}
              </p>
              <p className="text-xs text-white/80 truncate">
                {item.description}
              </p>
            </div>
            <div className="flex items-center justify-between text-xs text-white/60">
              <span>{(item.duration / 1000).toFixed(1)}s</span>
              <span>{item.transition}</span>
            </div>
          </div>
        </div>

        {item.transition && item.transition !== "cut" && (
          <div className="absolute -right-2 top-1/2 -translate-y-1/2 w-4 h-4 bg-orange-500/20 rounded-full z-10">
            <div className="absolute inset-1 bg-orange-500 rounded-full" />
          </div>
        )}
      </div>
    </div>
  ), [currentTime, selectedShot]);

  // Mapa de clips organizados por capas para el editor profesional multicanal
  const clips: TimelineClip[] = useMemo(() => {
    logger.info("üé¨ Generando clips para timeline editor, items:", timelineItems.length);
    
    // Asegurar que siempre hay un clip de audio en la capa 0 si existe audioUrl
    const audioClips = audioUrl ? [
      ensureCompatibleClip({
        id: 9999, // ID especial para audio principal
        start: 0,
        duration: estimatedDuration, // Usamos la duraci√≥n estimada
        type: 'audio' as const,
        layer: 0, // Capa de audio (0)
        title: 'Audio Principal',
        description: 'Pista de audio importada',
        audioUrl: audioUrl,
        visible: true,
        locked: false
      })
    ] : [];
    
    logger.info("üîä Audio importado:", audioUrl ? "SI" : "NO");
    
    // Mapear los items de timeline a clips visuales
    const visualClips = timelineItems.map(item => {
      // Determinar el tipo de clip basado en sus propiedades
      let clipType: 'video' | 'image' | 'transition' | 'audio' | 'effect' | 'text' = 'image';
      let clipLayer = 1; // Por defecto, capa de imagen (1)
      
      // Si tiene audioUrl, es un clip de audio adicional
      if (item.audioUrl) {
        clipType = 'audio';
        clipLayer = 0; // Capa de audio (0)
      } 
      // Si tiene textContent, es un clip de texto
      else if (item.metadata?.textContent) {
        clipType = 'text';
        clipLayer = 2; // Capa de texto (2)
      }
      // Si tiene movementApplied, es un clip con efecto
      else if (item.metadata?.movementApplied) {
        clipType = 'effect';
        clipLayer = 3; // Capa de efectos (3)
      }
      // Si tiene videoUrl o lipsyncVideoUrl, es un clip de video
      else if (item.videoUrl || item.metadata?.lipsync?.videoUrl || item.lipsyncVideoUrl) {
        clipType = 'video';
        clipLayer = 1; // Capa de video/imagen (1)
      }
      // Si es una imagen generada por IA (tiene generatedImage)
      else if (item.generatedImage) {
        clipType = 'image';
        clipLayer = 7; // Colocar im√°genes generadas en la capa 7
        logger.info(`üé® Imagen generada detectada: ${item.id} - Asignando a capa 7`);
      }
      
      // URL del recurso: priorizar video, luego imagen
      const url = item.videoUrl || 
                  item.metadata?.lipsync?.videoUrl || 
                  item.lipsyncVideoUrl || 
                  item.generatedImage || 
                  item.firebaseUrl || 
                  '';
      
      logger.info(`üìç Clip ${item.id} - Tipo: ${clipType}, Capa: ${clipLayer}, URL: ${url ? "SI" : "NO"}`);
      
      // Create base object with all necessary properties
      const clipBase = {
        id: typeof item.id === 'string' ? parseInt(item.id, 10) : item.id,
        start: (item.start_time - (timelineItems[0]?.start_time || 0)) / 1000,
        duration: (item.duration || 0) / 1000,
        // Usar tipo determinado (video, imagen, audio, texto, efecto)
        type: clipType,
        // Usar capa determinada (0=audio, 1=video/imagen, 2=texto, 3=efectos)
        layer: clipLayer,
        thumbnail: typeof item.generatedImage === 'string' ? item.generatedImage : (typeof item.firebaseUrl === 'string' ? item.firebaseUrl : undefined),
        title: item.shotType || `Clip ${item.id}`,
        description: item.description || '',
        // Propiedades espec√≠ficas por tipo
        imageUrl: (clipType === 'image') ? url : undefined,
        videoUrl: (clipType === 'video') ? url : undefined,
        audioUrl: (clipType === 'audio') ? item.audioUrl : undefined,
        textContent: (clipType === 'text') ? item.metadata?.textContent : undefined,
        // Agregar imagePrompt, prompt y shotType para regeneraci√≥n y camera angles
        imagePrompt: item.imagePrompt,
        prompt: item.imagePrompt || item.description || `${item.shotType} shot`,
        shotType: item.shotType,
        // Estado de visibilidad y bloqueo
        visible: true,
        locked: false,
        // Metadatos para preservar el orden exacto del guion
        metadata: {
          sourceIndex: typeof item.id === 'number' ? item.id : parseInt(String(item.id), 10),
          section: item.metadata?.section || 'default',
          movementApplied: !!item.metadata?.movementApplied,
          movementPattern: item.metadata?.movementPattern,
          movementIntensity: item.metadata?.movementIntensity,
          faceSwapApplied: !!item.metadata?.faceSwapApplied,
          // Preservar metadata de lipsync si existe
          lipsync: item.metadata?.lipsync
        }
      };
      
      // Usar ensureCompatibleClip para garantizar compatibilidad con la interfaz unificada
      return ensureCompatibleClip(clipBase);
    });
    
    // Combinar clips de audio con clips visuales
    return [...audioClips, ...visualClips];
  }, [timelineItems, audioUrl, estimatedDuration]);

  // Ahora podemos calcular la duraci√≥n real basada en los clips
  const totalDuration = useMemo(() => {
    return clips.reduce((acc, clip) => Math.max(acc, clip.start + clip.duration), 0);
  }, [clips]);

  const handleTimeUpdate = (time: number) => {
    const baseTime = timelineItems[0]?.start_time || 0;
    setCurrentTime(baseTime + time * 1000);
  };

  const handleClipUpdate = (clipId: number, updates: Partial<TimelineClip>) => {
    const updatedItems = timelineItems.map(item => {
      if (item.id === clipId) {
        // Crear objeto de actualizaci√≥n base
        const updatedItem = { ...item };
        
        // Si se actualizaron las propiedades de tiempo
        if (updates.start !== undefined) {
          updatedItem.start_time = timelineItems[0].start_time + updates.start * 1000;
        }
        
        if (updates.duration !== undefined) {
          updatedItem.duration = updates.duration * 1000;
        }
        
        // Manejar propiedades espec√≠ficas de LipSync
        if (updates.lipsyncApplied !== undefined) {
          // Asegurarse de que el objeto metadata existe
          if (!updatedItem.metadata) {
            updatedItem.metadata = {};
          }
          
          // Actualizar el estado de lipsync en metadata
          updatedItem.metadata.lipsync = {
            ...(updatedItem.metadata.lipsync || {}),
            applied: updates.lipsyncApplied !== undefined ? updates.lipsyncApplied : false,
            timestamp: new Date().toISOString(),
          };
        }
        
        if (updates.lipsyncVideoUrl !== undefined) {
          // Asegurarse de que el objeto metadata existe
          if (!updatedItem.metadata) {
            updatedItem.metadata = {};
          }
          
          // Actualizar la URL del video en metadata
          updatedItem.metadata.lipsync = {
            ...(updatedItem.metadata.lipsync || {}),
            applied: true, // Cuando hay URL de video, siempre aplicamos lipsync
            videoUrl: updates.lipsyncVideoUrl,
            timestamp: new Date().toISOString(), // A√±adir timestamp para seguimiento
          };
        }
        
        // Manejar el progreso de LipSync si est√° presente
        if (updates.lipsyncProgress !== undefined) {
          // Asegurarse de que el objeto metadata existe
          if (!updatedItem.metadata) {
            updatedItem.metadata = {};
          }
          
          // Actualizar el progreso en metadata
          updatedItem.metadata.lipsync = {
            ...(updatedItem.metadata.lipsync || {}),
            progress: updates.lipsyncProgress,
            applied: (updatedItem.metadata.lipsync?.applied === undefined) ? false : updatedItem.metadata.lipsync.applied,
          };
        }
        
        return updatedItem;
      }
      return item;
    });
    
    setTimelineItems(updatedItems);
    
    // Depurar para verificar la actualizaci√≥n
    logger.info(`Clip ${clipId} actualizado:`, updates);
  };
  
  // Funci√≥n para manejar la divisi√≥n de clips en la l√≠nea de tiempo
  const handleSplitClip = (clipId: number, splitTime: number) => {
    // Encontrar el clip que se va a dividir
    const clipToSplit = timelineItems.find(item => item.id === clipId);
    if (!clipToSplit) return;
    
    // Calcular la posici√≥n absoluta del punto de divisi√≥n
    const absoluteSplitTime = timelineItems[0].start_time + splitTime * 1000;
    
    // Crear el nuevo clip para la segunda parte
    const newClipId = Math.max(...timelineItems.map(item => typeof item.id === 'number' ? item.id : parseInt(String(item.id), 10))) + 1;
    const relativeStartInClip = splitTime - ((clipToSplit.start_time - timelineItems[0].start_time) / 1000);
    
    // Nuevo clip (segunda parte)
    // Creamos primero un objeto base TimelineItem
    const newClipBase: TimelineItem = {
      ...clipToSplit,
      id: newClipId,
      start_time: absoluteSplitTime,
      end_time: clipToSplit.end_time,
      start: (absoluteSplitTime - timelineItems[0].start_time) / 1000,
      duration: (clipToSplit.end_time - absoluteSplitTime) / 1000,
      // Conservar otros campos importantes
      title: `${clipToSplit.title} (parte 2)`,
    };
    
    // Aseguramos que el nuevo clip es compatible con TimelineClipUnified
    const newClip = ensureCompatibleClip(newClipBase);
    
    // Actualizar la lista de clips
    const updatedItems = timelineItems.map(item => {
      if (item.id === clipId) {
        // Actualizar el clip original (primera parte)
        const updatedItemBase = {
          ...item,
          duration: relativeStartInClip,
          end_time: absoluteSplitTime
        };
        // Asegurar que el clip original modificado tambi√©n sea compatible con TimelineClipUnified
        return ensureCompatibleClip(updatedItemBase);
      }
      return item;
    });
    
    // A√±adir el nuevo clip
    updatedItems.push(newClip);
    
    // Ordenar los clips por tiempo de inicio
    updatedItems.sort((a, b) => {
      // Compatibilidad con ambos formatos (TimelineItem y TimelineClipUnified)
      const aStart = 'start_time' in a ? a.start_time : a.start;
      const bStart = 'start_time' in b ? b.start_time : b.start;
      return aStart - bStart;
    });
    
    // Actualizar el estado
    setTimelineItems(updatedItems as TimelineItem[]);
    
    logger.info(`Clip ${clipId} dividido en: ${clipId} y ${newClipId} en tiempo ${splitTime}s`);
  };

  /**
   * Aplica todas las restricciones requeridas a los clips del timeline:
   * 1. Duraci√≥n m√°xima de clips (5 segundos)
   * 2. Im√°genes generadas por IA solo en capa 7
   * 3. No solapamiento de im√°genes en la misma capa
   * @param clips Lista de clips a verificar
   * @returns Lista de clips con restricciones aplicadas
   */
  const enforceAllConstraints = (clips: TimelineItem[]): TimelineItem[] => {
    if (!clips || !clips.length) return [];
    
    // Crear una copia de los clips para no modificar los originales
    const processedClips = [...clips];
    const MAX_CLIP_DURATION = 5 * 1000; // 5 segundos en milisegundos
    
    // Ordenamos los clips por tiempo de inicio para facilitar la detecci√≥n de solapamientos
    processedClips.sort((a, b) => {
      // Garantizar que los clips tienen la propiedad start_time
      const aStart = a.start_time;
      const bStart = b.start_time;
      return aStart - bStart;
    });
    
    // Recorremos todos los clips
    for (let i = 0; i < processedClips.length; i++) {
      const currentClip = processedClips[i];
      
      // 1. Restricci√≥n de duraci√≥n - limitar a 5 segundos m√°ximo
      // Asegurar que la duraci√≥n est√© definida
      const clipDuration = currentClip.duration || (currentClip.end_time - currentClip.start_time);
      
      if (clipDuration > MAX_CLIP_DURATION) {
        logger.info(`Ajustando clip ${currentClip.id} de ${clipDuration}ms a ${MAX_CLIP_DURATION}ms`);
        currentClip.duration = MAX_CLIP_DURATION;
        currentClip.end_time = currentClip.start_time + MAX_CLIP_DURATION;
      }
      
      // 2. Restricci√≥n de capa para im√°genes generadas por IA - siempre en capa 7
      if (currentClip.generatedImage || (currentClip.metadata && currentClip.metadata.isGeneratedImage)) {
        if (currentClip.group !== 7) {
          logger.info(`Moviendo clip de imagen generada ${currentClip.id} a capa 7`);
          currentClip.group = 7;
        }
      }
      
      // 3. Prevenir solapamiento de clips en la misma capa
      // Solo necesitamos verificar contra los clips que siguen, ya que estamos ordenados
      for (let j = i + 1; j < processedClips.length; j++) {
        const nextClip = processedClips[j];
        
        // Si est√°n en la misma capa y hay solapamiento
        if (currentClip.group === nextClip.group && 
            currentClip.end_time > nextClip.start_time) {
          
          logger.info(`Detectado solapamiento entre clips ${currentClip.id} y ${nextClip.id} en capa ${currentClip.group}`);
          
          // Ajustar la duraci√≥n del clip actual para evitar el solapamiento
          const newEndTime = nextClip.start_time;
          const newDuration = newEndTime - currentClip.start_time;
          
          // Solo aplicar el cambio si la nueva duraci√≥n es razonable (m√°s de 0.1 segundos)
          if (newDuration >= 100) {
            logger.info(`Ajustando fin de clip ${currentClip.id} de ${currentClip.end_time}ms a ${newEndTime}ms`);
            currentClip.end_time = newEndTime;
            currentClip.duration = newDuration;
          }
          // Si la duraci√≥n resultante es demasiado peque√±a, movemos el clip siguiente
          else if (newDuration < 100) {
            // Calculamos el nuevo start_time para el clip siguiente
            const newStartTime = currentClip.end_time;
            logger.info(`Ajustando inicio de clip ${nextClip.id} de ${nextClip.start_time}ms a ${newStartTime}ms`);
            nextClip.start_time = newStartTime;
            nextClip.duration = nextClip.end_time - newStartTime;
          }
        }
      }
    }
    
    return processedClips;
  };

  /**
   * Generates a prompt for a specific timeline segment
   * Extracts the lyrics corresponding to the segment and generates a visual prompt
   * @param segment - The timeline segment for which the prompt will be generated
   * @returns A string with the generated prompt or an error message
   */
  const generatePromptForSegment = async (segment: TimelineItem): Promise<string> => {
    if (!segment || typeof segment.id !== 'number') {
      logger.error("Invalid segment:", segment);
      return "Error: invalid segment";
    }
    
    const maxAttempts = 3;
    let attempt = 0;
    let lastError: Error | null = null;
    
    // Determine which part of the transcription corresponds to this segment
    const segmentStartTime = segment.start_time / 1000; // convert to seconds
    const segmentEndTime = segment.end_time / 1000;
    let relevantLyrics = "";
    
    try {
      logger.info(`Generating prompt for segment ${segment.id} (${segmentStartTime.toFixed(2)}s - ${segmentEndTime.toFixed(2)}s)`);
      
      // STEP 1: RELEVANT LYRICS EXTRACTION
      // If we have transcription with timestamps (more precise)
      if (transcriptionWithTimestamps && Array.isArray(transcriptionWithTimestamps.segments)) {
        // Search for transcription segments that match this timeline segment
        const relevantSegments = transcriptionWithTimestamps.segments.filter(
          (s: {start: number, end: number}) => 
            (s.start >= segmentStartTime && s.start <= segmentEndTime) || 
            (s.end >= segmentStartTime && s.end <= segmentEndTime) ||
            (s.start <= segmentStartTime && s.end >= segmentEndTime)
        );
        
        if (relevantSegments.length > 0) {
          relevantLyrics = relevantSegments
            .map((s: {text: string}) => s.text || "")
            .filter(text => text.trim().length > 0)
            .join(" ");
          
          logger.info(`Found ${relevantSegments.length} segments with timestamps for this fragment`);
        }
      }
      
      // If there are no specific lyrics, use general transcription
      if (!relevantLyrics && transcription) {
        // Divide total transcription proportionally
        const totalDuration = timelineItems.length > 0 ? 
          (timelineItems[timelineItems.length - 1].end_time / 1000) - (timelineItems[0].start_time / 1000) : 0;
          
        if (totalDuration > 0) {
          const segmentDuration = segmentEndTime - segmentStartTime;
          const segmentPercent = segmentDuration / totalDuration;
          const startPercent = (segmentStartTime - (timelineItems[0].start_time / 1000)) / totalDuration;
          
          // Estimate which part of the transcription corresponds to this segment
          const transcriptionWords = transcription.split(/\s+/);
          const startWordIndex = Math.floor(startPercent * transcriptionWords.length);
          const wordCount = Math.max(1, Math.floor(segmentPercent * transcriptionWords.length));
          
          if (startWordIndex >= 0 && wordCount > 0 && startWordIndex < transcriptionWords.length) {
            const endWordIndex = Math.min(startWordIndex + wordCount, transcriptionWords.length);
            relevantLyrics = transcriptionWords.slice(startWordIndex, endWordIndex).join(" ");
            logger.info(`Using proportional transcription: words ${startWordIndex}-${endWordIndex} of ${transcriptionWords.length}`);
          }
        }
      }

      // If we still don't have lyrics, use contextual information based on segment
      if (!relevantLyrics || relevantLyrics.trim().length === 0) {
        // Determine context based on position in video and segment characteristics
        const isBeginningSong = timelineItems.indexOf(segment) < Math.min(3, timelineItems.length * 0.2);
        const isEndingSong = timelineItems.indexOf(segment) > timelineItems.length * 0.8;
        const isHighEnergy = segment.energy && segment.averageEnergy && segment.energy > segment.averageEnergy * 1.3;
        const isLowEnergy = segment.energy && segment.averageEnergy && segment.energy < segment.averageEnergy * 0.7;
        
        if (isHighEnergy) {
          relevantLyrics = isBeginningSong 
            ? "Energetic and intense introduction" 
            : isEndingSong 
              ? "Final climax with great energy" 
              : "Instrumental section with high intensity";
        } else if (isLowEnergy) {
          relevantLyrics = isBeginningSong 
            ? "Soft and atmospheric introduction" 
            : isEndingSong 
              ? "Melodic and reflective closure" 
              : "Quiet and contemplative interlude";
        } else {
          relevantLyrics = isBeginningSong 
            ? "Song introduction" 
            : isEndingSong 
              ? "Song conclusion" 
              : "Instrumental";
        }
        
        logger.info(`No specific lyrics found, using context: "${relevantLyrics}"`);
      }

      // STEP 2: PROMPT GENERATION WITH MULTIPLE ATTEMPTS
      while (attempt < maxAttempts) {
        try {
          logger.info(`Generating prompt for segment ${segment.id}, attempt ${attempt + 1}/${maxAttempts}`);
          
          // Validate video style parameters before creating prompt
          if (!videoStyle.cameraFormat || !videoStyle.mood || !videoStyle.characterStyle || 
              !videoStyle.colorPalette || videoStyle.visualIntensity === undefined || 
              videoStyle.narrativeIntensity === undefined) {
            logger.error("Incomplete video styles:", videoStyle);
            throw new Error("Missing style parameters to generate prompt");
          }
          
          // Prepare parameters for prompt with typing
          const promptParams: VideoPromptParams = {
            shotType: segment.shotType || "medium shot",
            cameraFormat: videoStyle.cameraFormat,
            mood: segment.mood === 'intense' 
              ? 'Energetic' 
              : segment.mood === 'calm' 
                ? 'Calm' 
                : videoStyle.mood,
            visualStyle: videoStyle.characterStyle,
            visualIntensity: videoStyle.visualIntensity,
            narrativeIntensity: videoStyle.narrativeIntensity,
            colorPalette: videoStyle.colorPalette,
            duration: (segment.duration || 0) / 1000,
            directorStyle: videoStyle.selectedDirector?.style,
            specialty: videoStyle.selectedDirector?.specialty,
            styleReference: videoStyle.styleReferenceUrl || ""
          };

          // Add lyrics information to parameters
          const promptWithLyrics = `Music video scene representing these lyrics: "${relevantLyrics}". ${await generateVideoPromptWithRetry(promptParams)}`;

          if (promptWithLyrics && promptWithLyrics !== "Error generating prompt") {
            logger.info(`Prompt successfully generated for segment ${segment.id}`);
            return promptWithLyrics;
          }

          logger.warn(`Attempt ${attempt + 1} failed, retrying in ${2 * (attempt + 1)} seconds...`);
          await new Promise(resolve => setTimeout(resolve, 2000 * (attempt + 1)));
          attempt++;

        } catch (error) {
          logger.error(`Error in attempt ${attempt + 1}:`, error);
          lastError = error instanceof Error ? error : new Error(String(error));

          if (attempt === maxAttempts - 1) {
            toast({
              title: "Error",
              description: "Could not generate prompt after several attempts",
              variant: "destructive",
            });
            return segment.imagePrompt || "Error generating prompt";
          }

          // Exponential backoff
          const backoffTime = Math.min(1000 * Math.pow(2, attempt), 10000);
          logger.info(`Retrying in ${backoffTime/1000} seconds...`);
          await new Promise(resolve => setTimeout(resolve, backoffTime));
          attempt++;
        }
      }
    } catch (outerError) {
      logger.error("General error in generatePromptForSegment:", outerError);
      lastError = outerError instanceof Error ? outerError : new Error(String(outerError));
    }

    // FALLBACK: If no attempt succeeded
    logger.error(`Could not generate prompt for segment ${segment.id} after multiple attempts:`, lastError);
    
    // As a last resort, use a basic prompt based on shot type and mood
    const fallbackPrompt = `${segment.shotType || 'medium shot'} of a ${segment.mood || 'neutral'} scene with ${videoStyle.colorPalette || 'balanced'} colors. ${relevantLyrics}`;
    
    logger.warn(`Using fallback prompt for segment ${segment.id}: ${fallbackPrompt}`);
    return fallbackPrompt;
  };

  const generatePromptsForSegments = async () => {
    if (timelineItems.length === 0) {
      toast({
        title: "Error",
        description: "You must first detect musical cuts",
        variant: "destructive",
      });
      return;
    }

    // ‚úÖ VERIFICAR SI YA TIENEN PROMPTS DEL SCRIPT JSON
    const itemsWithPrompts = timelineItems.filter(item => item.imagePrompt && item.imagePrompt.length > 20);
    
    if (itemsWithPrompts.length === timelineItems.length) {
      toast({
        title: "‚úÖ Prompts ya generados",
        description: `Todos los ${timelineItems.length} segmentos ya tienen prompts del guion JSON. Puedes proceder a generar im√°genes.`,
      });
      setCurrentStep(5);
      return;
    }
    
    if (itemsWithPrompts.length > 0) {
      logger.info(`‚ÑπÔ∏è ${itemsWithPrompts.length}/${timelineItems.length} segmentos ya tienen prompts del JSON`);
    }

    if (!videoStyle.mood || !videoStyle.colorPalette || !videoStyle.characterStyle) {
      toast({
        title: "Error",
        description: "You must configure all style aspects before generating prompts",
        variant: "destructive",
      });
      return;
    }

    setIsGeneratingScript(true);

    try {
      // ‚úÖ ELIMINADO L√çMITE: Procesar TODOS los segmentos, no solo 10
      const updatedItems = [...timelineItems];
      let hasError = false;
      let successCount = 0;

      // Procesar los segmentos en grupos de 3 para evitar sobrecargar la API
      for (let i = 0; i < updatedItems.length; i += 3) {
        const batch = updatedItems.slice(i, i + 3);

        try {
          const results = await Promise.all(
            batch.map(async (segment) => {
              const newPrompt = await generatePromptForSegment(segment);
              return {
                segment,
                prompt: newPrompt
              };
            })
          );

          results.forEach(({ segment, prompt }) => {
            if (prompt && prompt !== "Error generating prompt") {
              const index = updatedItems.findIndex(item => item.id === segment.id);
              if (index !== -1) {
                updatedItems[index] = {
                  ...updatedItems[index],
                  imagePrompt: prompt
                };
                successCount++;
              }
            } else {
              hasError = true;
            }
          });

          // Actualizar el estado despu√©s de cada batch
          setTimelineItems([...updatedItems]);

          toast({
            title: "Progreso",
            description: `Generados ${successCount} de ${updatedItems.length} prompts`,
          });

          // Esperar entre batches para evitar rate limits
          if (i + 3 < updatedItems.length) {
            await new Promise(resolve => setTimeout(resolve, 3000));
          }

        } catch (error) {
          logger.error(`Error procesando batch ${i/3 + 1}:`, error);
          hasError = true;
        }
      }

      if (successCount === updatedItems.length) {
        toast({
          title: "√âxito",
          description: "Todos los prompts han sido generados",
        });
        setCurrentStep(5);
      } else {
        toast({
          title: "Completado con advertencias",
          description: `${successCount} de ${updatedItems.length} prompts generados exitosamente`,
          variant: hasError ? "destructive" : "default",
        });
      }

    } catch (error) {
      logger.error("Error en la generaci√≥n de prompts:", error);
      toast({
        title: "Error",
        description: "Error al generar los prompts",
        variant: "destructive",
      });
    } finally {
      setIsGeneratingScript(false);
    }
  };

  const generateVideo = async (): Promise<string | null> => {
    if (!timelineItems.length || !audioBuffer) {
      toast({
        title: "Error",
        description: "No hay suficientes elementos para generar el video",
        variant: "destructive",
      });
      return null;
    }

    // Verificar si hay suficientes im√°genes generadas
    const itemsWithImages = timelineItems.filter(item => item.generatedImage).length;
    if (itemsWithImages < timelineItems.length * 0.7) { // Al menos 70% de cobertura
      toast({
        title: "Atenci√≥n",
        description: `Solo ${itemsWithImages} de ${timelineItems.length} segmentos tienen im√°genes. Considera generar m√°s im√°genes primero.`,
        variant: "default",
      });
    }

    setIsGeneratingVideo(true);
    try {
      toast({
        title: "üé¨ Iniciando generaci√≥n",
        description: "Convirtiendo im√°genes a video con IA...",
      });

      // Paso 1: Guardar todas las im√°genes en Firebase
      const savePromises = timelineItems
        .filter(item => item.generatedImage && !item.firebaseUrl)
        .map(async (item) => {
          try {
            const url = await saveToFirebase(item);
            if (url) {
              setTimelineItems(prev => prev.map(
                i => i.id === item.id ? { ...i, firebaseUrl: url } : i
              ));
            }
            return { id: item.id, success: !!url, url };
          } catch (error) {
            logger.error(`Error guardando imagen para segmento ${item.id}:`, error);
            return { id: item.id, success: false };
          }
        });

      await Promise.all(savePromises);

      // Paso 2: Generar videos para cada escena (simulado por ahora)
      toast({
        title: "üìπ Generando videos",
        description: "Convirtiendo cada escena en video...",
      });

      // En una implementaci√≥n futura real, aqu√≠ generar√≠as videos con MiniMax/FAL
      // Por ahora, simulamos el proceso
      await new Promise(resolve => setTimeout(resolve, 2000));

      // Paso 3: Aplicar lip-sync a escenas de performance
      const performanceScenes = timelineItems.filter(item => 
        item.metadata?.role === 'performance' && item.generatedImage
      );

      if (performanceScenes.length > 0 && audioUrl) {
        toast({
          title: "üé§ Aplicando lip-sync",
          description: `Sincronizando ${performanceScenes.length} escenas de performance...`,
        });

        logger.info(`üé§ Aplicando lip-sync a ${performanceScenes.length} escenas de performance`);

        // Procesar lip-sync para cada escena de performance
        for (const scene of performanceScenes) {
          try {
            // En una implementaci√≥n real, aqu√≠ usar√≠as el video generado
            // Por ahora, usamos la imagen como placeholder
            const videoUrl = scene.firebaseUrl || scene.generatedImage;
            
            if (typeof videoUrl === 'string') {
              logger.info(`üé§ Procesando lip-sync para escena ${scene.id}`);
              
              // Aplicar lip-sync (esto requerir√≠a tener el video generado primero)
              // const syncResult = await applyLipSync({
              //   videoUrl: videoUrl,
              //   audioUrl: audioUrl,
              //   syncMode: 'cut_off'
              // });
              
              // if (syncResult.success) {
              //   setTimelineItems(prev => prev.map(
              //     i => i.id === scene.id ? { ...i, syncedVideoUrl: syncResult.videoUrl } : i
              //   ));
              // }
            }
          } catch (error) {
            logger.error(`Error aplicando lip-sync a escena ${scene.id}:`, error);
          }
        }

        toast({
          title: "‚úÖ Lip-sync completado",
          description: `${performanceScenes.length} escenas sincronizadas con el audio`,
        });
      }

      // Generar ID √∫nico para este video
      const videoId = `video_${Date.now()}`;
      setVideoId(videoId);

      // Crear un documento en Firestore para el video
      try {
        const videoRef = collection(db, 'videos');
        await addDoc(videoRef, {
          id: videoId,
          userId: user?.uid,
          title: songTitle || 'Video Musical Generado',
          status: 'preview',
          createdAt: serverTimestamp(),
          updatedAt: serverTimestamp(),
          duration: audioBuffer.duration || 0,
          thumbnailUrl: timelineItems.find(item => item.firebaseUrl || item.generatedImage)?.firebaseUrl || 
                         timelineItems.find(item => item.firebaseUrl || item.generatedImage)?.generatedImage || '',
          tags: ['m√∫sica', 'video', 'artista', 'canci√≥n', 'generado'],
          hasLipSync: performanceScenes.length > 0
        });
      } catch (error) {
        logger.error("Error guardando informaci√≥n del video:", error);
      }

      setCurrentStep(7);

      toast({
        title: "üéâ Video generado exitosamente",
        description: "Tu video musical est√° listo con lip-sync incluido",
      });

      return videoId;
    } catch (error) {
      logger.error("Error generando video:", error);
      toast({
        title: "Error",
        description: error instanceof Error ? error.message : "Error al generar el video",
        variant: "destructive",
      });
      return null;
    } finally {
      setIsGeneratingVideo(false);
    }
  };

  // Funci√≥n para descargar el video final
  const downloadVideo = () => {
    // Usar el video mejorado si est√° disponible, o el video generado original
    const videoToDownload = upscaledVideoUrl || generatedVideoUrl || "/assets/Standard_Mode_Generated_Video (2).mp4";
    const link = document.createElement('a');
    link.href = videoToDownload;
    link.download = `music-video-${videoId || 'final'}.mp4`;
    document.body.appendChild(link);
    link.click();
    document.body.removeChild(link);
    
    toast({
      title: "Descarga iniciada",
      description: "Tu video musical se est√° descargando ahora"
    });
  };
  
  // Funci√≥n para compartir el video en redes sociales
  const shareMusicVideo = () => {
    // En una implementaci√≥n real, aqu√≠ se abrir√≠a un modal con opciones
    // de compartir en diferentes redes sociales
    
    // Por ahora, simulamos compartir usando el navegador web API
    const videoToShare = upscaledVideoUrl || generatedVideoUrl || "/assets/Standard_Mode_Generated_Video (2).mp4";
    const shareData = {
      title: 'Mi Video Musical Generado con IA',
      text: '¬°Mira este incre√≠ble video musical que he creado con IA!',
      url: window.location.origin + videoToShare
    };
    
    if (navigator.share && navigator.canShare && navigator.canShare(shareData)) {
      navigator.share(shareData)
        .then(() => {
          toast({
            title: "Compartido con √©xito",
            description: "Tu video ha sido compartido"
          });
        })
        .catch(error => {
          logger.error('Error al compartir:', error);
          toast({
            title: "Error al compartir",
            description: "No se pudo compartir el video. Intenta otra opci√≥n."
          });
        });
    } else {
      // Fallback si Web Share API no est√° disponible
      toast({
        title: "Enlace copiado",
        description: "Enlace al video copiado al portapapeles. Ahora puedes compartirlo."
      });
    }
  };

  const analyzeReferenceImage = async (image: string) => {
    try {
      const analysis = await analyzeImage(image);

      setVideoStyle(prev => ({
        ...prev,
        styleDescription: analysis
      }));

      toast({
        title: "An√°lisis completado",
        description: "Estilo de referencia actualizado"
      });
    } catch (error) {
      logger.error("Error analyzing reference image:", error);
      toast({
        title: "Error",
        description: "No se pudo analizar la imagen de referencia",
        variant: "destructive"
      });
    }
  };

  useEffect(() => {
    const loadDirectors = async () => {
      try {
        const directorsSnapshot = await getDocs(collection(db, "directors"));
        const directorsData = directorsSnapshot.docs.map(doc => ({
          id: doc.id,
          ...doc.data()
        })) as Director[];
        setDirectors(directorsData);
      } catch (error) {
        logger.error("Error loading directors:", error);
        toast({
          title: "Error",
          description: "No se pudieron cargar los directores",
          variant: "destructive",
        });
      }
    };

    loadDirectors();
  }, []);

  // Auto-save project cuando cambien datos importantes
  useEffect(() => {
    if (!user?.email || !projectName.trim() || timelineItems.length === 0) {
      return; // No auto-guardar si no hay usuario, nombre de proyecto o timeline items
    }

    const imagesGenerated = timelineItems.filter(item => item.generatedImage || item.firebaseUrl).length;
    const videosGenerated = timelineItems.filter(item => item.videoUrl || item.lipsyncVideoUrl).length;

    musicVideoProjectServicePostgres.autoSave({
      userEmail: user.email,
      projectName,
      audioUrl: audioUrl || undefined,
      audioDuration: audioBuffer?.duration,
      transcription: transcription || undefined,
      scriptContent: scriptContent || undefined,
      timelineItems,
      selectedDirector: videoStyle.selectedDirector ? {
        id: videoStyle.selectedDirector.id || '',
        name: videoStyle.selectedDirector.name || '',
        specialty: videoStyle.selectedDirector.specialty || '',
        style: videoStyle.selectedDirector.style || '',
        experience: videoStyle.selectedDirector.experience || ''
      } : undefined,
      videoStyle: {
        cameraFormat: videoStyle.cameraFormat,
        mood: videoStyle.mood,
        characterStyle: videoStyle.characterStyle,
        colorPalette: videoStyle.colorPalette,
        visualIntensity: videoStyle.visualIntensity,
        narrativeIntensity: videoStyle.narrativeIntensity,
        selectedDirector: videoStyle.selectedDirector
      },
      artistReferenceImages,
      selectedEditingStyle: {
        id: selectedEditingStyle.id,
        name: selectedEditingStyle.name,
        description: selectedEditingStyle.description,
        duration: selectedEditingStyle.duration
      },
      status: videosGenerated === timelineItems.length && timelineItems.length > 0 ? "completed" : 
              imagesGenerated > 0 ? "generating_images" :
              scriptContent ? "generating_script" : "draft",
      progress: {
        scriptGenerated: !!scriptContent,
        imagesGenerated,
        totalImages: timelineItems.length,
        videosGenerated,
        totalVideos: timelineItems.length
      }
    }, 10000); // Auto-save despu√©s de 10 segundos de inactividad
  }, [user?.uid, projectName, audioUrl, transcription, scriptContent, timelineItems, videoStyle, artistReferenceImages, selectedEditingStyle, audioBuffer?.duration]);

  // Convertir los pasos para el componente EnhancedProgressSteps
  // Definir los pasos del workflow con el tipo Step importado
  const workflowSteps: Step[] = [
    {
      id: "transcription",
      name: "Transcripci√≥n de Audio",
      description: "Analizando y transcribiendo la letra de tu canci√≥n",
      status: currentStep > 1 ? "completed" : currentStep === 1 ? "in-progress" : "pending"
    },
    {
      id: "script",
      name: "Generaci√≥n de Guion",
      description: "Creando un guion visual basado en la letra",
      status: currentStep > 2 ? "completed" : currentStep === 2 ? "in-progress" : "pending"
    },
    {
      id: "sync",
      name: "Sincronizaci√≥n",
      description: "Alineando el contenido visual con el ritmo musical",
      status: currentStep > 3 ? "completed" : currentStep === 3 ? "in-progress" : "pending"
    },
    {
      id: "scenes",
      name: "Generaci√≥n de Escenas",
      description: "Creando escenas para cada secci√≥n",
      status: currentStep > 4 ? "completed" : currentStep === 4 ? "in-progress" : "pending"
    },
    {
      id: "customization",
      name: "Personalizaci√≥n",
      description: "Ajustando el estilo visual a tus preferencias",
      status: currentStep > 5 ? "completed" : currentStep === 5 ? "in-progress" : "pending"
    },
    {
      id: "movement",
      name: "Integraci√≥n de Movimiento",
      description: "A√±adiendo din√°micas visuales y coreograf√≠as",
      status: currentStep > 6 ? "completed" : currentStep === 6 ? "in-progress" : "pending"
    },
    {
      id: "lipsync",
      name: "Sincronizaci√≥n de Labios",
      description: "Sincronizando labios con la letra",
      status: currentStep > 7 ? "completed" : currentStep === 7 ? "in-progress" : "pending"
    },
    {
      id: "generation",
      name: "Generaci√≥n de Video",
      description: "Creando clips de video con IA",
      status: currentStep > 8 ? "completed" : currentStep === 8 ? "in-progress" : "pending"
    },
    {
      id: "rendering",
      name: "Renderizado Final",
      description: "Combinando todo en un video musical completo",
      status: currentStep > 9 ? "completed" : currentStep === 9 ? "in-progress" : "pending"
    }
  ];

  // Calcular el progreso para las animaciones
  const allStepsCompleted = workflowSteps.every(step => step.status === "completed");
  
  return (
    <div className="min-h-screen bg-black">
      {/* Modal de Onboarding Creativo */}
      <CreativeOnboardingModal
        open={showOnboarding}
        onComplete={handleOnboardingComplete}
      />

      {/* Modal de Selecci√≥n de Director y Estilo */}
      <DirectorSelectionModal
        open={showDirectorSelection}
        onSelect={handleDirectorSelection as any}
        preSelectedDirector={videoStyle.selectedDirector}
      />

      {/* Modal de Selecci√≥n de Concepto */}
      <ConceptSelectionModal
        open={showConceptSelection}
        concepts={conceptProposals}
        directorName={videoStyle.selectedDirector?.name || "El Director"}
        onSelect={handleConceptSelection}
      />

      {/* Character Generation Modal with Multi-Angle & Casting */}
      <CharacterGenerationModalEnhanced
        open={showCharacterGeneration}
        stage={characterGenerationStage}
        progress={characterGenerationProgress}
        character={masterCharacter}
        onContinue={async () => {
          logger.info('üëâ Usuario clicke√≥ "Continue to Concept Generation"');
          setShowCharacterGeneration(false);
          
          // Si hay conceptos pendientes de generar, gen√©ralos AHORA
          if (pendingConceptGeneration) {
            logger.info('üé¨ Iniciando generaci√≥n de 3 conceptos...');
            const { transcription, director } = pendingConceptGeneration;
            await handleGenerateConcepts(transcription, director);
            setPendingConceptGeneration(null);
          }
        }}
      />

      {/* Preview Modal - Shows first 10 images for approval */}
      <PreviewImagesModal
        open={showPreviewModal}
        images={previewImages}
        onApprove={handlePreviewApprove}
        onReject={handlePreviewReject}
      />

      {/* Modal de Templates R√°pidos */}
      <QuickStartTemplates
        open={showQuickStartTemplates}
        onClose={() => setShowQuickStartTemplates(false)}
        onSelectTemplate={handleTemplateSelection}
      />

      {/* Payment Gate Modal - Shows after free preview generation */}
      <PaymentGateModal
        isOpen={showPaymentGate}
        onClose={() => setShowPaymentGate(false)}
        onPaymentSuccess={handlePaymentSuccess}
        userEmail={user?.email || ''}
        demoImagesCount={FREE_SCENES_LIMIT}
        remainingImagesCount={Math.max(0, (scriptContent ? JSON.parse(scriptContent).scenes?.length || 40 : 40) - FREE_SCENES_LIMIT)}
        totalScenes={scriptContent ? JSON.parse(scriptContent).scenes?.length || 40 : 40}
        aspectRatio={videoAspectRatio}
        songTitle={projectName || songTitle || 'Your Music Video'}
      />

      {/* Timeline Editor CapCut - Full Screen After Image Generation */}
      {timelineItems.length > 0 && !showPreviewModal && (
        <div className="fixed inset-0 z-50">
          {typeof window !== 'undefined' && (
            <TimelineEditorCapCut
              initialClips={timelineItems}
              duration={selectedFile?.duration || audioDuration || 0}
              scenes={timelineItems
                .filter(item => item.generatedImage || item.firebaseUrl || item.imageUrl || item.thumbnail)
                .map((item, idx) => ({
                  id: String(item.id) || `scene-${idx}`,
                  imageUrl: (typeof item.generatedImage === 'string' ? item.generatedImage : '') || 
                           item.firebaseUrl || item.imageUrl || item.thumbnail || '',
                  timestamp: (item.start_time || 0) / 1000, // Convert ms to seconds
                  description: item.lyricsSegment || item.description || item.imagePrompt || `Scene ${idx + 1}`,
                  lyricsSegment: item.lyricsSegment || ''
                }))}
              audioPreviewUrl={selectedFile?.url || audioUrl}
              onChange={(clips) => setTimelineItems(clips)}
              onExport={handleExportVideo}
              onClose={() => {
                // Allow user to go back/close timeline editor
                // This resets to show the generation modal or previous step
                if (window.confirm('¬øSeguro que quieres salir del editor? Tus cambios se guardar√°n.')) {
                  setShowPreviewModal(true);
                }
              }}
              isExporting={isExporting}
              exportProgress={exportProgress}
              exportStatus={exportStatus}
            />
          )}
        </div>
      )}

      {/* Modal de Progreso de Generaci√≥n de Im√°genes */}
      <Dialog open={isGeneratingShots} onOpenChange={() => {}}>
        <DialogContent className="max-w-[95vw] sm:max-w-2xl md:max-w-3xl lg:max-w-4xl max-h-[90vh] overflow-y-auto bg-gradient-to-br from-black via-zinc-900 to-black border-orange-500/20">
          <div className="space-y-6 p-2 sm:p-4">
            {/* Encabezado con porcentaje */}
            <div className="text-center space-y-4">
              <motion.div
                className="inline-flex items-center justify-center w-24 h-24 sm:w-32 sm:h-32 rounded-full bg-gradient-to-br from-orange-500 to-orange-700 relative"
                animate={{ rotate: 360 }}
                transition={{ duration: 2, repeat: Infinity, ease: "linear" }}
              >
                <div className="absolute inset-2 rounded-full bg-black flex items-center justify-center">
                  <span className="text-2xl sm:text-4xl font-bold text-orange-400">
                    {generationProgress.percentage}%
                  </span>
                </div>
              </motion.div>
              
              {/* Retry Indicator */}
              {isRetrying && (
                <motion.div
                  initial={{ opacity: 0, scale: 0.8 }}
                  animate={{ opacity: 1, scale: 1 }}
                  className="flex items-center justify-center gap-2 bg-yellow-500/20 border border-yellow-500/40 rounded-lg px-4 py-2 mt-2"
                >
                  <RefreshCw className="h-4 w-4 text-yellow-400 animate-spin" />
                  <div className="text-sm">
                    <p className="text-yellow-400 font-semibold">Retrying...</p>
                    <p className="text-yellow-300/70 text-xs">{retryMessage}</p>
                  </div>
                </motion.div>
              )}
              
              <div>
                <h2 className="text-xl sm:text-2xl md:text-3xl font-bold text-white mb-2">
                  Generando Im√°genes con IA
                </h2>
                <p className="text-sm sm:text-base text-white/70 mb-1">
                  Creando visuales √∫nicos basados en tu estilo seleccionado
                </p>
                <p className="text-xs sm:text-sm text-orange-400/80">
                  {generationProgress.current} de {generationProgress.total} im√°genes completadas
                </p>
              </div>
            </div>

            {/* Barra de progreso */}
            <div className="space-y-2">
              <Progress value={generationProgress.percentage} className="h-2 bg-zinc-800" />
              <p className="text-xs sm:text-sm text-white/70 text-center">
                {generationProgress.status}
              </p>
            </div>

            {/* Galer√≠a secuencial de im√°genes - NUEVO COMPONENTE FLUIDO */}
            <SequentialImageGallery 
              images={generationProgress.generatedImages}
              currentPrompt={generationProgress.currentPrompt}
              total={generationProgress.total}
            />

            {/* Mensaje motivacional */}
            <motion.div
              className="text-center text-xs sm:text-sm text-white/60 italic"
              animate={{ opacity: [0.6, 1, 0.6] }}
              transition={{ duration: 2, repeat: Infinity }}
            >
              ‚ú® Creando tu video musical √∫nico con inteligencia artificial...
            </motion.div>
          </div>
        </DialogContent>
      </Dialog>
      
      {/* Overlay de progreso mejorado con dise√±o atractivo */}
      <AnimatePresence>
        {showProgress && (
          <EnhancedProgressModal
            currentStage={currentProgressStage}
            progress={progressPercentage}
            customMessage={progressMessage}
            onComplete={() => {
              setShowProgress(false);
            }}
          />
        )}
      </AnimatePresence>

      {/* Efectos visuales para toda la aplicaci√≥n */}
      {allStepsCompleted && <motion.div className="confetti-container" />}
      
      {/* Sistema de part√≠culas din√°micas basadas en el paso actual - Ajustadas a naranja/negro */}
      {/* Bot√≥n de Quick Start - Solo visible al inicio */}
      {currentStep === 1 && !transcription && (
        <motion.div
          initial={{ opacity: 0, y: -20 }}
          animate={{ opacity: 1, y: 0 }}
          className="mb-6"
        >
          <Card className="bg-gradient-to-r from-orange-600/20 to-orange-500/20 border-orange-500/30 p-6">
            <div className="flex flex-col md:flex-row items-center justify-between gap-4">
              <div className="flex items-center gap-4">
                <div className="bg-orange-500 rounded-full p-3">
                  <Zap className="w-6 h-6 text-white" />
                </div>
                <div>
                  <h3 className="text-lg font-bold text-white">üöÄ Inicio R√°pido con Templates</h3>
                  <p className="text-sm text-white/70">
                    Empieza en segundos con configuraci√≥n optimizada para tu g√©nero musical
                  </p>
                </div>
              </div>
              <Button
                onClick={() => setShowQuickStartTemplates(true)}
                className="bg-gradient-to-r from-orange-600 to-orange-500 hover:from-orange-700 hover:to-orange-600 border-0 shadow-md"
                data-testid="button-quick-start"
              >
                <Zap className="mr-2 h-4 w-4" />
                Ver Templates
              </Button>
            </div>
          </Card>
        </motion.div>
      )}

      {currentStep === 1 && (
        <ParticleSystem 
          count={30} 
          currentStep={1}
          active={true}
        />
      )}
      
      {currentStep === 2 && (
        <ParticleSystem 
          count={40} 
          currentStep={2}
          active={true}
        />
      )}
      
      {currentStep === 3 && (
        <ParticleSystem 
          count={50} 
          currentStep={3}
          active={true}
        />
      )}
      
      {currentStep === 4 && (
        <ParticleSystem 
          count={60} 
          currentStep={4}
          active={true}
        />
      )}
      
      {currentStep === 6 && (
        <ParticleSystem 
          count={80} 
          currentStep={6}
          active={true}
        />
      )}
      
      {currentStep >= 8 && currentStep < 9 && (
        <ParticleSystem 
          count={120}
          currentStep={8}
          active={true}
        />
      )}
      
      {/* Contenedor principal con posicionamiento relativo para los efectos */}
      <div className="relative">
        {/* Gradiente animado en el fondo - Usando solo naranja y negro */}
        <AnimatedGradient 
          colors={
            currentStep <= 2 ? ["#FF6B00", "#FF8800", "#FF4500", "#111111"] :
            currentStep <= 4 ? ["#FF4500", "#FF8800", "#111111", "#222222"] :
            currentStep <= 6 ? ["#FF7700", "#FF5500", "#111111", "#222222"] :
            currentStep <= 8 ? ["#FF6B00", "#111111", "#FF4500", "#000000"] :
            ["#FF8800", "#FF4500", "#111111", "#000000"]
          } 
          speed={currentStep <= 2 ? 5 : currentStep <= 5 ? 8 : 12} 
          className="opacity-20"
        />
        
        {/* Efectos de brillo seg√∫n la etapa del proceso */}
        {currentStep >= 5 && currentStep < 7 && (
          <GlowEffect 
            color="purple" 
            size={300} 
            x={25} 
            y={30} 
            pulsate={true} 
            className="opacity-10"
          />
        )}
        
        {currentStep >= 7 && (
          <GlowEffect 
            color="orange" 
            size={350} 
            x={75} 
            y={40} 
            pulsate={true} 
            className="opacity-15"
          />
        )}
        
        {/* Componente de pasos mejorado con animaciones */}
        <EnhancedProgressSteps
          steps={workflowSteps}
          currentStep={workflowSteps.find(s => s.status === "in-progress")?.id || "transcription"}
          showDescriptions={true}
        />
        
        {/* Mantener el ProgressSteps original como fallback (escondido para compatibilidad) */}
        <div className="hidden">
          <ProgressSteps 
            currentStep={String(currentStep)} 
            steps={[
              {
                id: "transcription",
                name: "Transcripci√≥n de Audio",
                description: "Analizando y transcribiendo la letra de tu canci√≥n",
                status: currentStep > 1 ? "completed" : currentStep === 1 ? "in-progress" : "pending"
              },
              {
                id: "script",
                name: "Generaci√≥n de Guion",
                description: "Creando un guion visual basado en tu m√∫sica",
                status: currentStep > 2 ? "completed" : currentStep === 2 ? "in-progress" : "pending"
              },
              {
                id: "sync",
                name: "Sincronizaci√≥n",
                description: "Sincronizando el video con el ritmo de la m√∫sica",
                status: currentStep > 3 ? "completed" : currentStep === 3 ? "in-progress" : "pending"
              },
              {
                id: "scenes",
                name: "Generaci√≥n de Escenas",
                description: "Creando las escenas del video musical",
                status: currentStep > 4 ? "completed" : currentStep === 4 ? "in-progress" : "pending"
              },
              {
                id: "customization",
                name: "Personalizaci√≥n",
                description: "Ajustando el estilo visual a tus preferencias",
                status: currentStep > 5 ? "completed" : currentStep === 5 ? "in-progress" : "pending"
              },
              {
                id: "movement",
                name: "Integraci√≥n de Movimiento",
                description: "A√±adiendo coreograf√≠as y din√°micas visuales",
                status: currentStep > 6 ? "completed" : currentStep === 6 ? "in-progress" : "pending"
              },
              {
                id: "lipsync",
                name: "Sincronizaci√≥n de Labios",
                description: "Sincronizando labios con la letra de la canci√≥n",
                status: currentStep > 7 ? "completed" : currentStep === 7 ? "in-progress" : "pending"
              },
              {
                id: "generation",
                name: "Generaci√≥n de Video",
                description: "Creando videos con IA a partir de tus escenas",
                status: currentStep > 8 ? "completed" : currentStep === 8 ? "in-progress" : "pending"
              },
              {
                id: "rendering",
                name: "Renderizado Final",
                description: "Combinando todo en tu video musical",
                status: currentStep > 9 ? "completed" : currentStep === 9 ? "in-progress" : "pending"
              }
            ]}
          />
        </div>
      </div> {/* Cierre del div className="relative" */}

      <motion.div 
        className="container py-6 space-y-8"
        initial={{ opacity: 0 }}
        animate={{ opacity: 1 }}
        transition={{ duration: 0.6 }}
      >
        <motion.div
          initial={{ y: 20, opacity: 0 }}
          animate={{ y: 0, opacity: 1 }}
          transition={{ 
            type: "spring",
            stiffness: 300,
            damping: 20,
            delay: 0.1
          }}
        >
          <Card className="p-6 relative overflow-hidden shadow-lg border-none">
            {/* Efectos decorativos m√∫ltiples en la esquina */}
            <div className="absolute top-0 right-0 w-40 h-40 bg-gradient-radial from-orange-400/20 to-transparent rounded-full -translate-y-1/2 translate-x-1/2 pointer-events-none" />
            <div className="absolute top-0 right-0 w-20 h-20 bg-gradient-radial from-purple-500/15 to-transparent rounded-full -translate-y-1/3 translate-x-1/3 pointer-events-none" />
            
            {/* L√≠nea decorativa animada - versi√≥n mejorada */}
            <motion.div 
              className="absolute bottom-0 left-0 h-1.5 bg-gradient-to-r from-orange-500 via-purple-500 to-blue-500 rounded-full"
              initial={{ width: "0%", opacity: 0.7 }}
              animate={{ 
                width: `${(currentStep / 9) * 100}%`,
                opacity: [0.7, 0.9, 0.7]
              }}
              transition={{ 
                width: { duration: 0.8, ease: "easeOut" },
                opacity: { duration: 2, repeat: Infinity, ease: "easeInOut" }
              }}
            />
            
            {/* Borde brillante animado en la parte superior */}
            <motion.div 
              className="absolute top-0 left-0 h-1 w-full bg-gradient-to-r from-blue-500/0 via-purple-500/30 to-orange-500/0"
              animate={{ 
                opacity: [0, 0.8, 0],
                left: ["-100%", "100%"]
              }}
              transition={{ 
                duration: 3, 
                repeat: Infinity, 
                ease: "easeInOut", 
                repeatDelay: 1
              }}
            />
            
          <div className="flex items-center justify-between mb-6">
            <div className="flex items-center gap-4">
              <motion.div 
                className="h-14 w-14 rounded-xl bg-gradient-to-br from-orange-500/20 to-orange-600/10 flex items-center justify-center border border-orange-500/20 shadow-sm"
                whileHover={{ scale: 1.05 }}
                animate={{ 
                  boxShadow: ["0 0 0 rgba(249, 115, 22, 0)", "0 0 12px rgba(249, 115, 22, 0.3)", "0 0 0 rgba(249, 115, 22, 0)"] 
                }}
                transition={{ 
                  boxShadow: { duration: 2, repeat: Infinity, ease: "easeInOut" } 
                }}
              >
                <Video className="h-7 w-7 text-orange-500" />
              </motion.div>
              <div>
                <h2 className="text-2xl font-bold bg-clip-text text-transparent bg-gradient-to-r from-orange-600 to-orange-500">
                  Creador de Videos Musicales AI
                </h2>
                <p className="text-sm text-muted-foreground/90 tracking-wide">
                  Transforma tu m√∫sica en experiencias visuales cautivadoras
                </p>
              </div>
            </div>
            
            {/* Bot√≥n para mostrar Mis Videos */}
            <Button
              onClick={() => setShowMyVideos(!showMyVideos)}
              variant={showMyVideos ? "default" : "outline"}
              className={cn(
                "flex items-center gap-2",
                showMyVideos && "bg-gradient-to-r from-purple-500 to-pink-500 hover:from-purple-600 hover:to-pink-600"
              )}
              data-testid="button-toggle-my-videos"
            >
              <Film className="w-4 h-4" />
              {showMyVideos ? "Volver al Creador" : "Mis Videos"}
            </Button>
          </div>
          
          {/* Dashboard de Mis Videos */}
          {showMyVideos ? (
            <MyGeneratedVideos />
          ) : (
            <>

          {/* Secci√≥n de Pasos de Creaci√≥n */}
          <div className="space-y-6">
            {/* T√≠tulo de la secci√≥n */}
            <motion.div 
              className="border-b border-orange-500/20 pb-4"
              initial={{ opacity: 0, y: -10 }}
              animate={{ opacity: 1, y: 0 }}
              transition={{ duration: 0.5 }}
            >
              <h3 className="text-2xl font-bold bg-clip-text text-transparent bg-gradient-to-r from-orange-600 to-orange-500 flex items-center gap-3">
                <Sparkles className="h-6 w-6 text-orange-500" />
                Pasos de Creaci√≥n
              </h3>
              <p className="text-sm text-muted-foreground mt-2">
                Sigue estos pasos para crear tu video musical con IA
              </p>
            </motion.div>

            <div className="space-y-6">
              <motion.div 
                className="border rounded-lg overflow-hidden p-5 bg-gradient-to-br from-zinc-900 to-black shadow-sm relative border-zinc-800"
                initial={{ opacity: 0, y: 20 }}
                animate={{ 
                  opacity: 1, 
                  y: 0,
                  boxShadow: currentStep >= 2 ? "0 0 0 2px rgba(249, 115, 22, 0.2)" : "none"
                }}
                transition={{ duration: 0.5 }}
              >
                {/* Indicador de paso completado */}
                {currentStep >= 2 && (
                  <motion.div 
                    className="absolute -top-1 -right-1 p-1 rounded-full bg-orange-100 text-orange-600 z-10"
                    initial={{ scale: 0 }}
                    animate={{ scale: 1 }}
                    transition={{ type: "spring", stiffness: 500, damping: 20 }}
                  >
                    <CheckCircle2 className="h-4 w-4" />
                  </motion.div>
                )}
                
                {/* T√≠tulo con icono animado */}
                <div className="flex items-center gap-3 mb-4">
                  <motion.div 
                    className="flex h-8 w-8 items-center justify-center rounded-full bg-orange-100 text-orange-600"
                    whileHover={{ scale: 1.1 }}
                    animate={{ 
                      rotate: isTranscribing ? [0, 10, -10, 0] : 0
                    }}
                    transition={{ 
                      rotate: { repeat: Infinity, duration: 1.5, ease: "easeInOut" },
                      scale: { duration: 0.2 }
                    }}
                  >
                    <Music2 className="h-4 w-4" />
                  </motion.div>
                  <Label className="text-lg font-semibold text-orange-500">1. Subir Audio</Label>
                </div>
                
                <div className="space-y-4">
                  <motion.div 
                    className="relative border-2 border-dashed border-orange-300 rounded-lg p-4 hover:border-orange-400 transition-colors bg-black/50"
                    whileHover={{ scale: 1.01 }}
                    whileTap={{ scale: 0.99 }}
                  >
                    <Input
                      type="file"
                      accept="audio/*,.mp3,.wav,.m4a,.aac,.ogg,.flac,.mp4,.webm,.caf,.aiff,.aifc"
                      onChange={handleFileChange}
                      disabled={isTranscribing}
                      className="absolute inset-0 w-full h-full opacity-0 cursor-pointer z-10"
                      data-testid="input-audio-file"
                    />
                    <div className="flex flex-col items-center justify-center gap-2 pointer-events-none">
                      <Upload className="h-8 w-8 text-orange-400 mb-1" />
                      <p className="font-medium text-sm text-center">Arrastra tu archivo de audio o haz clic para seleccionar</p>
                      <p className="text-xs text-muted-foreground text-center">Soporta todos los formatos de audio (MP3, WAV, M4A, iPhone, etc.)</p>
                    </div>
                  </motion.div>
                  
                  {selectedFile && (
                    <motion.div 
                      className="flex items-center gap-3 text-sm p-3 bg-orange-50 rounded-md border border-orange-100"
                      initial={{ opacity: 0, y: 10 }}
                      animate={{ opacity: 1, y: 0 }}
                      transition={{ duration: 0.3 }}
                    >
                      <div className="bg-orange-100 rounded-full p-1.5">
                        <Music2 className="h-4 w-4 text-orange-600" />
                      </div>
                      <div className="flex-1 truncate">
                        <span className="font-medium">{selectedFile.name}</span>
                        <span className="text-xs text-muted-foreground ml-2">
                          {(selectedFile.size / (1024 * 1024)).toFixed(2)} MB
                        </span>
                      </div>
                    </motion.div>
                  )}
                  
                  {isTranscribing && (
                    <motion.div 
                      className="flex items-center gap-3 text-sm p-3 bg-blue-50 rounded-md"
                      initial={{ opacity: 0, height: 0 }}
                      animate={{ opacity: 1, height: "auto" }}
                      transition={{ duration: 0.4 }}
                    >
                      <div className="bg-blue-100 rounded-full p-1.5 relative">
                        <Loader2 className="h-4 w-4 text-blue-600 animate-spin" />
                        <motion.div 
                          className="absolute inset-0 rounded-full border-2 border-blue-300 border-t-blue-600"
                          animate={{ rotate: 360 }}
                          transition={{ duration: 1.5, repeat: Infinity, ease: "linear" }}
                        />
                      </div>
                      <div>
                        <span className="font-medium">Transcribiendo audio...</span>
                        <span className="text-xs text-muted-foreground ml-2">
                          Procesando datos de voz con IA
                        </span>
                      </div>
                    </motion.div>
                  )}
                </div>
              </motion.div>

              <div className="space-y-6">
                <motion.div 
                  className="border rounded-lg overflow-hidden p-5 bg-gradient-to-br from-zinc-900 to-black shadow-sm relative border-zinc-800"
                  initial={{ opacity: 0, y: 20 }}
                  animate={{ 
                    opacity: 1, 
                    y: 0,
                    boxShadow: currentStep >= 3 ? "0 0 0 2px rgba(79, 70, 229, 0.2)" : "none"
                  }}
                  transition={{ duration: 0.5, delay: 0.1 }}
                >
                  {/* Indicador de paso completado */}
                  {currentStep >= 3 && (
                    <motion.div 
                      className="absolute -top-1 -right-1 p-1 rounded-full bg-orange-100 text-orange-600 z-10"
                      initial={{ scale: 0 }}
                      animate={{ scale: 1 }}
                      transition={{ type: "spring", stiffness: 500, damping: 20 }}
                    >
                      <CheckCircle2 className="h-4 w-4" />
                    </motion.div>
                  )}
                  
                  {/* T√≠tulo con icono animado */}
                  <div className="flex items-center gap-3 mb-4">
                    <motion.div 
                      className="flex h-8 w-8 items-center justify-center rounded-full bg-orange-100 text-orange-600"
                      whileHover={{ scale: 1.1 }}
                      animate={{ 
                        rotate: isGeneratingScript ? [0, 10, -10, 0] : 0
                      }}
                      transition={{ 
                        rotate: { repeat: Infinity, duration: 1.5, ease: "easeInOut" },
                        scale: { duration: 0.2 }
                      }}
                    >
                      <FileText className="h-4 w-4" />
                    </motion.div>
                    <Label className="text-lg font-semibold text-orange-500">2. Transcripci√≥n</Label>
                  </div>
                  
                  <div className="space-y-4">
                    <motion.div 
                      className="relative"
                      animate={{ opacity: 1 }}
                      initial={{ opacity: 0.8 }}
                      transition={{ duration: 0.3 }}
                    >
                      <ScrollArea className="h-[200px] w-full rounded-md border border-orange-500/20 bg-black/80 p-4 shadow-inner">
                        {transcription ? (
                          <motion.pre 
                            className="text-sm whitespace-pre-wrap font-normal text-slate-700"
                            initial={{ opacity: 0 }}
                            animate={{ opacity: 1 }}
                            transition={{ duration: 0.5 }}
                          >
                            {transcription}
                          </motion.pre>
                        ) : (
                          <div className="flex flex-col items-center justify-center h-full text-center opacity-60">
                            <FileText className="h-8 w-8 mb-2 text-slate-400" />
                            <p className="text-sm text-slate-500">Sube un archivo de audio para ver la transcripci√≥n</p>
                          </div>
                        )}
                      </ScrollArea>
                    </motion.div>
                    
                    {/* Mostrar bot√≥n de continuar cuando la transcripci√≥n se ha completado pero no se ha avanzado al paso 2 */}
                    {currentStep === 1.5 && (
                      <motion.div
                        initial={{ opacity: 0, y: 10 }}
                        animate={{ opacity: 1, y: 0 }}
                        transition={{ duration: 0.3 }}
                        className="space-y-4"
                      >
                        {/* Secci√≥n para seleccionar director */}
                        <div className="border border-orange-500/30 rounded-lg p-4 bg-orange-950/20">
                          <div className="flex items-center gap-2 mb-3">
                            <User className="h-5 w-5 text-orange-400" />
                            <Label className="text-base font-semibold text-orange-400">
                              Seleccionar Director
                            </Label>
                          </div>
                          <p className="text-xs text-muted-foreground mb-3">
                            Elige un director para definir el estilo visual del video musical
                          </p>
                          
                          {directors.length > 0 ? (
                            <div className="space-y-3">
                              <Select
                                value={videoStyle.selectedDirector?.id || ""}
                                onValueChange={(directorId) => {
                                  const director = directors.find(d => d.id === directorId);
                                  setVideoStyle(prev => ({
                                    ...prev,
                                    selectedDirector: director || null
                                  }));
                                }}
                              >
                                <SelectTrigger className="bg-black/40">
                                  <SelectValue placeholder="Seleccionar director" />
                                </SelectTrigger>
                                <SelectContent>
                                  {directors.map((director) => (
                                    <SelectItem key={director.id} value={director.id}>
                                      <div className="flex items-center gap-2">
                                        {director.imageUrl && (
                                          <img
                                            src={director.imageUrl}
                                            alt={director.name}
                                            className="w-8 h-8 rounded-full object-cover"
                                          />
                                        )}
                                        <div className="grid gap-0.5">
                                          <span className="font-medium">{director.name}</span>
                                          <span className="text-xs text-muted-foreground">{director.specialty}</span>
                                        </div>
                                      </div>
                                    </SelectItem>
                                  ))}
                                </SelectContent>
                              </Select>

                              {videoStyle.selectedDirector && (
                                <div className="p-3 bg-black/40 rounded-lg border border-orange-500/20">
                                  <div className="flex items-center gap-3">
                                    {videoStyle.selectedDirector.imageUrl && (
                                      <img
                                        src={videoStyle.selectedDirector.imageUrl}
                                        alt={videoStyle.selectedDirector.name}
                                        className="w-12 h-12 rounded-full object-cover"
                                      />
                                    )}
                                    <div className="space-y-1">
                                      <h4 className="font-semibold text-sm">{videoStyle.selectedDirector.name}</h4>
                                      <p className="text-xs text-muted-foreground">{videoStyle.selectedDirector.specialty}</p>
                                      <div className="flex items-center gap-1">
                                        <span className="text-orange-500 text-sm">‚òÖ</span>
                                        <span className="text-xs">{videoStyle.selectedDirector.rating?.toFixed(1) || 'N/A'}</span>
                                      </div>
                                    </div>
                                  </div>
                                </div>
                              )}
                            </div>
                          ) : (
                            <div className="p-3 bg-black/40 rounded-lg">
                              <p className="text-xs text-muted-foreground">Cargando directores...</p>
                            </div>
                          )}
                        </div>
                        
                        {/* Secci√≥n para subir im√°genes de referencia del artista */}
                        <div className="border border-purple-500/30 rounded-lg p-4 bg-purple-950/20">
                          <div className="flex items-center gap-2 mb-3">
                            <ImageIcon className="h-5 w-5 text-purple-400" />
                            <Label className="text-base font-semibold text-purple-400">
                              Im√°genes de Referencia del Artista (Opcional)
                            </Label>
                          </div>
                          <p className="text-xs text-muted-foreground mb-3">
                            Sube hasta 3 fotos del artista para que Nano Banana las use como referencia al generar las escenas del video
                          </p>
                          
                          {/* Grid para mostrar las im√°genes subidas */}
                          {artistReferenceImages.length > 0 && (
                            <div className="grid grid-cols-3 gap-2 mb-3">
                              {artistReferenceImages.map((img, index) => (
                                <div key={index} className="relative group">
                                  <img 
                                    src={img} 
                                    alt={`Referencia ${index + 1}`}
                                    className="w-full h-24 object-cover rounded-md border border-purple-500/40"
                                  />
                                  <button
                                    onClick={() => removeReferenceImage(index)}
                                    className="absolute -top-2 -right-2 bg-red-500 hover:bg-red-600 text-white rounded-full p-1 opacity-0 group-hover:opacity-100 transition-opacity"
                                    data-testid={`remove-reference-${index}`}
                                  >
                                    <X className="h-3 w-3" />
                                  </button>
                                </div>
                              ))}
                            </div>
                          )}
                          
                          {/* Bot√≥n para subir im√°genes */}
                          {artistReferenceImages.length < 3 && (
                            <div className="relative">
                              <Input
                                type="file"
                                accept="image/*,.jpg,.jpeg,.png,.webp,.heic,.heif,.gif,.bmp"
                                multiple
                                onChange={handleReferenceImageUpload}
                                disabled={isUploadingReferences}
                                className="absolute inset-0 w-full h-full opacity-0 cursor-pointer z-10"
                                data-testid="upload-reference-images"
                              />
                              <div className="border-2 border-dashed border-purple-400/40 rounded-lg p-3 hover:border-purple-400 transition-colors bg-purple-950/10 cursor-pointer">
                                <div className="flex flex-col items-center justify-center gap-1">
                                  <Upload className="h-6 w-6 text-purple-400" />
                                  <p className="text-xs font-medium text-center text-purple-300">
                                    {isUploadingReferences ? "Cargando..." : `Subir im√°genes (${artistReferenceImages.length}/3)`}
                                  </p>
                                  <p className="text-xs text-muted-foreground text-center">
                                    Todos los formatos (JPG, PNG, HEIC, WEBP, etc.) - M√°x. 5MB
                                  </p>
                                </div>
                              </div>
                            </div>
                          )}
                        </div>
                        
                        <Button
                          onClick={generateConceptProposals}
                          disabled={!videoStyle.selectedDirector || isGeneratingConcepts}
                          className="w-full bg-gradient-to-r from-orange-500 to-orange-600 hover:from-orange-600 hover:to-orange-700 text-white shadow-md"
                          data-testid="continue-to-next-step"
                        >
                          {isGeneratingConcepts ? (
                            <motion.div className="flex items-center justify-center">
                              <Loader2 className="mr-2 h-4 w-4 animate-spin" />
                              <span>Generando conceptos...</span>
                            </motion.div>
                          ) : (
                            <motion.div 
                              className="flex items-center"
                              whileHover={{ scale: 1.02 }}
                            >
                              <Sparkles className="mr-2 h-4 w-4" />
                              <span>Generar 3 Propuestas de Concepto</span>
                            </motion.div>
                          )}
                        </Button>
                      </motion.div>
                    )}
                    
                    {/* Paso 1.7: Mostrar 3 propuestas de concepto para que el usuario escoja */}
                    {currentStep === 1.7 && conceptProposals.length > 0 && (
                      <motion.div
                        initial={{ opacity: 0, y: 20 }}
                        animate={{ opacity: 1, y: 0 }}
                        transition={{ duration: 0.5 }}
                        className="space-y-4 mt-6"
                      >
                        <div className="text-center mb-6">
                          <h3 className="text-xl font-bold text-orange-500 mb-2">üé¨ Elige tu Concepto Favorito</h3>
                          <p className="text-sm text-muted-foreground">
                            El director {videoStyle.selectedDirector?.name} ha creado 3 propuestas diferentes. Selecciona la que m√°s te guste.
                          </p>
                        </div>
                        
                        <div className="grid grid-cols-1 md:grid-cols-3 gap-4">
                          {conceptProposals.map((concept, index) => (
                            <motion.div
                              key={index}
                              initial={{ opacity: 0, y: 20 }}
                              animate={{ opacity: 1, y: 0 }}
                              transition={{ delay: index * 0.1 }}
                              className={cn(
                                "border rounded-lg p-4 cursor-pointer transition-all",
                                selectedConcept === concept
                                  ? "border-orange-500 bg-orange-500/10 shadow-lg"
                                  : "border-zinc-700 bg-black/40 hover:border-orange-400/50"
                              )}
                              onClick={() => setSelectedConcept(concept)}
                              whileHover={{ scale: 1.02 }}
                              whileTap={{ scale: 0.98 }}
                            >
                              <div className="flex items-center justify-between mb-3">
                                <h4 className="font-bold text-lg text-orange-400">
                                  {concept.title || `Concepto ${index + 1}`}
                                </h4>
                                {selectedConcept === concept && (
                                  <CheckCircle2 className="h-5 w-5 text-orange-500" />
                                )}
                              </div>
                              
                              <div className="space-y-2 text-sm">
                                <div>
                                  <span className="font-semibold text-white">Historia:</span>
                                  <p className="text-muted-foreground line-clamp-3">
                                    {concept.story_concept}
                                  </p>
                                </div>
                                
                                <div>
                                  <span className="font-semibold text-white">Tema Visual:</span>
                                  <p className="text-muted-foreground line-clamp-2">
                                    {concept.visual_theme}
                                  </p>
                                </div>
                                
                                {concept.color_palette && (
                                  <div>
                                    <span className="font-semibold text-white">Paleta:</span>
                                    <div className="flex gap-1 mt-1">
                                      {concept.color_palette.primary_colors?.slice(0, 3).map((color: string, i: number) => (
                                        <div
                                          key={i}
                                          className="w-6 h-6 rounded-full border border-white/20"
                                          style={{ backgroundColor: color }}
                                          title={color}
                                        />
                                      ))}
                                    </div>
                                  </div>
                                )}
                              </div>
                            </motion.div>
                          ))}
                        </div>
                        
                        <Button
                          onClick={() => {
                            if (selectedConcept) {
                              setCurrentStep(2);
                              toast({
                                title: "Concepto seleccionado",
                                description: "Ahora puedes generar el guion completo",
                              });
                            } else {
                              toast({
                                title: "Selecciona un concepto",
                                description: "Haz clic en una de las propuestas para continuar",
                                variant: "destructive",
                              });
                            }
                          }}
                          disabled={!selectedConcept}
                          className="w-full bg-gradient-to-r from-green-500 to-green-600 hover:from-green-600 hover:to-green-700 text-white shadow-md"
                        >
                          <CheckCircle2 className="mr-2 h-4 w-4" />
                          Continuar con este concepto
                        </Button>
                      </motion.div>
                    )}
                    
                    <Button
                      onClick={generateScriptFromTranscription}
                      disabled={!transcription || isGeneratingScript || currentStep < 2}
                      className={cn(
                        "w-full group relative overflow-hidden transition-all",
                        transcription && !isGeneratingScript && currentStep >= 2 
                          ? "bg-gradient-to-r from-orange-500 to-orange-600 hover:from-orange-600 hover:to-orange-700 text-white shadow-md" 
                          : ""
                      )}
                    >
                      {isGeneratingScript ? (
                        <motion.div className="flex items-center justify-center w-full">
                          <motion.div 
                            className="mr-2"
                            animate={{ rotate: 360 }}
                            transition={{ repeat: Infinity, duration: 1, ease: "linear" }}
                          >
                            <Loader2 className="h-4 w-4" />
                          </motion.div>
                          <span>Generando guion...</span>
                        </motion.div>
                      ) : (
                        <motion.div 
                          className="flex items-center justify-center w-full"
                          whileHover={{ scale: 1.02 }}
                          transition={{ duration: 0.2 }}
                        >
                          <FileText className="mr-2 h-4 w-4" />
                          <span>Generar Guion Musical</span>
                        </motion.div>
                      )}
                      
                      {/* Efecto de brillo al pasar el mouse */}
                      {transcription && !isGeneratingScript && currentStep >= 2 && (
                        <motion.div 
                          className="absolute inset-0 w-full h-full bg-gradient-to-r from-transparent via-white/20 to-transparent -translate-x-full"
                          animate={{ translateX: ["100%", "-100%"] }}
                          transition={{ repeat: Infinity, duration: 2, ease: "easeInOut", repeatDelay: 0.5 }}
                        />
                      )}
                    </Button>
                  </div>
                </motion.div>

                <motion.div 
                  className="border rounded-lg overflow-hidden p-5 bg-gradient-to-br from-zinc-900 to-black shadow-sm relative border-zinc-800"
                  initial={{ opacity: 0, y: 20 }}
                  animate={{ 
                    opacity: 1, 
                    y: 0,
                    boxShadow: currentStep >= 4 ? "0 0 0 2px rgba(124, 58, 237, 0.2)" : "none"
                  }}
                  transition={{ duration: 0.5, delay: 0.2 }}
                >
                  {/* Indicador de paso completado */}
                  {currentStep >= 4 && (
                    <motion.div 
                      className="absolute -top-1 -right-1 p-1 rounded-full bg-orange-100 text-orange-600 z-10"
                      initial={{ scale: 0 }}
                      animate={{ scale: 1 }}
                      transition={{ type: "spring", stiffness: 500, damping: 20 }}
                    >
                      <CheckCircle2 className="h-4 w-4" />
                    </motion.div>
                  )}
                  
                  {/* T√≠tulo con icono animado y badge */}
                  <div className="flex justify-between items-center mb-4">
                    <div className="flex items-center gap-3">
                      <motion.div 
                        className="flex h-8 w-8 items-center justify-center rounded-full bg-orange-100 text-orange-600"
                        whileHover={{ scale: 1.1 }}
                        animate={scriptContent ? { 
                          scale: [1, 1.05, 1],
                          rotate: [0, 2, -2, 0]
                        } : {}}
                        transition={{ 
                          repeat: scriptContent ? Infinity : 0,
                          repeatDelay: 3,
                          duration: 1
                        }}
                      >
                        <Film className="h-4 w-4" />
                      </motion.div>
                      <Label className="text-lg font-semibold text-orange-500">3. Guion Profesional</Label>
                    </div>
                    
                    {scriptContent && (
                      <motion.div
                        initial={{ opacity: 0, scale: 0.8 }}
                        animate={{ opacity: 1, scale: 1 }}
                        transition={{ duration: 0.3 }}
                      >
                        <Badge variant="outline" className="bg-gradient-to-r from-amber-50 to-yellow-50 text-amber-800 hover:from-amber-100 hover:to-yellow-100 border-amber-200">
                          <Film className="h-3 w-3 mr-1" />
                          An√°lisis cinematogr√°fico
                        </Badge>
                      </motion.div>
                    )}
                  </div>
                  
                  <div className="space-y-4">
                    {!scriptContent ? (
                      <motion.div 
                        className="flex flex-col items-center justify-center py-8 text-center rounded-md bg-gradient-to-b from-zinc-900 to-black border border-zinc-800 shadow-sm"
                        initial={{ opacity: 0.8 }}
                        animate={{ opacity: 1 }}
                        transition={{ duration: 0.5 }}
                      >
                        <motion.div
                          animate={{ 
                            y: [0, -5, 0],
                            opacity: [0.5, 0.8, 0.5]
                          }}
                          transition={{ 
                            repeat: Infinity,
                            duration: 3,
                            ease: "easeInOut"
                          }}
                        >
                          <Film className="h-14 w-14 mb-3 text-orange-400" />
                        </motion.div>
                        <p className="max-w-md font-medium text-gray-600">El guion profesional se generar√° basado en la transcripci√≥n de la letra.</p>
                        <div className="mt-4 grid grid-cols-3 gap-3 max-w-lg">
                          <div className="flex flex-col items-center p-3 rounded-lg bg-orange-50/50 border border-orange-100">
                            <span className="text-xs font-semibold text-orange-800 mb-1">Estilo</span>
                            <span className="text-[10px] text-center text-orange-600">An√°lisis de g√©nero y est√©tica</span>
                          </div>
                          <div className="flex flex-col items-center p-3 rounded-lg bg-amber-50/50 border border-amber-100">
                            <span className="text-xs font-semibold text-amber-800 mb-1">Arco</span>
                            <span className="text-[10px] text-center text-amber-600">Estructura narrativa</span>
                          </div>
                          <div className="flex flex-col items-center p-3 rounded-lg bg-orange-50/50 border border-orange-100">
                            <span className="text-xs font-semibold text-orange-800 mb-1">T√©cnica</span>
                            <span className="text-[10px] text-center text-orange-600">Direcci√≥n esc√©nica</span>
                          </div>
                        </div>
                      </motion.div>
                    ) : (
                      <motion.div
                        initial={{ opacity: 0, y: 10 }}
                        animate={{ opacity: 1, y: 0 }}
                        transition={{ duration: 0.5 }}
                      >
                        <motion.div 
                          className="grid grid-cols-3 gap-2 text-xs mb-4"
                          initial={{ opacity: 0, y: 5 }}
                          animate={{ opacity: 1, y: 0 }}
                          transition={{ 
                            duration: 0.5,
                            staggerChildren: 0.1
                          }}
                        >
                          <motion.div 
                            className="bg-gradient-to-br from-zinc-900 to-black p-3 rounded-md border border-orange-800/30 shadow-sm"
                            whileHover={{ scale: 1.02, boxShadow: "0 4px 12px rgba(251, 191, 36, 0.1)" }}
                            transition={{ duration: 0.2 }}
                            initial={{ opacity: 0, x: -10 }}
                            animate={{ opacity: 1, x: 0 }}
                          >
                            <span className="font-semibold block text-orange-400">An√°lisis Musical</span>
                            <span className="text-orange-300">G√©nero y estructura</span>
                          </motion.div>
                          <motion.div 
                            className="bg-gradient-to-br from-zinc-900 to-black p-3 rounded-md border border-orange-800/30 shadow-sm"
                            whileHover={{ scale: 1.02, boxShadow: "0 4px 12px rgba(249, 115, 22, 0.1)" }}
                            transition={{ duration: 0.2 }}
                            initial={{ opacity: 0, y: -10 }}
                            animate={{ opacity: 1, y: 0 }}
                            
                          >
                            <span className="font-semibold block text-orange-400">Narrativa Visual</span>
                            <span className="text-orange-300">Arco emocional y mensajes</span>
                          </motion.div>
                          <motion.div 
                            className="bg-gradient-to-br from-zinc-900 to-black p-3 rounded-md border border-orange-800/30 shadow-sm"
                            whileHover={{ scale: 1.02, boxShadow: "0 4px 12px rgba(249, 115, 22, 0.1)" }}
                            transition={{ duration: 0.2 }}
                            initial={{ opacity: 0, x: 10 }}
                            animate={{ opacity: 1, x: 0 }}
                          >
                            <span className="font-semibold block text-orange-400">Direcci√≥n T√©cnica</span>
                            <span className="text-orange-300">Planos, transiciones, mood</span>
                          </motion.div>
                        </motion.div>
                        
                        <motion.div
                          className="relative overflow-hidden rounded-lg"
                          initial={{ opacity: 0 }}
                          animate={{ opacity: 1 }}
                          transition={{ delay: 0.3, duration: 0.5 }}
                        >
                          {/* Efecto de resplandor superior */}
                          <motion.div 
                            className="absolute top-0 left-0 w-full h-[3px] bg-gradient-to-r from-orange-400/0 via-orange-500/50 to-orange-400/0 z-10"
                            animate={{ 
                              opacity: [0.3, 0.7, 0.3]
                            }}
                            transition={{ 
                              duration: 3,
                              repeat: Infinity,
                              ease: "easeInOut"
                            }}
                          />
                          
                          <ScrollArea className="h-[300px] w-full rounded-md border border-zinc-800 p-4 bg-gradient-to-b from-zinc-950 to-zinc-900 text-zinc-100 shadow-inner">
                            <pre className="text-sm whitespace-pre-wrap font-mono leading-relaxed">{scriptContent}</pre>
                          </ScrollArea>
                        </motion.div>
                      </motion.div>
                    )}
                  </div>
                </motion.div>

                <motion.div 
                  ref={visualStyleRef}
                  className="border rounded-lg overflow-hidden p-5 bg-gradient-to-br from-zinc-900 to-black shadow-sm relative border-zinc-800"
                  initial={{ opacity: 0, y: 20 }}
                  animate={{ 
                    opacity: 1, 
                    y: 0,
                    boxShadow: currentStep >= 5 ? "0 0 0 2px rgba(244, 63, 94, 0.2)" : "none"
                  }}
                  transition={{ duration: 0.5, delay: 0.3 }}
                >
                  {/* Indicador de paso completado */}
                  {currentStep >= 5 && (
                    <motion.div 
                      className="absolute -top-1 -right-1 p-1 rounded-full bg-orange-100 text-orange-600 z-10"
                      initial={{ scale: 0 }}
                      animate={{ scale: 1 }}
                      transition={{ type: "spring", stiffness: 500, damping: 20 }}
                    >
                      <CheckCircle2 className="h-4 w-4" />
                    </motion.div>
                  )}
                  
                  {/* T√≠tulo con icono animado */}
                  <div className="flex items-center gap-3 mb-6">
                    <motion.div 
                      className="flex h-8 w-8 items-center justify-center rounded-full bg-orange-100 text-orange-600"
                      whileHover={{ scale: 1.1 }}
                      animate={{ 
                        rotate: [0, -5, 5, 0],
                      }}
                      transition={{ 
                        rotate: { repeat: Infinity, duration: 5, ease: "easeInOut", repeatDelay: 1 },
                        scale: { duration: 0.2 }
                      }}
                    >
                      <ImageIcon className="h-4 w-4" />
                    </motion.div>
                    <div>
                      <Label className="text-lg font-semibold bg-clip-text text-transparent bg-gradient-to-r from-orange-600 to-orange-500">4. Estilo Visual</Label>
                      <p className="text-xs text-muted-foreground">Define la est√©tica visual de tu video musical</p>
                    </div>
                  </div>
                  
                  <div className="grid gap-5">
                    <motion.div 
                      className="space-y-3"
                      initial={{ opacity: 0, y: 10 }}
                      animate={{ opacity: 1, y: 0 }}
                      transition={{ duration: 0.3 }}
                    >
                      <div className="flex items-center justify-between">
                        <Label className="font-medium text-orange-900/80">Formato de C√°mara</Label>
                        <motion.div 
                          className="h-6 w-6 rounded-full bg-orange-50 flex items-center justify-center text-orange-500"
                          whileHover={{ scale: 1.2, backgroundColor: "rgb(255 237 213 / 1)" }}
                          transition={{ duration: 0.2 }}
                        >
                          <Film className="h-3 w-3" />
                        </motion.div>
                      </div>
                      <Select
                        value={videoStyle.cameraFormat}
                        onValueChange={(value) => setVideoStyle(prev => ({ ...prev, cameraFormat: value }))}
                      >
                        <SelectTrigger className="bg-black/90 border-orange-500/20 focus:ring-orange-500 h-11 text-white/90">
                          <SelectValue placeholder="Seleccionar formato de c√°mara" />
                        </SelectTrigger>
                        <SelectContent>
                          {videoStyles.cameraFormats.map((format) => (
                            <SelectItem key={format.name} value={format.name}>
                              <div className="grid gap-1">
                                <span>{format.name}</span>
                                <span className="text-xs text-muted-foreground">{format.description}</span>
                              </div>
                            </SelectItem>
                          ))}
                        </SelectContent>
                      </Select>
                    </motion.div>

                    <div className="grid sm:grid-cols-2 gap-4">
                      <motion.div 
                        className="space-y-3"
                        initial={{ opacity: 0, y: 10 }}
                        animate={{ opacity: 1, y: 0 }}
                        transition={{ duration: 0.3, delay: 0.1 }}
                      >
                        <div className="flex items-center justify-between">
                          <Label className="font-medium text-orange-900/80">Mood</Label>
                          <motion.div 
                            className="h-6 w-6 rounded-full bg-orange-50 flex items-center justify-center text-orange-500"
                            whileHover={{ scale: 1.2, backgroundColor: "rgb(255 237 213 / 1)" }}
                            transition={{ duration: 0.2 }}
                          >
                            <span className="text-xs font-semibold">M</span>
                          </motion.div>
                        </div>
                        <Select
                          value={videoStyle.mood}
                          onValueChange={(value) => setVideoStyle(prev => ({ ...prev, mood: value }))}
                        >
                          <SelectTrigger className="bg-black/90 border-orange-500/20 focus:ring-orange-500 h-11 text-white/90">
                            <SelectValue placeholder="Seleccionar mood" />
                          </SelectTrigger>
                          <SelectContent>
                            {videoStyles.moods.map((mood) => (
                              <SelectItem key={mood} value={mood}>
                                {mood}
                              </SelectItem>
                            ))}
                          </SelectContent>
                        </Select>
                      </motion.div>

                      <motion.div 
                        className="space-y-3"
                        initial={{ opacity: 0, y: 10 }}
                        animate={{ opacity: 1, y: 0 }}
                        transition={{ duration: 0.3, delay: 0.2 }}
                      >
                        <div className="flex items-center justify-between">
                          <Label className="font-medium text-orange-900/80">Paleta de Colores</Label>
                          <div className="flex space-x-1">
                            <motion.div 
                              className="h-4 w-4 rounded-full bg-orange-400"
                              whileHover={{ scale: 1.2 }}
                              transition={{ duration: 0.2 }}
                            />
                            <motion.div 
                              className="h-4 w-4 rounded-full bg-orange-600"
                              whileHover={{ scale: 1.2 }}
                              transition={{ duration: 0.2 }}
                            />
                            <motion.div 
                              className="h-4 w-4 rounded-full bg-zinc-900"
                              whileHover={{ scale: 1.2 }}
                              transition={{ duration: 0.2 }}
                            />
                          </div>
                        </div>
                        <Select
                          value={videoStyle.colorPalette}
                          onValueChange={(value) => setVideoStyle(prev => ({ ...prev, colorPalette: value }))}
                        >
                          <SelectTrigger className="bg-black/90 border-orange-500/20 focus:ring-orange-500 h-11 text-white/90">
                            <SelectValue placeholder="Seleccionar paleta" />
                          </SelectTrigger>
                          <SelectContent>
                            {videoStyles.colorPalettes.map((palette) => (
                              <SelectItem key={palette} value={palette}>
                                {palette}
                              </SelectItem>
                            ))}
                          </SelectContent>
                        </Select>
                      </motion.div>
                    </div>

                    <div className="grid sm:grid-cols-2 gap-4">
                      <motion.div 
                        className="space-y-3"
                        initial={{ opacity: 0, y: 10 }}
                        animate={{ opacity: 1, y: 0 }}
                        transition={{ duration: 0.3, delay: 0.3 }}
                      >
                        <div className="flex items-center justify-between">
                          <Label className="font-medium text-orange-900/80">Estilo de Personajes</Label>
                          <motion.div 
                            className="h-6 w-6 rounded-full bg-orange-50 flex items-center justify-center text-orange-500"
                            whileHover={{ scale: 1.2, backgroundColor: "rgb(255 237 213 / 1)" }}
                            transition={{ duration: 0.2 }}
                          >
                            <User className="h-3 w-3" />
                          </motion.div>
                        </div>
                        <Select
                          value={videoStyle.characterStyle}
                          onValueChange={(value) => setVideoStyle(prev => ({ ...prev, characterStyle: value }))}
                        >
                          <SelectTrigger className="bg-black/90 border-orange-500/20 focus:ring-orange-500 h-11 text-white/90">
                            <SelectValue placeholder="Seleccionar estilo" />
                          </SelectTrigger>
                          <SelectContent>
                            {videoStyles.characterStyles.map((style) => (
                              <SelectItem key={style} value={style}>
                                {style}
                              </SelectItem>
                            ))}
                          </SelectContent>
                        </Select>
                      </motion.div>

                      <motion.div 
                        className="space-y-3"
                        initial={{ opacity: 0, y: 10 }}
                        animate={{ opacity: 1, y: 0 }}
                        transition={{ duration: 0.3, delay: 0.4 }}
                      >
                        <div className="flex items-center justify-between">
                          <Label className="font-medium text-orange-900/80">
                            Intensidad Visual
                            <span className="ml-2 inline-flex items-center justify-center rounded-full bg-orange-100 px-2 py-0.5 text-xs font-medium text-orange-700">
                              {videoStyle.visualIntensity}%
                            </span>
                          </Label>
                        </div>
                        <div className="pt-2">
                          <Slider
                            value={[videoStyle.visualIntensity]}
                            onValueChange={([value]) => setVideoStyle(prev => ({ ...prev, visualIntensity: value }))}
                            max={100}
                            step={1}
                            className="py-2"
                          />
                          <div className="flex justify-between text-xs text-muted-foreground mt-1">
                            <span>Sutil</span>
                            <span>Impactante</span>
                          </div>
                        </div>
                      </motion.div>
                    </div>

                    <motion.div 
                      className="space-y-3 pt-1"
                      initial={{ opacity: 0, y: 10 }}
                      animate={{ opacity: 1, y: 0 }}
                      transition={{ duration: 0.3, delay: 0.5 }}
                    >
                      <div className="flex items-center justify-between">
                        <Label className="font-medium text-orange-900/80">
                          Intensidad Narrativa 
                          <span className="ml-2 inline-flex items-center justify-center rounded-full bg-orange-100 px-2 py-0.5 text-xs font-medium text-orange-700">
                            {videoStyle.narrativeIntensity}%
                          </span>
                        </Label>
                      </div>
                      <p className="text-xs text-muted-foreground">
                        Ajusta qu√© tan fielmente el video sigue la narrativa de la letra
                      </p>
                      <div className="pt-1">
                        <Slider
                          value={[videoStyle.narrativeIntensity]}
                          onValueChange={([value]) => setVideoStyle(prev => ({ ...prev, narrativeIntensity: value }))}
                          max={100}
                          step={1}
                          className="py-2"
                        />
                        <div className="flex justify-between text-xs text-muted-foreground mt-1">
                          <span>Abstracto</span>
                          <span>Literal</span>
                        </div>
                      </div>
                    </motion.div>

                    <div className="space-y-2">
                      <Label>Imagen de Referencia</Label>
                      <div className="grid gap-4">
                        <Input
                          type="file"
                          accept="image/*,.jpg,.jpeg,.png,.webp,.heic,.heif,.gif,.bmp"
                          onChange={async (e) => {
                            const file = e.target.files?.[0];
                            if (file) {
                              const reader = new FileReader();
                              reader.onload = async (e) => {
                                const base64 = e.target?.result as string;
                                setVideoStyle(prev => ({
                                  ...prev,
                                  referenceImage: base64
                                }));
                                await analyzeReferenceImage(base64);
                              };
                              reader.readAsDataURL(file);
                            }
                          }}
                        />
                        {videoStyle.referenceImage && (
                          <div className="relative aspect-video w-full rounded-lg overflow-hidden">
                            <img
                              src={videoStyle.referenceImage}
                              alt="Referencia de estilo"
                              className="object-cover w-full h-full"
                            />
                          </div>
                        )}
                        {videoStyle.styleDescription && (
                          <div className="p-4 bg-muted rounded-lg">
                            <p className="text-sm">{videoStyle.styleDescription}</p>
                          </div>
                        )}
                      </div>
                    </div>

                    <div className="space-y-2">
                      <Label>Director del Video</Label>
                      {directors.length > 0 ? (
                        <div className="grid gap-4">
                          <Select
                            value={videoStyle.selectedDirector?.id || ""}
                            onValueChange={(directorId) => {
                              const director = directors.find(d => d.id === directorId);
                              setVideoStyle(prev => ({
                                ...prev,
                                selectedDirector: director || null
                              }));
                            }}
                          >
                            <SelectTrigger>
                              <SelectValue placeholder="Seleccionar director" />
                            </SelectTrigger>
                            <SelectContent>
                              {directors.map((director) => (
                                <SelectItem key={director.id} value={director.id}>
                                  <div className="flex items-center gap-2">
                                    {director.imageUrl && (
                                      <img
                                        src={director.imageUrl}
                                        alt={director.name}
                                        className="w-8 h-8 rounded-full object-cover"
                                      />
                                    )}
                                    <div className="grid gap-0.5">
                                      <span className="font-medium">{director.name}</span>
                                      <span className="text-xs text-muted-foreground">{director.specialty}</span>
                                    </div>
                                  </div>
                                </SelectItem>
                              ))}
                            </SelectContent>
                          </Select>

                          {videoStyle.selectedDirector && (
                            <div className="p-4 bg-muted rounded-lg">
                              <div className="flex items-center gap-4">
                                {videoStyle.selectedDirector.imageUrl && (
                                  <img
                                    src={videoStyle.selectedDirector.imageUrl}
                                    alt={videoStyle.selectedDirector.name}
                                    className="w-16 h-16 rounded-full object-cover"
                                  />
                                )}
                                <div className="space-y-1">
                                  <h4 className="font-semibold">{videoStyle.selectedDirector.name}</h4>
                                  <p className="text-sm text-muted-foreground">{videoStyle.selectedDirector.experience}</p>
                                  <p className="text-sm">{videoStyle.selectedDirector.style}</p>
                                  <div className="flex items-center gap-1">
                                    <span className="text-orange-500">‚òÖ</span>
                                    <span className="text-sm">{videoStyle.selectedDirector.rating.toFixed(1)}</span>
                                  </div>
                                </div>
                              </div>
                            </div>
                          )}
                        </div>
                      ) : (
                        <div className="p-4 border rounded-lg bg-muted">
                          <p className="text-sm text-muted-foreground">Cargando directores...</p>
                        </div>
                      )}
                    </div>
                  </div>
                </motion.div>

                <motion.div 
                  className="border border-orange-500/30 rounded-lg overflow-hidden p-5 bg-gradient-to-br from-black to-black/70 shadow-sm relative"
                  initial={{ opacity: 0, y: 20 }}
                  animate={{ 
                    opacity: 1, 
                    y: 0,
                    boxShadow: currentStep >= 6 ? "0 0 0 2px rgba(255, 98, 0, 0.4)" : "none"
                  }}
                  transition={{ duration: 0.5, delay: 0.3 }}
                >
                  {/* Indicador de paso completado */}
                  {currentStep >= 6 && (
                    <motion.div 
                      className="absolute -top-1 -right-1 p-1 rounded-full bg-orange-100 text-orange-600 z-10"
                      initial={{ scale: 0 }}
                      animate={{ scale: 1 }}
                      transition={{ type: "spring", stiffness: 500, damping: 20 }}
                    >
                      <CheckCircle2 className="h-4 w-4" />
                    </motion.div>
                  )}
                  
                  {/* T√≠tulo con icono animado */}
                  <div className="flex items-center gap-3 mb-6">
                    <motion.div 
                      className="flex h-8 w-8 items-center justify-center rounded-full bg-orange-500/20 text-orange-500"
                      whileHover={{ scale: 1.1 }}
                      animate={{ 
                        rotate: [0, -3, 3, 0],
                      }}
                      transition={{ 
                        rotate: { repeat: Infinity, duration: 4, ease: "easeInOut", repeatDelay: 1 },
                        scale: { duration: 0.2 }
                      }}
                    >
                      <Waves className="h-4 w-4" />
                    </motion.div>
                    <div>
                      <Label className="text-lg font-semibold bg-clip-text text-transparent bg-gradient-to-r from-orange-500 to-orange-300">5. Crear Timeline</Label>
                      <p className="text-xs text-white/70">Genera el timeline basado en el gui√≥n del video musical</p>
                    </div>
                  </div>
                  
                  <motion.div
                    initial={{ opacity: 0, y: 10 }}
                    animate={{ opacity: 1, y: 0 }}
                    transition={{ duration: 0.3 }}
                  >
                    <Button
                      onClick={syncAudioWithTimeline}
                      disabled={!audioBuffer || isGeneratingShots || currentStep < 3}
                      className="w-full mb-3 h-12 bg-gradient-to-r from-orange-600 to-orange-500 hover:from-orange-700 hover:to-orange-600 border-0 shadow-md"
                    >
                      {isGeneratingShots ? (
                        <motion.div className="flex items-center justify-center gap-2" animate={{ opacity: [0.7, 1] }} transition={{ duration: 0.5, repeat: Infinity, repeatType: "reverse" }}>
                          <Loader2 className="mr-2 h-4 w-4 animate-spin" />
                          <span>Creando timeline desde gui√≥n...</span>
                        </motion.div>
                      ) : (
                        <motion.div className="flex items-center justify-center" whileHover={{ scale: 1.03 }} transition={{ duration: 0.2 }}>
                          <RefreshCcw className="mr-2 h-4 w-4" />
                          <span>Crear Timeline desde Gui√≥n</span>
                        </motion.div>
                      )}
                    </Button>
                  </motion.div>
                </motion.div>

                <div className="border rounded-lg p-4 mt-4">
                  <Label className="text-lg font-semibold mb-4">Estilo de Edici√≥n</Label>
                  <RadioGroup
                    value={selectedEditingStyle.id}
                    onValueChange={(value) => {
                      const style = editingStyles.find(s => s.id === value);
                      if (style) setSelectedEditingStyle(style);
                    }}
                    className="grid grid-cols-2 gap-4"
                  >
                    {editingStyles.map((style) => (
                      <div key={style.id} className="flex items-start space-x-3">
                        <RadioGroupItem value={style.id} id={style.id} />
                        <div className="grid gap-1.5">
                          <Label htmlFor={style.id} className="font-medium">
                            {style.name}
                          </Label>
                          <p className="text-sm text-muted-foreground">
                            {style.description} ({style.duration.min}s - {style.duration.max}s)
                          </p>
                        </div>
                      </div>
                    ))}
                  </RadioGroup>
                </div>

                {/* Project Management */}
                {user && (
                  <div className="mt-6">
                    <ProjectManager
                      userId={user?.id}
                      projectName={projectName}
                      onProjectNameChange={setProjectName}
                      onSaveProject={handleSaveProject}
                      onLoadProject={handleLoadProject}
                      isSaving={isSavingProject}
                      currentProjectId={currentProjectId}
                      hasImages={timelineItems.some(item => item.generatedImage || item.firebaseUrl)}
                      clips={timelineItems as any}
                      audioUrl={audioUrl || undefined}
                      audioDuration={audioDuration}
                      hasUserPaid={hasUserPaid}
                      onShowPaymentGate={() => setShowPaymentGate(true)}
                      videoGenerationsCount={videoGenerationsCount}
                      onVideoRenderComplete={(videoUrl) => {
                        logger.info('‚úÖ Video rendered:', videoUrl);
                        setVideoGenerationsCount(prev => prev + 1);
                      }}
                    />
                  </div>
                )}

                {/* Video Generation with FAL Models */}
                {timelineItems.length > 0 && (
                  <div className="mt-6">
                    <VideoModelSelector
                      onGenerateVideo={handleGenerateIndividualVideo}
                      onGenerateAllVideos={handleGenerateAllVideos}
                      isGenerating={isGeneratingVideos}
                      scenesCount={timelineItems.length}
                      hasImages={timelineItems.some(item => item.generatedImage || item.firebaseUrl)}
                      selectedSceneId={selectedSceneId}
                    />
                  </div>
                )}

                {/* Video Generation Progress */}
                {isGeneratingVideos && videoGenerationProgress.total > 0 && (
                  <div className="mt-4 p-4 border rounded-lg bg-gradient-to-r from-purple-50 to-blue-50 dark:from-purple-950/20 dark:to-blue-950/20">
                    <div className="flex items-center gap-2 mb-2">
                      <Loader2 className="h-4 w-4 animate-spin text-primary" />
                      <span className="font-medium">Generating Videos...</span>
                    </div>
                    <Progress 
                      value={(videoGenerationProgress.current / videoGenerationProgress.total) * 100} 
                      className="h-2"
                    />
                    <p className="text-sm text-muted-foreground mt-2">
                      {videoGenerationProgress.current} of {videoGenerationProgress.total} videos completed
                    </p>
                  </div>
                )}

                {/* Secciones "Generar Prompts" y "Generar Im√°genes" eliminadas - ahora autom√°tico */}

                {/* Componente de Generaci√≥n de Video (Paso 8) */}
                {currentStep === 8 && (
                  <div className="mt-6">
                    <div className="border rounded-lg p-4 mb-6">
                      <Label className="text-lg font-semibold mb-4">8. Generaci√≥n de Video</Label>
                      <p className="text-sm text-muted-foreground mb-4">
                        Genera un video a partir de tus escenas sincronizadas. Este paso utiliza IA para convertir
                        tus im√°genes en secuencias de video fluidas con efectos profesionales.
                      </p>
                      <VideoGenerator
                        onGenerateVideo={async (settings) => {
                          logger.info("Configuraci√≥n para generar video:", settings);
                          toast({
                            title: "Generaci√≥n iniciada",
                            description: `Generando video con modelo ${settings.model}, calidad ${settings.quality}`
                          });
                          await generateVideo();
                        }}
                        isLoading={isGeneratingVideo}
                        scenesCount={timelineItems.length}
                        clips={timelineItems.map(item => ({
                          id: typeof item.id === 'number' ? item.id : parseInt(String(item.id), 10),
                          start: (item.start_time - (timelineItems[0]?.start_time || 0)) / 1000,
                          duration: (item.duration || 0) / 1000,
                          type: 'image' as const,
                          layer: 1, // A√±adimos layer=1 para video/imagen
                          thumbnail: typeof item.generatedImage === 'string' ? item.generatedImage : (typeof item.firebaseUrl === 'string' ? item.firebaseUrl : undefined),
                          title: item.shotType || 'Escena',
                          description: item.description || '',
                          imageUrl: typeof item.generatedImage === 'string' ? item.generatedImage : (typeof item.firebaseUrl === 'string' ? item.firebaseUrl : undefined),
                          imagePrompt: item.imagePrompt,
                          metadata: {
                            section: item.metadata?.section || 'default',
                            movementApplied: item.metadata?.movementApplied,
                            movementPattern: item.metadata?.movementPattern,
                            movementIntensity: item.metadata?.movementIntensity,
                            faceSwapApplied: item.metadata?.faceSwapApplied,
                            musicianIntegrated: item.metadata?.musicianIntegrated
                          }
                        }))}
                        duration={audioBuffer?.duration || 0}
                        isGenerating={isGeneratingVideo}
                        onGenerate={async () => { await generateVideo(); return; }}
                      />
                      {videoId && (
                        <Button 
                          className="w-full mt-4 bg-gradient-to-r from-orange-600 to-orange-500 hover:from-orange-700 hover:to-orange-600 border-0 shadow-md"
                          onClick={() => setCurrentStep(9)}
                        >
                          <CheckCircle2 className="mr-2 h-4 w-4" />
                          Continuar a Renderizado Final
                        </Button>
                      )}
                    </div>
                  </div>
                )}

                {/* Pasos 5, 6, 7 eliminados - flujo simplificado */}

                {/* Paso 8: Generaci√≥n de Video */}
                {currentStep === 8 && (
                  <div className="mt-6">
                    <div className="border rounded-lg p-4 mb-6">
                      <Label className="text-lg font-semibold mb-4">8. Generaci√≥n de Video</Label>
                      <p className="text-sm text-muted-foreground mb-4">
                        Genera videos din√°micos a partir de tus escenas utilizando inteligencia artificial avanzada.
                      </p>
                      <VideoGenerator
                        scenesCount={timelineItems.length}
                        isLoading={isGeneratingVideo}
                        onGenerateVideo={async (settings) => {
                          logger.info("Configuraci√≥n para generar video:", settings);
                          toast({
                            title: "Generaci√≥n iniciada",
                            description: `Generando video con modelo ${settings.model}, calidad ${settings.quality}`
                          });
                          
                          try {
                            await generateVideo();
                            setCurrentStep(9);
                          } catch (error) {
                            logger.error("Error generando video:", error);
                            toast({
                              title: "Error",
                              description: "No se pudo generar el video. Intenta de nuevo.",
                              variant: "destructive"
                            });
                          }
                        }}
                      />
                    </div>
                  </div>
                )}

                {/* Paso 9: Renderizado Final con Upscaling */}
                {currentStep === 9 && (
                  <div className="mt-6">
                    <div className="border rounded-lg p-4 mb-6">
                      <Label className="text-lg font-semibold mb-4">9. Renderizado Final</Label>
                      <p className="text-sm text-muted-foreground mb-4">
                        El proceso de creaci√≥n ha terminado. Ahora puedes mejorar la calidad de tu video musical con Qubico Video Toolkit antes de exportarlo.
                      </p>
                      
                      <FinalRendering
                        timelineClips={timelineItems.map(item => ({
                          id: typeof item.id === 'number' ? item.id : parseInt(String(item.id), 10),
                          start: (item.start_time - (timelineItems[0]?.start_time || 0)) / 1000,
                          duration: (item.duration || 0) / 1000,
                          title: item.shotType || 'Escena',
                          type: 'video' as const,
                          layer: 1, // A√±adimos layer=1 para video/imagen
                          thumbnail: item.generatedImage || fallbackImage
                        }))}
                        videoUrl={generatedVideoUrl || '/assets/Standard_Mode_Generated_Video (2).mp4'}
                        onUpscaleVideo={async (options) => {
                          try {
                            setIsUpscaling(true);
                            // Llamar al servicio real de upscaling
                            const result = await upscaleVideo(
                              generatedVideoUrl || '/assets/Standard_Mode_Generated_Video (2).mp4', 
                              options
                            );
                            
                            if (result.success && result.url) {
                              setUpscaledVideoUrl(result.url);
                              return result.url;
                            } else {
                              throw new Error(result.error || 'Error al mejorar el video');
                            }
                          } catch (error) {
                            logger.error('Error en upscaling:', error);
                            throw error;
                          } finally {
                            setIsUpscaling(false);
                          }
                        }}
                        onDownloadVideo={downloadVideo}
                        onShareVideo={shareMusicVideo}
                      />
                    </div>
                  </div>
                )}

              </div>
            </div>

            {/* Separador visual entre creaci√≥n y edici√≥n avanzada */}
            <motion.div 
              className="my-12 py-8 border-t border-orange-500/30"
              initial={{ opacity: 0, scaleX: 0 }}
              animate={{ opacity: 1, scaleX: 1 }}
              transition={{ duration: 0.6, delay: 0.2 }}
            >
              <motion.div 
                className="border-l-4 border-purple-500 pl-4 mb-6"
                initial={{ opacity: 0, x: -20 }}
                animate={{ opacity: 1, x: 0 }}
                transition={{ duration: 0.5 }}
              >
                <h3 className="text-3xl font-bold bg-clip-text text-transparent bg-gradient-to-r from-purple-600 via-blue-500 to-cyan-500 flex items-center gap-3">
                  <Film className="h-7 w-7 text-purple-500" />
                  Editor de Timeline
                </h3>
                <p className="text-muted-foreground mt-3 text-base">
                  Edita y ajusta las escenas de tu video en el timeline. Perfecciona cada detalle antes de la generaci√≥n final.
                </p>
              </motion.div>
            </motion.div>

            <div className="space-y-6">
              <div className="space-y-4">
                <div className="space-y-4">
                  {/* Enhanced Scenes Gallery */}
                  {timelineItems.length > 0 && (
                    <motion.div
                      initial={{ opacity: 0, y: 10 }}
                      animate={{ opacity: 1, y: 0 }}
                    >
                      <EnhancedScenesGallery
                        scenes={timelineItems}
                        currentTime={currentTime}
                        onSceneClick={(scene, index) => {
                          // Navigate to scene in timeline
                          if (scene.start_time !== undefined) {
                            setCurrentTime(scene.start_time);
                          }
                        }}
                        onRegenerateScene={(sceneId) => {
                          // Use existing regenerate function
                          const id = typeof sceneId === 'string' ? parseInt(sceneId) : sceneId;
                          handleRegenerateImageFromTimeline(id);
                        }}
                        onEditScene={(scene) => {
                          // Open scene editor or allow inline editing
                          toast({
                            title: "Edit Scene",
                            description: "Scene editor will be available soon",
                          });
                        }}
                        onDeleteScene={(sceneId) => {
                          // Remove scene from timeline
                          setTimelineItems(prev => prev.filter(item => item.id !== sceneId));
                          toast({
                            title: "Scene deleted",
                            description: "Scene removed from timeline",
                          });
                        }}
                        onReorderScenes={(reorderedScenes) => {
                          // Update timeline with new order
                          setTimelineItems(reorderedScenes);
                        }}
                        generatingScenes={new Set()}
                      />
                    </motion.div>
                  )}
                  
                  {/* Preview Player - Muestra la imagen actual basada en currentTime */}
                  {/* SIEMPRE visible si hay timeline items, muestra placeholder si falta la imagen */}
                  {timelineItems.length > 0 && (
                    <motion.div
                      initial={{ opacity: 0, y: 10 }}
                      animate={{ opacity: 1, y: 0 }}
                      className="bg-black/60 backdrop-blur-lg border border-white/10 rounded-lg p-4 mb-4"
                    >
                      <div className="flex items-center gap-2 mb-3">
                        <Play className="h-5 w-5 text-green-400" />
                        <h3 className="text-sm font-semibold text-white">Preview en Vivo</h3>
                        <Badge variant="secondary" className="ml-auto">
                          {(currentTime / 1000).toFixed(2)}s / {totalDuration.toFixed(2)}s
                        </Badge>
                      </div>
                      
                      {(() => {
                        // Encontrar la imagen actual basada en currentTime
                        const currentScene = timelineItems.find(item => {
                          const itemStart = item.start_time || 0;
                          const itemEnd = (item.start_time || 0) + (item.duration || 0);
                          return currentTime >= itemStart && currentTime < itemEnd;
                        });
                        
                        const currentImage = currentScene?.imageUrl || currentScene?.thumbnail;
                        
                        return (
                          <div className="relative">
                            {/* Preview de imagen actual */}
                            <div className="aspect-video rounded-lg overflow-hidden bg-black/80 border border-white/20 relative">
                              {currentImage ? (
                                <>
                                  <img
                                    src={currentImage}
                                    alt={currentScene?.title || "Vista previa"}
                                    className="w-full h-full object-contain"
                                  />
                                  {/* Informaci√≥n de la escena actual */}
                                  <div className="absolute bottom-0 left-0 right-0 bg-gradient-to-t from-black via-black/80 to-transparent p-3">
                                    <div className="flex items-center justify-between">
                                      <div className="flex-1">
                                        <p className="text-white font-semibold text-sm mb-1">
                                          {currentScene?.title || "Escena actual"}
                                        </p>
                                        <div className="flex items-center gap-2 text-xs">
                                          {currentScene?.shotType && (
                                            <Badge className="bg-purple-500/80 border-purple-400 text-white font-mono text-[10px] px-1.5 py-0.5">
                                              {currentScene.shotType}
                                            </Badge>
                                          )}
                                          {currentScene?.metadata?.role && (
                                            <Badge className="bg-blue-500/80 border-blue-400 text-white text-[10px] px-1.5 py-0.5">
                                              {currentScene.metadata.role}
                                            </Badge>
                                          )}
                                        </div>
                                      </div>
                                      {isPlaying && (
                                        <div className="flex items-center gap-1.5 text-green-400">
                                          <Activity className="h-4 w-4 animate-pulse" />
                                          <span className="text-[10px] font-semibold">EN VIVO</span>
                                        </div>
                                      )}
                                    </div>
                                  </div>
                                </>
                              ) : (
                                <div className="w-full h-full flex flex-col items-center justify-center gap-3">
                                  <ImageIcon className="h-12 w-12 text-white/20" />
                                  <p className="text-white/40 text-sm">
                                    {currentScene ? "Imagen a√∫n no generada" : "Ninguna escena activa"}
                                  </p>
                                </div>
                              )}
                            </div>
                            
                            {/* Indicador de progreso */}
                            {currentScene && (
                              <div className="mt-2 bg-white/10 rounded-full h-1 overflow-hidden">
                                <div 
                                  className="h-full bg-gradient-to-r from-green-400 to-blue-500 transition-all duration-100"
                                  style={{
                                    width: `${((currentTime - (currentScene.start_time || 0)) / (currentScene.duration || 1)) * 100}%`
                                  }}
                                />
                              </div>
                            )}
                          </div>
                        );
                      })()}
                    </motion.div>
                  )}
                  
                  {/* Timeline Section con ref para scroll autom√°tico */}
                  <div ref={timelineRef} className="w-full">
                    <TimelineEditor
                      initialClips={clips || []}
                      duration={totalDuration || 0}
                      markers={[]}
                      readOnly={false}
                      videoPreviewUrl={undefined}
                      audioPreviewUrl={selectedFile ? URL.createObjectURL(selectedFile) : undefined}
                      onChange={handleClipUpdate || (() => {})}
                      audioBuffer={audioBuffer}
                      genreHint="Pop"
                    />
                  </div>

                  <AnalyticsDashboard
                    clips={clips}
                    audioBuffer={audioBuffer}
                    duration={totalDuration}
                  />

                  {/* Panel de Sugerencias Inteligentes */}
                  {timelineItems.length > 0 && (
                    <SmartSuggestionsPanel
                      timelineItems={timelineItems}
                      onApplySuggestion={(suggestionId) => {
                        logger.info('Aplicando sugerencia:', suggestionId);
                        
                        if (suggestionId === 'pending-images') {
                          // Iniciar generaci√≥n de im√°genes pendientes
                          const pendingItems = timelineItems.filter(item => !item.generatedImage && !item.firebaseUrl);
                          if (pendingItems.length > 0) {
                            toast({
                              title: "Iniciando generaci√≥n",
                              description: `Generando ${pendingItems.length} im√°genes...`,
                            });
                            // Aqu√≠ podr√≠as llamar a la funci√≥n de generaci√≥n
                          }
                        } else if (suggestionId === 'similar-clips') {
                          // Regenerar clips similares con variedad
                          toast({
                            title: "Optimizaci√≥n iniciada",
                            description: "Regenerando clips para mayor variedad...",
                          });
                        }
                      }}
                    />
                  )}

                  {/* Controles de Batch Operations */}
                  {selectedClipIds.length > 0 && (
                    <motion.div
                      initial={{ opacity: 0, y: 20 }}
                      animate={{ opacity: 1, y: 0 }}
                      className="mt-4"
                    >
                      <Card className="bg-gradient-to-r from-blue-600/20 to-blue-500/20 border-blue-500/30 p-4">
                        <div className="flex items-center justify-between gap-4">
                          <div className="flex items-center gap-3">
                            <Badge variant="secondary" className="text-sm">
                              {selectedClipIds.length} clips seleccionados
                            </Badge>
                            <span className="text-sm text-white/70">
                              Operaciones en lote disponibles
                            </span>
                          </div>
                          <div className="flex gap-2">
                            <Button
                              size="sm"
                              variant="outline"
                              onClick={() => setSelectedClipIds([])}
                              className="text-xs"
                              data-testid="button-clear-selection"
                            >
                              Limpiar selecci√≥n
                            </Button>
                            <Button
                              size="sm"
                              onClick={handleBatchRegenerateImages}
                              disabled={isBatchRegenerating}
                              className="bg-blue-600 hover:bg-blue-700 text-xs"
                              data-testid="button-batch-regenerate"
                            >
                              <RefreshCw className={`mr-1 h-3 w-3 ${isBatchRegenerating ? 'animate-spin' : ''}`} />
                              {isBatchRegenerating ? 'Regenerando...' : 'Regenerar todas'}
                            </Button>
                          </div>
                        </div>
                      </Card>
                    </motion.div>
                  )}
                </div>
              </div>
            </div>
          </div>
          </>
          )}
        </Card>
        </motion.div>
      </motion.div>
      
      {/* Load Project Dialog */}
      <Dialog open={showLoadProjectDialog} onOpenChange={setShowLoadProjectDialog}>
        <DialogContent className="max-w-2xl max-h-[80vh] overflow-y-auto">
          <div className="space-y-4">
            <div>
              <h2 className="text-2xl font-bold">Load Project</h2>
              <p className="text-sm text-muted-foreground">Select a project to load</p>
            </div>
            
            {savedProjects.length === 0 ? (
              <div className="text-center py-8 text-muted-foreground">
                <p>No saved projects found</p>
              </div>
            ) : (
              <div className="grid gap-3">
                {savedProjects.map((project) => (
                  <div
                    key={project.id}
                    className="p-4 border rounded-lg hover:bg-accent cursor-pointer transition-colors"
                    onClick={async () => {
                      await handleLoadProject(project.id);
                      setShowLoadProjectDialog(false);
                    }}
                  >
                    <div className="flex justify-between items-start mb-2">
                      <h3 className="font-semibold text-lg">{project.projectName}</h3>
                      <Badge variant={
                        project.status === 'completed' ? 'default' :
                        project.status === 'generating_images' ? 'secondary' :
                        'outline'
                      }>
                        {project.status}
                      </Badge>
                    </div>
                    
                    <div className="text-sm text-muted-foreground space-y-1">
                      {project.progress && (
                        <p>
                          Images: {project.progress.imagesGenerated || 0}/{project.progress.totalImages || 0} ‚Ä¢ 
                          Videos: {project.progress.videosGenerated || 0}/{project.progress.totalVideos || 0}
                        </p>
                      )}
                      <p>Last updated: {new Date(project.updatedAt).toLocaleDateString()}</p>
                    </div>
                  </div>
                ))}
              </div>
            )}
          </div>
        </DialogContent>
      </Dialog>
    </div>
  );
}