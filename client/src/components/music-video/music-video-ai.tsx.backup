import { useState, useEffect, useRef, useCallback, useMemo } from "react";
import { motion, AnimatePresence } from "framer-motion";
import { Button } from "../ui/button";
import { Input } from "../ui/input";
import { Label } from "../ui/label";
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from "../ui/select";
import { Textarea } from "../ui/textarea";
import { TimelineEditor } from "./TimelineEditor";
import type { TimelineClip } from "./TimelineEditor";
import { TimelineClipUnified, ensureCompatibleClip, TimelineItem } from "../timeline/TimelineClipUnified";
import { Slider } from "../ui/slider";
import { Card } from "../ui/card";
import Editor from "@monaco-editor/react";
import {
  Video, Loader2, Music2, Image as ImageIcon, Download, Play, Pause,
  ZoomIn, ZoomOut, SkipBack, FastForward, Rewind, Edit, RefreshCcw, Plus, RefreshCw,
  Film, CheckCircle2, Share, User, Upload, X, Check, Activity, ChevronUp, ChevronDown,
  Megaphone, Waves, HelpCircle, Sparkles
} from "lucide-react";
import { useToast } from "../../hooks/use-toast";
import { ScrollArea } from "../ui/scroll-area";
import { Badge } from "../ui/badge";
import { cn } from "../../lib/utils";
import * as fal from "@fal-ai/serverless-client";
import { getStorage, ref, uploadBytes, getDownloadURL } from "firebase/storage";
import { collection, addDoc, getDocs, serverTimestamp } from "firebase/firestore";
import { db } from "../../firebase";
import { useAuth } from "../../lib/context/auth-context";
import { AnalyticsDashboard } from './analytics-dashboard';
import { RadioGroup, RadioGroupItem } from "../ui/radio-group";
import { VideoGenerator } from "./video-generator";
import { ArtistCustomization } from "./artist-customization";
import { MusicianIntegration } from "./musician-integration";
import { MovementIntegration } from "./movement-integration";
import { LipSyncIntegration } from "./lip-sync-integration";
import { FinalRendering, type UpscaleOptions } from "./final-rendering";
import { ProgressSteps } from "./progress-steps";
import { EnhancedProgressSteps, Step } from "./enhanced-progress-steps";
import { 
  ParticleSystem, 
  AnimatedGradient,
  GlowEffect
} from "./animation-effects";
import { 
  analyzeImage, 
  generateVideoPromptWithRetry, 
  generateMusicVideoScript,
  type VideoPromptParams 
} from "../../lib/api/openrouter";
import { upscaleVideo } from "../../lib/api/video-service";
import { generateVideoScript as generateVideoScriptAPI } from "../../lib/api/openrouter";
import { FileText } from "lucide-react";
import fluxService, { FluxModel, FluxTaskType } from "../../lib/api/flux/flux-service";

// Fal.ai configuration
fal.config({
  credentials: import.meta.env.VITE_FAL_API_KEY,
});

// Transcribe audio using backend API (secure)
async function transcribeAudio(file: File) {
  try {
    const formData = new FormData();
    formData.append('audio', file);

    console.log('üåê Haciendo fetch a /api/audio/transcribe...');
    const response = await fetch('/api/audio/transcribe', {
      method: 'POST',
      body: formData
    });

    console.log('üìä Respuesta del servidor:', response.status, response.statusText);

    let data;
    try {
      data = await response.json();
      console.log('üì¶ Datos recibidos:', data);
    } catch (parseError) {
      console.error('‚ùå Error al parsear JSON de respuesta:', parseError);
      throw new Error('La respuesta del servidor no es JSON v√°lido');
    }

    if (!response.ok || !data.success) {
      const errorMsg = data.error || `Error del servidor: ${response.status} ${response.statusText}`;
      console.error('‚ùå Error en respuesta del servidor:', errorMsg);
      throw new Error(errorMsg);
    }

    if (!data.transcription || !data.transcription.text) {
      console.error('‚ùå Respuesta del servidor no contiene transcripci√≥n');
      throw new Error('La transcripci√≥n no se gener√≥ correctamente');
    }

    return data.transcription.text;
  } catch (error) {
    console.error("‚ùå Error en transcribeAudio:", error);
    if (error instanceof Error) {
      throw error;
    }
    throw new Error('Error desconocido al transcribir el audio');
  }
}

const videoStyles = {
  moods: [
    "Energ√©tico", "Melanc√≥lico", "Rom√°ntico", "Dram√°tico",
    "Misterioso", "Alegre", "√âpico", "Minimalista"
  ],
  colorPalettes: [
    "Vibrante", "Monocrom√°tico", "Pastel", "Oscuro y Contrastado",
    "C√°lido", "Fr√≠o", "Retro", "Ne√≥n"
  ],
  characterStyles: [
    "Realista", "Estilizado", "Art√≠stico", "Abstracto",
    "Cinematogr√°fico", "Documental", "Surrealista", "Vintage"
  ],
  cameraFormats: [
    {
      name: "35mm Est√°ndar",
      description: "El formato cl√°sico del cine, ofrece una imagen natural y cinematogr√°fica"
    },
    {
      name: "IMAX",
      description: "Alto detalle y amplitud visual, ideal para escenas √©picas"
    },
    {
      name: "Super 8mm",
      description: "Look vintage y granulado, perfecto para escenas nost√°lgicas"
    },
    {
      name: "Anam√≥rfico",
      description: "Formato panor√°mico con caracter√≠sticos lens flares"
    },
    {
      name: "PANAVISION",
      description: "Cinematogr√°fico de alta gama con bokeh distintivo"
    },
    {
      name: "Digital RAW",
      description: "Look moderno y n√≠tido con alto rango din√°mico"
    }
  ]
};

const editingStyles = [
  {
    id: "phrases",
    name: "Edici√≥n por Frases",
    description: "Cortes sincronizados con las frases musicales",
    duration: { min: 4, max: 8 }
  },
  {
    id: "random_bars",
    name: "Compases Aleatorios",
    description: "Cortes variados siguiendo el ritmo",
    duration: { min: 2, max: 6 }
  },
  {
    id: "dynamic",
    name: "Din√°mico",
    description: "Cortes r√°pidos en momentos intensos, m√°s lentos en partes suaves",
    duration: { min: 1.5, max: 4 }
  },
  {
    id: "slow",
    name: "Lento",
    description: "Cortes largos y suaves transiciones",
    duration: { min: 5, max: 10 }
  },
  {
    id: "cinematic",
    name: "Cinematogr√°fico",
    description: "Estilo de pel√≠cula con variedad de duraciones",
    duration: { min: 3, max: 8 }
  },
  {
    id: "music_video",
    name: "Video Musical",
    description: "Estilo MTV con cortes r√°pidos y din√°micos",
    duration: { min: 1, max: 3 }
  },
  {
    id: "narrative",
    name: "Narrativo",
    description: "Cortes que siguen la historia de la letra",
    duration: { min: 4, max: 7 }
  },
  {
    id: "experimental",
    name: "Experimental",
    description: "Patrones de corte no convencionales",
    duration: { min: 1, max: 6 }
  },
  {
    id: "rhythmic",
    name: "R√≠tmico",
    description: "Cortes precisos en cada beat",
    duration: { min: 1, max: 2 }
  },
  {
    id: "minimalist",
    name: "Minimalista",
    description: "Pocos cortes, transiciones suaves",
    duration: { min: 6, max: 12 }
  }
];

// Usamos la interfaz TimelineItem importada anteriormente
// No es necesario importarla de nuevo

// Usamos la interfaz TimelineItem importada para mantener compatibilidad
// Definimos un tipo espec√≠fico para nuestra aplicaci√≥n basado en TimelineItem
type MusicVideoTimelineItem = TimelineItem;

const groups = [
  { id: 1, title: "Video", stackItems: true },
  { id: 2, title: "Transiciones", stackItems: false },
  { id: 3, title: "Audio", stackItems: false }
];

const fallbackImage = "data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='100' height='100' viewBox='0 0 24 24' fill='none' stroke='%23888' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='3' width='18' height='18' rx='2' ry='2'/%3E%3Ccircle cx='8.5' cy='8.5' r='1.5'/%3E%3Cpolyline points='21 15 16 10 5 21'/%3E%3C/svg%3E";

interface Director {
  id: string;
  name: string;
  specialty: string;
  style: string;
  experience: string;
  rating: number;
  imageUrl?: string;
}

export function MusicVideoAI() {
  const { toast } = useToast();
  const { user } = useAuth();
  const [selectedFile, setSelectedFile] = useState<File | null>(null);
  const [isTranscribing, setIsTranscribing] = useState(false);
  const [isGeneratingScript, setIsGeneratingScript] = useState(false);
  const [isGeneratingShots, setIsGeneratingShots] = useState(false);
  const [isGeneratingImages, setIsGeneratingImages] = useState(false);
  const [transcription, setTranscription] = useState<string>("");
  const [timelineItems, setTimelineItems] = useState<TimelineItem[]>([]);
  const [isExporting, setIsExporting] = useState(false);
  const [isPlaying, setIsPlaying] = useState(false);
  const [currentTime, setCurrentTime] = useState(0);
  const [zoomLevel, setZoomLevel] = useState(1);
  const [visibleTimeStart, setVisibleTimeStart] = useState<number>(0);
  const [visibleTimeEnd, setVisibleTimeEnd] = useState<number>(60000);
  const [hoveredShot, setHoveredShot] = useState<TimelineItem | null>(null);
  const [selectedShot, setSelectedShot] = useState<TimelineItem | null>(null);
  const [isEditingScript, setIsEditingScript] = useState(false);
  const [videoId, setVideoId] = useState<string>("");
  const [songTitle, setSongTitle] = useState<string>("");
  const [duration, setDuration] = useState<number>(0);
  const [scriptContent, setScriptContent] = useState<string>("");
  const playbackRef = useRef<NodeJS.Timeout | null>(null);
  const [videoStyle, setVideoStyle] = useState({
    mood: "",
    colorPalette: "",
    characterStyle: "",
    visualIntensity: 50,
    cameraFormat: "",
    narrativeIntensity: 50,
    referenceImage: null as string | null,
    styleDescription: "",
    styleReferenceUrl: "",
    selectedDirector: null as Director | null
  });
  const storage = getStorage();
  const [isSaving, setIsSaving] = useState(false);
  const [audioBuffer, setAudioBuffer] = useState<AudioBuffer | undefined>(undefined);
  const [audioUrl, setAudioUrl] = useState<string | null>(null);
  const [transcriptionWithTimestamps, setTranscriptionWithTimestamps] = useState<{
    segments: Array<{
      start: number;
      end: number;
      text: string;
    }>;
  } | null>(null);
  const audioContext = useRef<AudioContext | null>(null);
  const audioSource = useRef<AudioBufferSourceNode | null>(null);
  const [currentStep, setCurrentStep] = useState<number>(1);
  const [selectedEditingStyle, setSelectedEditingStyle] = useState<string>("dynamic");
  const [seed, setSeed] = useState<number>(Math.floor(Math.random() * 1000000));
  const [isGeneratingVideo, setIsGeneratingVideo] = useState(false);
  const [directors, setDirectors] = useState<Director[]>([]);
  const [isUpscaling, setIsUpscaling] = useState(false);
  const [generatedVideoUrl, setGeneratedVideoUrl] = useState<string | null>(null);
  const [upscaledVideoUrl, setUpscaledVideoUrl] = useState<string | null>(null);
  
  // Estado para las 3 im√°genes de referencia del artista (para Nano Banana)
  const [artistReferenceImages, setArtistReferenceImages] = useState<string[]>([]);
  const [isUploadingReferences, setIsUploadingReferences] = useState(false);

  const handleFileChange = useCallback((event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      if (file.size > 50 * 1024 * 1024) {
        toast({
          title: "Error",
          description: "El archivo debe ser menor a 50MB",
          variant: "destructive",
        });
        return;
      }

      if (!file.type.startsWith("audio/")) {
        toast({
          title: "Error",
          description: "Por favor sube un archivo de audio v√°lido (MP3)",
          variant: "destructive",
        });
        return;
      }

      setSelectedFile(file);
      setTranscription("");
      setTimelineItems([]);
      setCurrentTime(0);
      setIsPlaying(false);

      const reader = new FileReader();
      reader.onload = async (e) => {
        if (e.target?.result instanceof ArrayBuffer) {
          if (!audioContext.current) {
            audioContext.current = new AudioContext();
          }
          const buffer = await audioContext.current.decodeAudioData(e.target.result);
          setAudioBuffer(buffer);

          // Usar OpenAI para la transcripci√≥n
          console.log('üé§ Iniciando transcripci√≥n del archivo:', file.name, `(${(file.size / 1024 / 1024).toFixed(2)} MB)`);
          setIsTranscribing(true);
          try {
            console.log('üì§ Enviando archivo al servidor para transcripci√≥n...');
            const transcriptionText = await transcribeAudio(file);
            console.log('‚úÖ Transcripci√≥n completada, longitud:', transcriptionText.length, 'caracteres');
            setTranscription(transcriptionText);
            // Establecer el paso como completado para habilitar el siguiente bot√≥n
            // pero no cambiar la vista (por eso usamos 1.5 en lugar de 2)
            setCurrentStep(1.5);
            toast({
              title: "√âxito",
              description: `Audio transcrito correctamente (${transcriptionText.length} caracteres). Ahora puedes generar el gui√≥n musical.`,
            });
          } catch (err) {
            console.error("‚ùå Error transcribing audio:", err);
            toast({
              title: "Error en transcripci√≥n",
              description: err instanceof Error ? err.message : "Error al transcribir el audio. Por favor intenta de nuevo.",
              variant: "destructive",
            });
          } finally {
            console.log('üèÅ Proceso de transcripci√≥n finalizado');
            setIsTranscribing(false);
          }
        }
      };
      reader.readAsArrayBuffer(file);
    }
  }, [toast]);

  // Funci√≥n para manejar la subida de im√°genes de referencia del artista
  const handleReferenceImageUpload = useCallback(async (event: React.ChangeEvent<HTMLInputElement>) => {
    const files = event.target.files;
    if (!files || files.length === 0) return;

    // Validar que no se suban m√°s de 3 im√°genes en total
    if (artistReferenceImages.length + files.length > 3) {
      toast({
        title: "Error",
        description: "Solo puedes subir un m√°ximo de 3 im√°genes de referencia",
        variant: "destructive",
      });
      return;
    }

    setIsUploadingReferences(true);

    try {
      const newImages: string[] = [];
      
      for (let i = 0; i < files.length && artistReferenceImages.length + newImages.length < 3; i++) {
        const file = files[i];
        
        // Validar tipo de archivo
        if (!file.type.startsWith('image/')) {
          toast({
            title: "Error",
            description: `${file.name} no es una imagen v√°lida`,
            variant: "destructive",
          });
          continue;
        }

        // Validar tama√±o (m√°ximo 5MB por imagen)
        if (file.size > 5 * 1024 * 1024) {
          toast({
            title: "Error",
            description: `${file.name} excede el tama√±o m√°ximo de 5MB`,
            variant: "destructive",
          });
          continue;
        }

        // Convertir imagen a base64
        const base64 = await new Promise<string>((resolve, reject) => {
          const reader = new FileReader();
          reader.onload = () => resolve(reader.result as string);
          reader.onerror = reject;
          reader.readAsDataURL(file);
        });

        newImages.push(base64);
      }

      setArtistReferenceImages([...artistReferenceImages, ...newImages]);
      
      toast({
        title: "√âxito",
        description: `${newImages.length} imagen(es) de referencia agregada(s) (${artistReferenceImages.length + newImages.length}/3)`,
      });
    } catch (error) {
      console.error("Error al cargar im√°genes de referencia:", error);
      toast({
        title: "Error",
        description: "Error al procesar las im√°genes de referencia",
        variant: "destructive",
      });
    } finally {
      setIsUploadingReferences(false);
    }
  }, [artistReferenceImages, toast]);

  // Funci√≥n para eliminar una imagen de referencia
  const removeReferenceImage = useCallback((index: number) => {
    setArtistReferenceImages(prev => prev.filter((_, i) => i !== index));
    toast({
      title: "Imagen eliminada",
      description: `Imagen de referencia ${index + 1} eliminada`,
    });
  }, [toast]);

  const generateScriptFromTranscription = async () => {
    if (!transcription) {
      toast({
        title: "Error",
        description: "Es necesario transcribir el audio primero",
        variant: "destructive",
      });
      return;
    }

    setIsGeneratingScript(true);
    try {
      // Llamar a la API para generar el guion
      toast({
        title: "Procesando",
        description: "Generando guion basado en la letra de la canci√≥n...",
      });

      // Pasar informaci√≥n del director si est√° seleccionado
      const directorInfo = videoStyle.selectedDirector ? {
        name: videoStyle.selectedDirector.name,
        specialty: videoStyle.selectedDirector.specialty,
        style: videoStyle.selectedDirector.style
      } : undefined;
      
      // Pasar duraci√≥n del audio para generar escenas cada ~4 segundos
      const audioDurationInSeconds = audioBuffer?.duration || undefined;
      
      const scriptResponse = await generateMusicVideoScript(
        transcription, 
        undefined, 
        directorInfo,
        audioDurationInSeconds
      );
      
      // Intentar dar formato al JSON para mejor visualizaci√≥n
      try {
        // Verificamos si ya es un string JSON v√°lido, y lo parseamos para darle formato
        const parsed = JSON.parse(scriptResponse);
        setScriptContent(JSON.stringify(parsed, null, 2));
      } catch (parseError) {
        // Si no se puede parsear, usamos directamente la respuesta
        console.warn("No se pudo formatear el JSON del guion, usando respuesta directa", parseError);
        setScriptContent(scriptResponse);
      }
      
      // Marcar este paso como completado
      setCurrentStep(3);
      
      toast({
        title: "√âxito",
        description: "Guion del video musical generado correctamente",
      });
    } catch (error) {
      console.error("Error generando guion:", error);
      toast({
        title: "Error",
        description: error instanceof Error ? error.message : "Error al generar el guion del video musical",
        variant: "destructive",
      });
    } finally {
      setIsGeneratingScript(false);
    }
  };

  const syncAudioWithTimeline = async () => {
    if (!audioBuffer) return;

    if (!scriptContent) {
      toast({
        title: "Error",
        description: "Primero debes generar el gui√≥n del video musical",
        variant: "destructive",
      });
      return;
    }

    setIsGeneratingShots(true);
    try {
      let segments: TimelineItem[] = [];
      
      // Crear segmentos basados en las escenas del JSON del gui√≥n
      try {
        const parsedScript = JSON.parse(scriptContent);
        
        // Verificar el formato del script y extraer las escenas
        let scenes = [];
        if (parsedScript.scenes && Array.isArray(parsedScript.scenes)) {
          // Nuevo formato: { scenes: [...] }
          scenes = parsedScript.scenes;
        } else if (Array.isArray(parsedScript) && parsedScript.length > 0 && parsedScript[0].scene_id) {
          // Formato anterior: array directo de escenas
          scenes = parsedScript;
        }
        
        // Verificar si tenemos escenas v√°lidas
        if (scenes.length > 0 && scenes[0].scene_id) {
          segments = createSegmentsFromScenes(scenes, audioBuffer.duration);
          toast({
            title: "Sincronizando",
            description: `Creando ${segments.length} escenas basadas en el gui√≥n cinematogr√°fico`,
          });
        } else {
          throw new Error("El gui√≥n no contiene escenas v√°lidas");
        }
      } catch (e) {
        console.error("Error al parsear el gui√≥n:", e);
        throw new Error("No se pudo procesar el gui√≥n. Por favor, genera el gui√≥n nuevamente.");
      }
      
      if (segments && segments.length > 0) {
        setTimelineItems(segments);
        setCurrentStep(4);

        toast({
          title: "√âxito",
          description: `${segments.length} escenas sincronizadas con la m√∫sica`,
        });
      } else {
        throw new Error("No se detectaron segmentos en el gui√≥n");
      }
    } catch (error) {
      console.error("Error sincronizando audio:", error);
      toast({
        title: "Error",
        description: error instanceof Error ? error.message : "Error al sincronizar el audio con el timeline",
        variant: "destructive",
      });
    } finally {
      setIsGeneratingShots(false);
    }
  };

  // Nueva funci√≥n para crear segmentos del timeline basados en las escenas del gui√≥n JSON
  // Lee directamente start_time y duration del JSON del script
  const createSegmentsFromScenes = (scenes: any[], totalDuration: number): TimelineItem[] => {
    const segments: TimelineItem[] = [];
    
    scenes.forEach((scene, index) => {
      // LEER directamente start_time y duration del JSON del script
      // NO calcular duraciones iguales - usar los valores aleatorios (3-4 seg) del JSON
      const startTime = (scene.start_time || 0) * 1000; // Convertir segundos a milisegundos
      const duration = (scene.duration || 3.5) * 1000; // Duraci√≥n en milisegundos (default 3.5s)
      const endTime = startTime + duration;
      
      console.log(`üé¨ Creando clip ${scene.scene_id}: start=${scene.start_time}s, duration=${scene.duration}s`);
      
      segments.push({
        id: `scene-${scene.scene_id}`,
        type: 'image', // Tipo imagen para que se muestre correctamente
        group: 1,
        title: scene.title || `Scene ${scene.scene_id}`,
        start_time: startTime,
        end_time: endTime,
        duration: duration,
        shotType: scene.shot_type || scene.camera?.lens || 'MS', // Shot type desde el JSON
        thumbnail: '', // Se asignar√° cuando se genere la imagen
        imageUrl: '', // Se asignar√° cuando se genere la imagen
        itemProps: {
          style: {
            background: `hsl(${(index * 30) % 360}, 70%, 50%)`,
            border: '1px solid rgba(255,255,255,0.3)',
            borderRadius: '4px',
            color: 'white'
          }
        },
        metadata: {
          scene_id: scene.scene_id,
          section: scene.section,
          shot_type: scene.shot_type || scene.camera?.lens,
          role: scene.role,
          camera: scene.camera,
          lighting: scene.lighting,
          environment: scene.environment,
          performance: scene.performance,
          sound: scene.sound,
          emotional_tone: scene.emotional_tone,
          transition: scene.transition,
          production_notes: scene.production_notes
        }
      });
    });
    
    console.log(`‚úÖ ${segments.length} clips creados desde JSON con duraciones aleatorias`);
    return segments;
  };

  // Generar todas las im√°genes para las escenas del timeline usando Gemini con referencias faciales
  const generateAllSceneImages = async () => {
    if (!scriptContent) {
      toast({
        title: "Error",
        description: "Primero debes generar el gui√≥n",
        variant: "destructive",
      });
      return;
    }

    if (artistReferenceImages.length === 0) {
      toast({
        title: "Advertencia",
        description: "No hay im√°genes de referencia. Se generar√°n im√°genes sin consistencia facial",
      });
    }

    setIsGeneratingImages(true);
    try {
      const parsedScript = JSON.parse(scriptContent);
      
      // Extraer las escenas del formato correcto
      let scenes = [];
      if (parsedScript.scenes && Array.isArray(parsedScript.scenes)) {
        scenes = parsedScript.scenes;
      } else if (Array.isArray(parsedScript)) {
        scenes = parsedScript;
      }
      
      if (scenes.length === 0) {
        throw new Error("El gui√≥n no tiene escenas v√°lidas");
      }

      toast({
        title: "Generando im√°genes",
        description: `Iniciando generaci√≥n de ${scenes.length} escenas con Gemini 2.5 Flash Image...`,
      });

      // Preparar las escenas en el formato que espera Gemini usando el NUEVO schema
      const geminiScenes = scenes.map((scene: any) => {
        // Usar los campos del nuevo schema MusicVideoScene
        const shotType = scene.shot_type || "MS";
        const cameraMovement = scene.camera_movement || "static";
        const lens = scene.lens || "standard";
        const lighting = scene.lighting || "natural";
        const visualStyle = scene.visual_style || "cinematic";
        const description = scene.description || "";
        const location = scene.location || "performance space";
        const colorTemp = scene.color_temperature || "5000K";
        
        return {
          id: scene.scene_id || `scene-${Math.random()}`,
          scene: description, // Usar la descripci√≥n completa que ya incluye todos los detalles
          camera: `${lens} lens, ${shotType} shot, ${cameraMovement} movement`,
          lighting: `${lighting} lighting, ${colorTemp} color temperature`,
          style: `${visualStyle} style, ${location}`,
          movement: cameraMovement
        };
      });

      // Llamar al endpoint de Gemini con m√∫ltiples referencias faciales
      const response = await fetch('/api/gemini-image/generate-batch-with-multiple-faces', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          scenes: geminiScenes,
          referenceImagesBase64: artistReferenceImages
        }),
      });

      if (!response.ok) {
        throw new Error(`Error del servidor: ${response.statusText}`);
      }

      const data = await response.json();
      
      if (!data.success || !data.results) {
        throw new Error(data.error || 'Error al generar im√°genes');
      }

      // Actualizar timeline items con las im√°genes generadas
      setTimelineItems(prevItems => {
        // Filtrar solo clips de im√°genes/escenas (excluir audio, texto, etc.)
        const sceneItems = prevItems.filter(item => 
          item.type === 'image' || item.id.toString().startsWith('scene-')
        );
        
        return prevItems.map(item => {
          // Solo procesar clips de im√°genes/escenas
          if (item.type !== 'image' && !item.id.toString().startsWith('scene-')) {
            return item;
          }
          
          // Encontrar el √≠ndice de esta escena en el array filtrado
          const sceneIndex = sceneItems.findIndex(s => s.id === item.id);
          if (sceneIndex === -1) {
            console.warn(`‚ö†Ô∏è No se encontr√≥ √≠ndice de escena para ${item.id}`);
            return item;
          }
          
          // El backend retorna results indexados desde 0
          const imageResult = data.results[sceneIndex];
          
          console.log(`üìç Asignando imagen ${sceneIndex} a ${item.id}:`, imageResult?.success ? 'S√ç' : 'NO', imageResult?.imageUrl ? `URL: ${imageResult.imageUrl.substring(0, 50)}...` : '');
          
          if (imageResult && imageResult.success && imageResult.imageUrl) {
            return {
              ...item,
              imageUrl: imageResult.imageUrl,
              thumbnail: imageResult.imageUrl,
              url: imageResult.imageUrl, // Tambi√©n asignar a url para compatibilidad
              metadata: {
                ...item.metadata,
                isGeneratedImage: true,
                imageGeneratedAt: new Date().toISOString(),
                shot_type: item.shotType || item.metadata?.shot_type,
                role: item.metadata?.role || 'performance'
              }
            };
          }
          
          console.warn(`‚ö†Ô∏è No se pudo asignar imagen a ${item.id}`);
          return item;
        });
      });

      toast({
        title: "¬°√âxito!",
        description: `${parsedScript.length} im√°genes generadas con Gemini Nano Banana`,
      });

      setCurrentStep(5);
    } catch (error) {
      console.error("Error generando im√°genes:", error);
      toast({
        title: "Error",
        description: error instanceof Error ? error.message : "Error al generar las im√°genes",
        variant: "destructive",
      });
    } finally {
      setIsGeneratingImages(false);
    }
  };
  


  const generateVideoScriptFromAudio = async () => {
    if (!transcription || timelineItems.length === 0) return;

    setIsGeneratingScript(true);
    try {
      // Extraemos informaci√≥n de los cortes actuales en el timeline
      const timelineInfo = timelineItems.map((item, index) => ({
        id: item.id,
        start_time: item.start_time,
        end_time: item.end_time,
        duration: item.duration
      }));

      // Calculamos duraci√≥n exacta y n√∫mero total de segmentos
      const totalSegments = timelineItems.length;
      const totalDuration = audioBuffer?.duration || 0;

      const prompt = `Como director de videos musicales profesional, necesito que analices esta canci√≥n y crees un guion detallado, perfectamente sincronizado con los cortes musicales ya identificados.

LETRA DE LA CANCI√ìN:
${transcription}

DURACI√ìN TOTAL: ${totalDuration.toFixed(2)} segundos

INFORMACI√ìN DE CORTES MUSICALES:
${JSON.stringify(timelineInfo, null, 2)}

REQUISITOS ESTRICTOS DE SINCRONIZACI√ìN:
1. Debes crear EXACTAMENTE ${totalSegments} segmentos de guion, uno para cada corte musical predefinido.
2. Cada segmento debe corresponder con una secci√≥n espec√≠fica de la letra que coincida con el tiempo exacto del corte.
3. Si un corte abarca un periodo instrumental sin letra, especifica que es un momento instrumental y describe qu√© deber√≠a mostrarse.

INSTRUCCIONES ESPEC√çFICAS:
1. AN√ÅLISIS DE LETRA Y M√öSICA:
   - Para cada corte, identifica qu√© parte exacta de la letra encaja con su duraci√≥n
   - Describe los elementos musicales precisos que ocurren durante ese corte
   - Se√±ala cualquier cambio de ritmo, tono o instrumentaci√≥n

2. CREACI√ìN DE GUION VISUAL SINCRONIZADO:
   - Para cada segmento, relaciona la escena exactamente con la parte de la letra correspondiente
   - Cada descripci√≥n visual debe reflejar el significado literal o metaf√≥rico de esa parte espec√≠fica de la letra
   - El tipo de plano y mood deben ser apropiados para el momento espec√≠fico de la canci√≥n

ESTRUCTURA REQUERIDA (JSON exacto):
{
  "segments": [
    {
      "id": n√∫mero (debe coincidir con el ID del corte),
      "timeStart": n√∫mero (tiempo de inicio en segundos, debe coincidir con el corte),
      "timeEnd": n√∫mero (tiempo de fin en segundos, debe coincidir con el corte),
      "lyrics": "parte EXACTA de la letra que ocurre durante este corte temporal",
      "musical_elements": "descripci√≥n precisa de los elementos musicales durante este corte",
      "description": "descripci√≥n visual detallada que representa fielmente esta parte espec√≠fica de la letra",
      "imagePrompt": "prompt detallado y espec√≠fico para generar una imagen que capture esta escena",
      "shotType": "tipo de plano espec√≠fico (primer plano, plano medio, plano general, etc.)",
      "mood": "estado de √°nimo preciso basado en esta parte espec√≠fica de la letra y m√∫sica",
      "transition": "tipo de transici√≥n hacia el siguiente segmento"
    }
  ]
}

CRUCIAL:
- Cada segmento debe tener un ID que coincida exactamente con el ID del corte musical correspondiente
- Los tiempos de inicio y fin deben coincidir exactamente con los cortes musicales proporcionados
- Los prompts de imagen deben reflejar ESPEC√çFICAMENTE el contenido de la letra en ese corte exacto
- La descripci√≥n debe explicar expl√≠citamente c√≥mo la escena se relaciona con esa parte espec√≠fica de la letra

LETRA COMPLETA DE LA CANCI√ìN:
${transcription}`;

      // Validamos que el prompt sea una cadena de texto
      if (typeof prompt !== 'string') {
        throw new Error("El prompt debe ser una cadena de texto");
      }
      
      // Llamada a la API para generar el guion con validaci√≥n de tipos
      const jsonContent: string = await generateVideoScriptAPI(prompt);

      try {
        // Validar y procesar la respuesta
        let scriptResult;
        try {
          if (typeof jsonContent === 'string') {
            scriptResult = JSON.parse(jsonContent);
          } else {
            throw new Error("La respuesta no es una cadena de texto v√°lida");
          }
        } catch (parseError) {
          // Intentar extraer JSON v√°lido si est√° dentro de comillas, markdown, etc.
          const error = parseError as Error;
          console.error("Error parsing JSON:", error.message);
          
          // Verificar que jsonContent es un string antes de usar regex
          if (typeof jsonContent === 'string') {
            // Extraer un objeto JSON v√°lido de la respuesta
            try {
              const regex = /\{[\s\S]*"segments"[\s\S]*\}/;
              const match = jsonContent.match(regex);
              if (match && match[0]) {
                scriptResult = JSON.parse(match[0]);
              } else {
                throw new Error("No se pudo encontrar un JSON v√°lido con segmentos");
              }
            } catch (regexError) {
              console.error("Error en la b√∫squeda de JSON con regex:", regexError);
              throw new Error("No se pudo extraer un JSON v√°lido de la respuesta");
            }
          } else {
            throw new Error("La respuesta no es una cadena de texto v√°lida");
          }
        }

        if (!scriptResult || !scriptResult.segments || !Array.isArray(scriptResult.segments)) {
          throw new Error("Formato de guion inv√°lido: no se encontr√≥ el array de segmentos");
        }

        // Crear un mapa para buscar segmentos por ID eficientemente
        const segmentMap = new Map();
        scriptResult.segments.forEach((segment: { id?: number; }) => {
          if (segment && segment.id !== undefined) {
            segmentMap.set(segment.id, segment);
          }
        });

        // Actualizar cada elemento del timeline con la informaci√≥n del guion
        const updatedItems = timelineItems.map(item => {
          const scriptSegment = segmentMap.get(item.id);
          
          if (scriptSegment) {
            return {
              ...item,
              description: `Letra: "${scriptSegment.lyrics || 'Instrumental'}"\n\nM√∫sica: ${scriptSegment.musical_elements || 'N/A'}\n\nEscena: ${scriptSegment.description || 'N/A'}`,
              imagePrompt: `${scriptSegment.imagePrompt || ''} La escena representa estas letras precisas: "${scriptSegment.lyrics || 'Instrumental'}" con elementos musicales: ${scriptSegment.musical_elements || 'ritmo principal'}`,
              shotType: scriptSegment.shotType || 'Plano medio',
              transition: scriptSegment.transition || 'Corte directo',
              mood: scriptSegment.mood || 'Neutral'
            };
          }
          return item;
        });

        setTimelineItems(updatedItems);
        setCurrentStep(4);

        // Guardar el script completo para referencia
        setScriptContent(JSON.stringify(scriptResult, null, 2));

        toast({
          title: "√âxito",
          description: "Guion sincronizado generado correctamente con todos los cortes musicales",
        });

      } catch (parseError) {
        const error = parseError as Error;
        console.error("Error parsing response:", error);
        console.error("Response content:", jsonContent);
        throw new Error("Error al procesar la respuesta del guion: " + error.message);
      }

    } catch (error) {
      console.error("Error generating script:", error);
      toast({
        title: "Error en la generaci√≥n del guion",
        description: error instanceof Error ? error.message : "Error al generar el guion sincronizado del video",
        variant: "destructive",
      });
    } finally {
      setIsGeneratingScript(false);
    }
  };

  /**
   * Genera una imagen para un segmento espec√≠fico utilizando FAL AI
   * @param item - El segmento de timeline para el que se generar√° la imagen
   * @returns Promise<string> URL de la imagen generada o null en caso de error
   */
  const generateImageForSegment = async (item: TimelineItem): Promise<string | null> => {
    if (!item.imagePrompt) {
      console.warn(`Segmento ${item.id} no tiene prompt para generar imagen`);
      return null;
    }

    // N√∫mero de intentos para generaci√≥n de imagen
    const maxAttempts = 2;
    let attempt = 0;
    let lastError: Error | null = null;

    while (attempt < maxAttempts) {
      try {
        // Formateamos el prompt para incluir informaci√≥n de estilo
        const prompt = `${item.imagePrompt}. Style: ${videoStyle.mood}, ${videoStyle.colorPalette} color palette, ${videoStyle.characterStyle} character style, ${item.shotType} composition`;
        
        console.log(`Generando imagen para segmento ${item.id}, intento ${attempt + 1}/${maxAttempts}`);
        console.log(`Prompt: ${prompt.substring(0, 100)}...`);

        // Configuramos los par√°metros para la API de Flux
        const params = {
          prompt: prompt,
          negativePrompt: "low quality, blurry, distorted, deformed, unrealistic, oversaturated, text, watermark",
          width: 1024,
          height: 576, // Relaci√≥n de aspecto 16:9
          guidance_scale: 2.5,
          model: FluxModel.FLUX1_DEV,
          taskType: FluxTaskType.TXT2IMG,
          // Usar una semilla espec√≠fica para cada segmento, pero consistente en regeneraciones
          seed: seed + (typeof item.id === 'string' ? parseInt(item.id, 10) || 0 : item.id)
        };

        // Iniciar la generaci√≥n de imagen con Flux API
        console.log('Iniciando generaci√≥n con Flux API');
        const result = await fluxService.generateImage(params);

        if (!result.success || !result.taskId) {
          throw new Error(`Error iniciando la generaci√≥n de imagen: ${result.error || 'Respuesta inv√°lida'}`);
        }

        console.log(`Tarea de generaci√≥n iniciada con ID: ${result.taskId}`);
        
        // Esperar a que la imagen se genere (polling)
        const imageUrl = await waitForFluxImageGeneration(result.taskId);
        
        if (imageUrl) {
          console.log(`Imagen generada exitosamente para segmento ${item.id}: ${imageUrl}`);
          return imageUrl;
        } else {
          throw new Error("No se recibi√≥ URL de imagen en la respuesta");
        }
      } catch (error) {
        console.error(`Error en intento ${attempt + 1} para segmento ${item.id}:`, error);
        lastError = error instanceof Error ? error : new Error(String(error));
        
        // Si es el √∫ltimo intento, no esperamos
        if (attempt < maxAttempts - 1) {
          const backoffTime = Math.min(1000 * Math.pow(2, attempt), 10000);
          console.log(`Reintentando en ${backoffTime/1000} segundos...`);
          await new Promise(resolve => setTimeout(resolve, backoffTime));
        }
        
        attempt++;
      }
    }

    console.error(`No se pudo generar imagen para segmento ${item.id} despu√©s de ${maxAttempts} intentos:`, lastError);
    return null;
  };

  /**
   * Espera a que se complete la generaci√≥n de imagen en Flux API mediante polling
   * @param taskId ID de la tarea de generaci√≥n de imagen
   * @returns URL de la imagen generada o null si falla
   */
  const waitForFluxImageGeneration = async (taskId: string): Promise<string | null> => {
    const maxAttempts = 40; // M√°ximo n√∫mero de intentos para verificar el estado
    const pollingInterval = 1500; // Intervalo entre verificaciones (1.5 segundos)
    let attempts = 0;

    // Funci√≥n para hacer un √∫nico intento de verificaci√≥n
    const checkStatus = async (): Promise<string | null> => {
      const statusResult = await fluxService.checkTaskStatus(taskId);
      
      console.log(`Estado de la tarea ${taskId}:`, statusResult.status);
      
      if (statusResult.success && statusResult.status === 'completed' && statusResult.images && statusResult.images.length > 0) {
        return statusResult.images[0];
      } else if (!statusResult.success || statusResult.status === 'failed') {
        throw new Error(`La generaci√≥n de imagen fall√≥: ${statusResult.error || 'Error desconocido'}`);
      }
      
      return null; // Todav√≠a procesando
    };

    // Bucle de polling
    while (attempts < maxAttempts) {
      try {
        const result = await checkStatus();
        if (result) {
          return result; // Imagen generada exitosamente
        }
        
        // Esperar antes del siguiente intento
        await new Promise(resolve => setTimeout(resolve, pollingInterval));
        attempts++;
      } catch (error) {
        console.error('Error verificando estado de generaci√≥n:', error);
        return null;
      }
    }

    console.error(`Tiempo de espera agotado despu√©s de ${attempts} intentos para la tarea ${taskId}`);
    return null;
  };

  /**
   * Regenera la imagen para un segmento espec√≠fico
   * @param item - El segmento de timeline cuya imagen se regenerar√°
   */
  const regenerateImage = async (item: TimelineItem) => {
    if (!item.imagePrompt) {
      toast({
        title: "Error",
        description: "Este segmento no tiene un prompt para generar imagen",
        variant: "destructive",
      });
      return;
    }

    try {
      const imageUrl = await generateImageForSegment(item);
      
      if (imageUrl) {
        const updatedItems = timelineItems.map(timelineItem =>
          timelineItem.id === item.id
            ? { ...timelineItem, generatedImage: imageUrl }
            : timelineItem
        );
        setTimelineItems(updatedItems);

        toast({
          title: "Imagen regenerada",
          description: "La imagen se ha regenerado exitosamente",
        });
      } else {
        throw new Error("No se pudo generar la imagen");
      }
    } catch (error) {
      console.error("Error regenerando imagen:", error);
      toast({
        title: "Error",
        description: error instanceof Error ? error.message : "Error al regenerar la imagen",
        variant: "destructive",
      });
    }
  };

  const generateTimelineItems = useCallback((shots: { duration?: string; shotType: string; description: string; imagePrompt?: string; transition?: string }[]) => {
    const baseTime = Date.now();
    let currentTime = baseTime;

    const items = shots.map((shot, index) => {
      const duration = shot.duration ? parseFloat(shot.duration) * 1000 : Math.floor(Math.random() * (5000 - 1000) + 1000);
      const item: TimelineItem = {
        id: index + 1,
        group: 1,
        title: shot.shotType,
        start_time: currentTime,
        end_time: currentTime + duration,
        description: shot.description,
        shotType: shot.shotType,
        imagePrompt: shot.imagePrompt,
        generatedImage: undefined,
        duration: duration,
        transition: shot.transition || "cut",
        // Campos necesarios para compatibilidad con TimelineClip
        start: (currentTime - baseTime) / 1000,
        type: 'image',
        thumbnail: undefined,
        mood: 'neutral'
      };
      currentTime += duration;
      return item;
    });

    setTimelineItems(items);
    setVisibleTimeStart(baseTime);
    setVisibleTimeEnd(currentTime);
    setZoomLevel(1);
  }, []);

  const handleTimeChange = (visibleTimeStart: number, visibleTimeEnd: number) => {
    setVisibleTimeStart(visibleTimeStart);
    setVisibleTimeEnd(visibleTimeEnd);
  };

  const togglePlayback = useCallback(() => {
    if (!audioBuffer || !audioContext.current) return;

    if (isPlaying) {
      audioSource.current?.stop();
      setIsPlaying(false);
    } else {
      const source = audioContext.current.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(audioContext.current.destination);
      source.start(0, currentTime / 1000);
      audioSource.current = source;
      setIsPlaying(true);
    }
  }, [isPlaying, audioBuffer, currentTime]);

  const handleZoomIn = () => {
    setZoomLevel(prev => Math.min(prev * 1.5, 10));
  };

  const handleZoomOut = () => {
    setZoomLevel(prev => Math.max(prev / 1.5, 0.1));
  };

  const handleReset = () => {
    if (timelineItems.length > 0) {
      setCurrentTime(timelineItems[0].start_time);
      setIsPlaying(false);
    }
  };

  const handleSkipForward = () => {
    if (timelineItems.length > 0) {
      const currentIndex = timelineItems.findIndex(item => item.start_time > currentTime);
      if (currentIndex !== -1) {
        setCurrentTime(timelineItems[currentIndex].start_time);
      }
    }
  };

  const handleSkipBackward = () => {
    if (timelineItems.length > 0) {
      const currentIndex = timelineItems.findIndex(item => item.end_time > currentTime) - 1;
      if (currentIndex >= 0) {
        setCurrentTime(timelineItems[currentIndex].start_time);
      } else {
        setCurrentTime(timelineItems[0].start_time);
      }
    }
  };

  const saveToFirebase = async (item: TimelineItem) => {
    if (!item.generatedImage) return null;

    try {
      // Asegurarnos de que generatedImage sea una URL v√°lida (string)
      const imageUrl = typeof item.generatedImage === 'string' ? item.generatedImage : '';
      if (!imageUrl) return null;
      
      const response = await fetch(imageUrl);
      const blob = await response.blob();

      const storageRef = ref(storage, `videos/${Date.now()}_${item.id}.jpg`);
      await uploadBytes(storageRef, blob);
      const url = await getDownloadURL(storageRef);

      return url;
    } catch (error) {
      console.error("Error saving to Firebase:", error);
      return null;
    }
  };

  /**
   * Genera im√°genes para todos los segmentos que tengan prompts
   * Procesa los segmentos en paralelo en batches para optimizar tiempo
   */
  const generateShotImages = async () => {
    if (timelineItems.length === 0) {
      toast({
        title: "Error",
        description: "No hay segmentos para generar im√°genes",
        variant: "destructive",
      });
      return;
    }

    // Verificar que haya prompts generados
    const itemsWithoutPrompts = timelineItems.filter(item => !item.imagePrompt).length;
    if (itemsWithoutPrompts === timelineItems.length) {
      toast({
        title: "Error",
        description: "Los segmentos no tienen prompts para generar im√°genes",
        variant: "destructive",
      });
      return;
    }

    if (itemsWithoutPrompts > 0) {
      toast({
        title: "Advertencia",
        description: `${itemsWithoutPrompts} segmentos no tienen prompts y se omitir√°n`,
        variant: "default",
      });
    }

    setIsGeneratingShots(true);
    try {
      // Limitar a m√°ximo 10 im√°genes para evitar sobrecarga
      const items = timelineItems
        .filter(item => item.imagePrompt && !item.generatedImage) // Solo procesar los que tienen prompt pero no imagen
        .slice(0, 10);

      if (items.length === 0) {
        toast({
          title: "Informaci√≥n",
          description: "Todos los segmentos ya tienen im√°genes generadas",
        });
        setIsGeneratingShots(false);
        return;
      }

      toast({
        title: "Iniciando generaci√≥n",
        description: `Generando ${items.length} im√°genes para el video musical`,
      });

      let successCount = 0;
      let failCount = 0;

      // Procesar en batches de 2 para equilibrar velocidad y estabilidad
      const batchSize = 2;
      
      for (let i = 0; i < items.length; i += batchSize) {
        const currentBatch = items.slice(i, i + batchSize);
        
        try {
          // Mostrar batch actual
          console.log(`Procesando batch ${Math.floor(i/batchSize) + 1} de ${Math.ceil(items.length/batchSize)}`);
          toast({
            title: "Progreso",
            description: `Procesando batch ${Math.floor(i/batchSize) + 1} de ${Math.ceil(items.length/batchSize)}`,
          });

          // Generar im√°genes para el batch actual en paralelo
          const results = await Promise.all(
            currentBatch.map(async (item) => {
              try {
                const imageUrl = await generateImageForSegment(item);
                return {
                  id: item.id,
                  success: true,
                  url: imageUrl
                };
              } catch (error) {
                console.error(`Error en generaci√≥n para segmento ${item.id}:`, error);
                return {
                  id: item.id,
                  success: false,
                  error: error instanceof Error ? error.message : "Error desconocido"
                };
              }
            })
          );

          // Actualizar el timeline con las im√°genes generadas
          let updatedItems = [...timelineItems];
          
          for (const result of results) {
            if (result.success && result.url) {
              // Actualizar el item correspondiente
              updatedItems = updatedItems.map(item => 
                item.id === result.id 
                  ? { ...item, generatedImage: result.url as string } 
                  : item
              );
              successCount++;
            } else {
              failCount++;
              console.error(`Fallo en segmento ${result.id}:`, result.error);
            }
          }
          
          // Actualizar estado solo una vez para todo el batch
          setTimelineItems(updatedItems);

          // Esperar entre batches para evitar rate limits
          if (i + batchSize < items.length) {
            await new Promise(resolve => setTimeout(resolve, 4000));
          }
        } catch (batchError) {
          console.error(`Error procesando batch ${Math.floor(i/batchSize) + 1}:`, batchError);
          toast({
            title: "Error en batch",
            description: `Error en batch ${Math.floor(i/batchSize) + 1}, continuando con el siguiente...`,
            variant: "destructive",
          });
        }
      }

      // Mostrar resultado final
      if (successCount > 0) {
        toast({
          title: "Proceso completado",
          description: `Se generaron ${successCount} de ${items.length} im√°genes ${failCount > 0 ? `(${failCount} fallaron)` : ''}`,
        });
        
        if (successCount >= 1) { // Mostrar vista previa incluso si solo se gener√≥ una imagen
          // Generar ID √∫nico para este video
          const videoId = `video_${Date.now()}`;
          
          // Guardar el videoId en el estado para usarlo en la generaci√≥n del video
          setVideoId(videoId);
          
          // Calcular duraci√≥n total en segundos
          const calculateTotalDuration = () => {
            if (timelineItems.length === 0) return 0;
            const lastItem = timelineItems[timelineItems.length - 1];
            return lastItem.end_time / 1000; // Convertir a segundos
          };
          
          // Extraer palabras clave del primer segmento o usar etiquetas predeterminadas
          const extractTags = () => {
            const firstSegment = timelineItems[0];
            if (firstSegment && firstSegment.description) {
              return firstSegment.description
                .split(' ')
                .filter(word => word.length > 5)
                .slice(0, 5);
            }
            return ['m√∫sica', 'video', 'artista', 'canci√≥n', 'generado'];
          };
          
          // Crear un documento de video en Firestore para futuras referencias
          try {
            const videoRef = collection(db, 'videos');
            await addDoc(videoRef, {
              id: videoId,
              userId: user?.uid,
              title: songTitle || 'Video Musical Generado',
              status: 'preview', // Inicialmente solo vista previa
              createdAt: serverTimestamp(),
              updatedAt: serverTimestamp(),
              duration: duration || calculateTotalDuration(),
              thumbnailUrl: timelineItems.find(item => item.generatedImage)?.generatedImage || '',
              tags: extractTags(),
            });
          } catch (error) {
            console.error('Error guardando informaci√≥n del video:', error);
          }
          
          setCurrentStep(5); // Avanzar al siguiente paso
        }
      } else {
        toast({
          title: "Error",
          description: "No se pudo generar ninguna imagen",
          variant: "destructive",
        });
      }

    } catch (error) {
      console.error("Error en el proceso de generaci√≥n:", error);
      toast({
        title: "Error general",
        description: error instanceof Error ? error.message : "Error en el proceso de generaci√≥n de im√°genes",
        variant: "destructive",
      });
    } finally {
      setIsGeneratingShots(false);
    }
  };

  /**
   * Exporta el video generado basado en las im√°genes y el audio
   * @returns Promise<string> URL del video generado
   */
  const handleExportVideo = async (): Promise<string | null> => {
    if (!timelineItems.length || !audioBuffer) {
      toast({
        title: "Error",
        description: "No hay suficientes elementos para exportar el video",
        variant: "destructive",
      });
      return null;
    }
    
    // Verificar que todos los segmentos tengan im√°genes generadas
    const missingImages = timelineItems.filter(item => !item.generatedImage && !item.firebaseUrl).length;
    if (missingImages > 0) {
      toast({
        title: "Advertencia",
        description: `Faltan ${missingImages} im√°genes por generar. El video puede estar incompleto.`,
        variant: "destructive",
      });
    }
    
    setIsExporting(true);
    try {
      // Primero, guardar todas las im√°genes en Firebase para tener URLs estables
      const savePromises = timelineItems.map(async (item) => {
        if (item.generatedImage && !item.firebaseUrl) {
          const url = await saveToFirebase(item);
          if (url) {
            return {
              id: item.id,
              url
            };
          }
        }
        return {
          id: item.id,
          url: item.firebaseUrl || item.generatedImage
        };
      });
      
      const savedImages = await Promise.all(savePromises);
      
      // Simulamos el proceso de renderizado (en una implementaci√≥n real, aqu√≠ ir√≠a la l√≥gica de FFmpeg)
      await new Promise(resolve => setTimeout(resolve, 3000));
      
      // Crear un simulado video URL (en una implementaci√≥n real, esto ser√≠a una URL de Firebase Storage)
      const mockVideoUrl = `https://storage.googleapis.com/music-video-generator/${Date.now()}_export.mp4`;
      
      toast({
        title: "Exportaci√≥n completada",
        description: "Video disponible para descarga",
      });
      
      setCurrentStep(6); // Marcar como completado

      return mockVideoUrl;
    } catch (error) {
      console.error("Error exportando video:", error);
      toast({
        title: "Error",
        description: error instanceof Error ? error.message : "Error al exportar el video",
        variant: "destructive",
      });
      return null;
    } finally {
      setIsExporting(false);
    }
  };

  const handleScriptChange = (value: string | undefined) => {
    if (!value) return;
    setScriptContent(value);
    try {
      const scriptData = JSON.parse(value);
      
      // Extraer las escenas del formato correcto
      let scenesData = [];
      if (scriptData.scenes && Array.isArray(scriptData.scenes)) {
        // Nuevo formato: { scenes: [...] }
        scenesData = scriptData.scenes;
      } else if (scriptData.segments && Array.isArray(scriptData.segments)) {
        // Formato intermedio
        scenesData = scriptData.segments;
      } else if (scriptData.shots && Array.isArray(scriptData.shots)) {
        // Formato antiguo
        scenesData = scriptData.shots;
      }
      
      // Compatibilidad con diferentes formatos de script
      if (scriptData.shots && Array.isArray(scriptData.shots)) {
        // Formato anterior
        generateTimelineItems(scriptData.shots);
      } else if (scenesData.length > 0) {
        // Nuevo formato de script desde generateMusicVideoScript
        const shotItems = scenesData.map((segment: any) => ({
          shotType: segment.tipo_plano || segment.shotType || "Plano medio",
          description: segment.descripci√≥n_visual || segment.description || "",
          imagePrompt: segment.imagePrompt || "",
          transition: segment.transici√≥n || segment.transition || "corte directo",
          duration: typeof segment.duration === 'number' ? String(segment.duration) : "3"
        }));
        generateTimelineItems(shotItems);
      } else if (scriptData.segmentos && Array.isArray(scriptData.segmentos)) {
        // Formato en espa√±ol
        const shotItems = scriptData.segmentos.map((segmento: any) => ({
          shotType: segmento.tipo_plano || "Plano medio",
          description: segmento.descripci√≥n_visual || "",
          imagePrompt: `Escena musical: ${segmento.descripci√≥n_visual || ""}. Estilo: ${segmento.mood || "neutral"}`,
          transition: segmento.transici√≥n || "corte directo",
          duration: typeof segmento.duration === 'number' ? String(segmento.duration) : "3"
        }));
        generateTimelineItems(shotItems);
      } else {
        console.warn("Formato de script no reconocido:", scriptData);
      }
    } catch (error) {
      console.error("Error parsing script:", error);
      toast({
        title: "Error de formato",
        description: "El script no tiene un formato JSON v√°lido",
        variant: "destructive"
      });
    }
  };

  const itemRenderer = useCallback(({ item, itemContext, getItemProps }: any) => (
    <div
      {...getItemProps()}
      className="relative h-full cursor-pointer group"
      onMouseEnter={() => setHoveredShot(item)}
      onMouseLeave={() => setHoveredShot(null)}
      onClick={() => setSelectedShot(item)}
    >
      <div className={cn(
        "absolute inset-0 bg-card rounded-md border overflow-hidden",
        "transition-all duration-200 ease-in-out",
        currentTime >= item.start_time && currentTime < item.end_time ? "ring-2 ring-orange-500" : "",
        selectedShot?.id === item.id ? "ring-2 ring-blue-500" : "",
        "hover:scale-[1.02] hover:z-10"
      )}>
        <div className="absolute inset-0">
          <img
            src={item.generatedImage || item.firebaseUrl || fallbackImage}
            alt={item.description}
            className="w-full h-full object-cover"
          />
          <div className="absolute inset-0 bg-black/40 p-2 flex flex-col justify-between opacity-0 group-hover:opacity-100 transition-opacity">
            <div>
              <p className="text-xs font-medium text-white truncate">
                {item.shotType}
              </p>
              <p className="text-xs text-white/80 truncate">
                {item.description}
              </p>
            </div>
            <div className="flex items-center justify-between text-xs text-white/60">
              <span>{(item.duration / 1000).toFixed(1)}s</span>
              <span>{item.transition}</span>
            </div>
          </div>
        </div>

        {item.transition && item.transition !== "cut" && (
          <div className="absolute -right-2 top-1/2 -translate-y-1/2 w-4 h-4 bg-orange-500/20 rounded-full z-10">
            <div className="absolute inset-1 bg-orange-500 rounded-full" />
          </div>
        )}
      </div>
    </div>
  ), [currentTime, selectedShot]);

  // Calculamos un estimado de duraci√≥n antes de generar los clips
  // para evitar la dependencia circular
  const estimatedDuration = useMemo(() => {
    // Si tenemos audioBuffer, usamos su duraci√≥n como fuente principal
    if (audioBuffer) {
      return audioBuffer.duration;
    }
    
    // Si tenemos items de timeline, calculamos la duraci√≥n en base a ellos
    if (timelineItems.length > 0) {
      const lastItem = timelineItems[timelineItems.length - 1];
      return (lastItem.end_time - timelineItems[0].start_time) / 1000; // Convertir a segundos
    }
    
    // Duraci√≥n predeterminada si no hay otras fuentes
    return 180; // 3 minutos por defecto
  }, [audioBuffer, timelineItems]);

  // Mapa de clips organizados por capas para el editor profesional multicanal
  const clips: TimelineClip[] = useMemo(() => {
    console.log("üé¨ Generando clips para timeline editor, items:", timelineItems.length);
    
    // Asegurar que siempre hay un clip de audio en la capa 0 si existe audioUrl
    const audioClips = audioUrl ? [
      ensureCompatibleClip({
        id: 9999, // ID especial para audio principal
        start: 0,
        duration: estimatedDuration, // Usamos la duraci√≥n estimada
        type: 'audio' as const,
        layer: 0, // Capa de audio (0)
        title: 'Audio Principal',
        description: 'Pista de audio importada',
        audioUrl: audioUrl,
        visible: true,
        locked: false
      })
    ] : [];
    
    console.log("üîä Audio importado:", audioUrl ? "SI" : "NO");
    
    // Mapear los items de timeline a clips visuales
    const visualClips = timelineItems.map(item => {
      // Determinar el tipo de clip basado en sus propiedades
      let clipType: 'video' | 'image' | 'transition' | 'audio' | 'effect' | 'text' = 'image';
      let clipLayer = 1; // Por defecto, capa de imagen (1)
      
      // Si tiene audioUrl, es un clip de audio adicional
      if (item.audioUrl) {
        clipType = 'audio';
        clipLayer = 0; // Capa de audio (0)
      } 
      // Si tiene textContent, es un clip de texto
      else if (item.metadata?.textContent) {
        clipType = 'text';
        clipLayer = 2; // Capa de texto (2)
      }
      // Si tiene movementApplied, es un clip con efecto
      else if (item.metadata?.movementApplied) {
        clipType = 'effect';
        clipLayer = 3; // Capa de efectos (3)
      }
      // Si tiene videoUrl o lipsyncVideoUrl, es un clip de video
      else if (item.videoUrl || item.metadata?.lipsync?.videoUrl || item.lipsyncVideoUrl) {
        clipType = 'video';
        clipLayer = 1; // Capa de video/imagen (1)
      }
      // Si es una imagen generada por IA (tiene generatedImage)
      else if (item.generatedImage) {
        clipType = 'image';
        clipLayer = 7; // Colocar im√°genes generadas en la capa 7
        console.log(`üé® Imagen generada detectada: ${item.id} - Asignando a capa 7`);
      }
      
      // URL del recurso: priorizar video, luego imagen
      const url = item.videoUrl || 
                  item.metadata?.lipsync?.videoUrl || 
                  item.lipsyncVideoUrl || 
                  item.generatedImage || 
                  item.firebaseUrl || 
                  '';
      
      console.log(`üìç Clip ${item.id} - Tipo: ${clipType}, Capa: ${clipLayer}, URL: ${url ? "SI" : "NO"}`);
      
      // Crear un objeto base con todas las propiedades necesarias
      const clipBase = {
        id: item.id,
        start: (item.start_time - timelineItems[0]?.start_time || 0) / 1000,
        duration: item.duration / 1000,
        // Usar tipo determinado (video, imagen, audio, texto, efecto)
        type: clipType,
        // Usar capa determinada (0=audio, 1=video/imagen, 2=texto, 3=efectos)
        layer: clipLayer,
        thumbnail: item.generatedImage || item.firebaseUrl,
        title: item.shotType || `Clip ${item.id}`,
        description: item.description || '',
        // Propiedades espec√≠ficas por tipo
        imageUrl: (clipType === 'image') ? url : undefined,
        videoUrl: (clipType === 'video') ? url : undefined,
        audioUrl: (clipType === 'audio') ? item.audioUrl : undefined,
        textContent: (clipType === 'text') ? item.metadata?.textContent : undefined,
        // Estado de visibilidad y bloqueo
        visible: true,
        locked: false,
        // Metadatos para preservar el orden exacto del guion
        metadata: {
          sourceIndex: item.id,
          section: item.metadata?.section || 'default',
          movementApplied: !!item.metadata?.movementApplied,
          movementPattern: item.metadata?.movementPattern,
          movementIntensity: item.metadata?.movementIntensity,
          faceSwapApplied: !!item.metadata?.faceSwapApplied,
          // Preservar metadata de lipsync si existe
          lipsync: item.metadata?.lipsync
        }
      };
      
      // Usar ensureCompatibleClip para garantizar compatibilidad con la interfaz unificada
      return ensureCompatibleClip(clipBase);
    });
    
    // Combinar clips de audio con clips visuales
    return [...audioClips, ...visualClips];
  }, [timelineItems, audioUrl, estimatedDuration]);

  // Ahora podemos calcular la duraci√≥n real basada en los clips
  const totalDuration = useMemo(() => {
    return clips.reduce((acc, clip) => Math.max(acc, clip.start + clip.duration), 0);
  }, [clips]);

  const handleTimeUpdate = (time: number) => {
    const baseTime = timelineItems[0]?.start_time || 0;
    setCurrentTime(baseTime + time * 1000);
  };

  const handleClipUpdate = (clipId: number, updates: Partial<TimelineClip>) => {
    const updatedItems = timelineItems.map(item => {
      if (item.id === clipId) {
        // Crear objeto de actualizaci√≥n base
        const updatedItem = { ...item };
        
        // Si se actualizaron las propiedades de tiempo
        if (updates.start !== undefined) {
          updatedItem.start_time = timelineItems[0].start_time + updates.start * 1000;
        }
        
        if (updates.duration !== undefined) {
          updatedItem.duration = updates.duration * 1000;
        }
        
        // Manejar propiedades espec√≠ficas de LipSync
        if (updates.lipsyncApplied !== undefined) {
          // Asegurarse de que el objeto metadata existe
          if (!updatedItem.metadata) {
            updatedItem.metadata = {};
          }
          
          // Actualizar el estado de lipsync en metadata
          updatedItem.metadata.lipsync = {
            ...(updatedItem.metadata.lipsync || {}),
            applied: updates.lipsyncApplied !== undefined ? updates.lipsyncApplied : false,
            timestamp: new Date().toISOString(),
          };
        }
        
        if (updates.lipsyncVideoUrl !== undefined) {
          // Asegurarse de que el objeto metadata existe
          if (!updatedItem.metadata) {
            updatedItem.metadata = {};
          }
          
          // Actualizar la URL del video en metadata
          updatedItem.metadata.lipsync = {
            ...(updatedItem.metadata.lipsync || {}),
            applied: true, // Cuando hay URL de video, siempre aplicamos lipsync
            videoUrl: updates.lipsyncVideoUrl,
            timestamp: new Date().toISOString(), // A√±adir timestamp para seguimiento
          };
        }
        
        // Manejar el progreso de LipSync si est√° presente
        if (updates.lipsyncProgress !== undefined) {
          // Asegurarse de que el objeto metadata existe
          if (!updatedItem.metadata) {
            updatedItem.metadata = {};
          }
          
          // Actualizar el progreso en metadata
          updatedItem.metadata.lipsync = {
            ...(updatedItem.metadata.lipsync || {}),
            progress: updates.lipsyncProgress,
            applied: (updatedItem.metadata.lipsync?.applied === undefined) ? false : updatedItem.metadata.lipsync.applied,
          };
        }
        
        return updatedItem;
      }
      return item;
    });
    
    setTimelineItems(updatedItems);
    
    // Depurar para verificar la actualizaci√≥n
    console.log(`Clip ${clipId} actualizado:`, updates);
  };
  
  // Funci√≥n para manejar la divisi√≥n de clips en la l√≠nea de tiempo
  const handleSplitClip = (clipId: number, splitTime: number) => {
    // Encontrar el clip que se va a dividir
    const clipToSplit = timelineItems.find(item => item.id === clipId);
    if (!clipToSplit) return;
    
    // Calcular la posici√≥n absoluta del punto de divisi√≥n
    const absoluteSplitTime = timelineItems[0].start_time + splitTime * 1000;
    
    // Crear el nuevo clip para la segunda parte
    const newClipId = Math.max(...timelineItems.map(item => item.id)) + 1;
    const relativeStartInClip = splitTime - ((clipToSplit.start_time - timelineItems[0].start_time) / 1000);
    
    // Nuevo clip (segunda parte)
    // Creamos primero un objeto base TimelineItem
    const newClipBase: TimelineItem = {
      ...clipToSplit,
      id: newClipId,
      start_time: absoluteSplitTime,
      end_time: clipToSplit.end_time,
      start: (absoluteSplitTime - timelineItems[0].start_time) / 1000,
      duration: (clipToSplit.end_time - absoluteSplitTime) / 1000,
      // Conservar otros campos importantes
      title: `${clipToSplit.title} (parte 2)`,
    };
    
    // Aseguramos que el nuevo clip es compatible con TimelineClipUnified
    const newClip = ensureCompatibleClip(newClipBase);
    
    // Actualizar la lista de clips
    const updatedItems = timelineItems.map(item => {
      if (item.id === clipId) {
        // Actualizar el clip original (primera parte)
        const updatedItemBase = {
          ...item,
          duration: relativeStartInClip,
          end_time: absoluteSplitTime
        };
        // Asegurar que el clip original modificado tambi√©n sea compatible con TimelineClipUnified
        return ensureCompatibleClip(updatedItemBase);
      }
      return item;
    });
    
    // A√±adir el nuevo clip
    updatedItems.push(newClip);
    
    // Ordenar los clips por tiempo de inicio
    updatedItems.sort((a, b) => {
      // Compatibilidad con ambos formatos (TimelineItem y TimelineClipUnified)
      const aStart = 'start_time' in a ? a.start_time : a.start;
      const bStart = 'start_time' in b ? b.start_time : b.start;
      return aStart - bStart;
    });
    
    // Actualizar el estado
    setTimelineItems(updatedItems as TimelineItem[]);
    
    console.log(`Clip ${clipId} dividido en: ${clipId} y ${newClipId} en tiempo ${splitTime}s`);
  };

  /**
   * Aplica todas las restricciones requeridas a los clips del timeline:
   * 1. Duraci√≥n m√°xima de clips (5 segundos)
   * 2. Im√°genes generadas por IA solo en capa 7
   * 3. No solapamiento de im√°genes en la misma capa
   * @param clips Lista de clips a verificar
   * @returns Lista de clips con restricciones aplicadas
   */
  const enforceAllConstraints = (clips: TimelineItem[]): TimelineItem[] => {
    if (!clips || !clips.length) return [];
    
    // Crear una copia de los clips para no modificar los originales
    const processedClips = [...clips];
    const MAX_CLIP_DURATION = 5 * 1000; // 5 segundos en milisegundos
    
    // Ordenamos los clips por tiempo de inicio para facilitar la detecci√≥n de solapamientos
    processedClips.sort((a, b) => {
      // Garantizar que los clips tienen la propiedad start_time
      const aStart = a.start_time;
      const bStart = b.start_time;
      return aStart - bStart;
    });
    
    // Recorremos todos los clips
    for (let i = 0; i < processedClips.length; i++) {
      const currentClip = processedClips[i];
      
      // 1. Restricci√≥n de duraci√≥n - limitar a 5 segundos m√°ximo
      // Asegurar que la duraci√≥n est√© definida
      const clipDuration = currentClip.duration || (currentClip.end_time - currentClip.start_time);
      
      if (clipDuration > MAX_CLIP_DURATION) {
        console.log(`Ajustando clip ${currentClip.id} de ${clipDuration}ms a ${MAX_CLIP_DURATION}ms`);
        currentClip.duration = MAX_CLIP_DURATION;
        currentClip.end_time = currentClip.start_time + MAX_CLIP_DURATION;
      }
      
      // 2. Restricci√≥n de capa para im√°genes generadas por IA - siempre en capa 7
      if (currentClip.generatedImage || (currentClip.metadata && currentClip.metadata.isGeneratedImage)) {
        if (currentClip.group !== 7) {
          console.log(`Moviendo clip de imagen generada ${currentClip.id} a capa 7`);
          currentClip.group = 7;
        }
      }
      
      // 3. Prevenir solapamiento de clips en la misma capa
      // Solo necesitamos verificar contra los clips que siguen, ya que estamos ordenados
      for (let j = i + 1; j < processedClips.length; j++) {
        const nextClip = processedClips[j];
        
        // Si est√°n en la misma capa y hay solapamiento
        if (currentClip.group === nextClip.group && 
            currentClip.end_time > nextClip.start_time) {
          
          console.log(`Detectado solapamiento entre clips ${currentClip.id} y ${nextClip.id} en capa ${currentClip.group}`);
          
          // Ajustar la duraci√≥n del clip actual para evitar el solapamiento
          const newEndTime = nextClip.start_time;
          const newDuration = newEndTime - currentClip.start_time;
          
          // Solo aplicar el cambio si la nueva duraci√≥n es razonable (m√°s de 0.1 segundos)
          if (newDuration >= 100) {
            console.log(`Ajustando fin de clip ${currentClip.id} de ${currentClip.end_time}ms a ${newEndTime}ms`);
            currentClip.end_time = newEndTime;
            currentClip.duration = newDuration;
          }
          // Si la duraci√≥n resultante es demasiado peque√±a, movemos el clip siguiente
          else if (newDuration < 100) {
            // Calculamos el nuevo start_time para el clip siguiente
            const newStartTime = currentClip.end_time;
            console.log(`Ajustando inicio de clip ${nextClip.id} de ${nextClip.start_time}ms a ${newStartTime}ms`);
            nextClip.start_time = newStartTime;
            nextClip.duration = nextClip.end_time - newStartTime;
          }
        }
      }
    }
    
    return processedClips;
  };

  /**
        let sum = 0;
        for (let j = 0; j < windowSize; j++) {
          if (i + j < channelData.length) {
            sum += Math.abs(channelData[i + j]);
          }
        }
        const energy = sum / windowSize;
        allEnergyValues.push(energy);
        maxEnergy = Math.max(maxEnergy, energy);
      }
      
      // Calcular estad√≠sticas de energ√≠a
      allEnergyValues.sort((a, b) => a - b);
      const medianEnergy = allEnergyValues[Math.floor(allEnergyValues.length / 2)];
      const p75Energy = allEnergyValues[Math.floor(allEnergyValues.length * 0.75)];
      
      // Ajustar threshold basado en estad√≠sticas de energ√≠a si es necesario
      const adjustedThreshold = selectedEditingStyle === "dynamic" 
        ? threshold 
        : Math.max(threshold, medianEnergy * 1.5);
      
      console.log(`Estad√≠sticas de energ√≠a: max=${maxEnergy.toFixed(4)}, mediana=${medianEnergy.toFixed(4)}, p75=${p75Energy.toFixed(4)}, threshold=${adjustedThreshold.toFixed(4)}`);
      
      // Segundo pase: detecci√≥n de beats y construcci√≥n de segmentos
      for (let i = 0; i < channelData.length; i += windowSize) {
        let sum = 0;
        for (let j = 0; j < windowSize; j++) {
          if (i + j < channelData.length) {
            sum += Math.abs(channelData[i + j]);
          }
        }
        const energy = sum / windowSize;
        energyHistory.push(energy);

        if (energyHistory.length > historySize) {
          energyHistory.shift();

          const averageEnergy = energyHistory.reduce((a, b) => a + b) / energyHistory.length;
          const currentTime = i / sampleRate;
          
          // Normalizamos la energ√≠a para tener valores entre 0-1
          const normalizedEnergy = maxEnergy > 0 ? energy / maxEnergy : 0;

          // Detecci√≥n de beat con umbral din√°mico mejorado
          if (energy > averageEnergy * adjustedThreshold &&
              currentTime - lastBeatTime >= minSegmentDuration &&
              currentTime - lastBeatTime <= maxSegmentDuration) {
              
            // Determinar si es un downbeat (beat principal) basado en la energ√≠a relativa
            const isDownbeat = normalizedEnergy > 0.6 || energy > p75Energy * 1.2;

            // Determinar el tipo de beat basado en su intensidad y energ√≠a
            let beatType = "beat";
            if (isDownbeat) {
              beatType = "downbeat"; // Beat principal (m√°s fuerte)
            } else if (normalizedEnergy > 0.4) {
              beatType = "accent"; // Beat con acento (medio)
            }
            
            // Almacenar datos del beat detectado con formato de timecode
            detectedBeats.push({
              time: currentTime,
              timecode: secondsToTimecode(currentTime),
              energy: energy,
              intensity: normalizedEnergy,
              type: beatType,
              isDownbeat: isDownbeat
            });

            // Seleccionar tipo de plano y transici√≥n con ponderaci√≥n
            const shotType = weightedSelection(shotTypes);
            const transition = weightedSelection(transitions).type;

            let segmentDuration = currentTime - lastBeatTime;

            // Ajustar duraci√≥n seg√∫n estilo de edici√≥n
            if (selectedEditingStyle === "dynamic") {
              // Duraci√≥n inversamente proporcional a la energ√≠a - m√°s energ√≠a, cortes m√°s r√°pidos
              segmentDuration = Math.max(minSegmentDuration,
                maxSegmentDuration * (1 - energy / (averageEnergy * 2)));
            } else if (selectedEditingStyle === "minimalist") {
              // Estilo minimalista prefiere tomas m√°s largas
              segmentDuration = Math.max(segmentDuration, minSegmentDuration * 1.5);
            } else if (selectedEditingStyle === "rhythmic") {
              // Estilo r√≠tmico se ajusta exactamente al beat
              segmentDuration = Math.max(minSegmentDuration, Math.min(segmentDuration, maxSegmentDuration * 0.8));
            }

            // Calcula el estado de √°nimo basado en la parte del video (inicio/medio/final)
            const videoProgress = currentTime / totalDuration;
            let mood = 'neutral';
            
            if (videoProgress < 0.25) mood = 'introductory';
            else if (videoProgress > 0.75) mood = 'conclusive';
            else if (energy > averageEnergy * 1.5) mood = 'intense';
            else if (energy < averageEnergy * 0.7) mood = 'calm';

            // Aseguramos que la duraci√≥n no exceda los 5 segundos (MAX_CLIP_DURATION de timeline-constants.ts)
            const maxDuration = 5; // 5 segundos como l√≠mite m√°ximo
            if (segmentDuration > maxDuration) {
              segmentDuration = maxDuration;
              console.log(`Duraci√≥n del segmento ajustada a ${maxDuration} segundos seg√∫n l√≠mite m√°ximo`);
            }
            
            // Creamos segmento base
            const segmentBase = {
              id: segments.length + 1,
              group: 7, // Colocamos las im√°genes generadas en la capa 7 seg√∫n especificaci√≥n
              title: `Escena ${segments.length + 1}`,
              start_time: lastBeatTime * 1000,
              end_time: (lastBeatTime + segmentDuration) * 1000,
              description: shotType.description,
              shotType: shotType.type,
              duration: segmentDuration * 1000,
              transition: transition,
              imagePrompt: shotType.prompt,
              // Campos adicionales para compatibilidad con TimelineClip
              start: lastBeatTime,
              type: 'image' as const, // Usamos type assertion para asegurar compatibilidad
              mood: mood,
              // Datos para an√°lisis
              energy: energy,
              averageEnergy: averageEnergy,
              // Informaci√≥n de timecode para sincronizaci√≥n
              timecode: secondsToTimecode(lastBeatTime),
              endTimecode: secondsToTimecode(lastBeatTime + segmentDuration),
              normalizedEnergy: normalizedEnergy,
              isDownbeat: isDownbeat,
              // Indicador de que es una imagen generada por IA
              metadata: {
                isGeneratedImage: true
              }
            };
            
            // Usamos ensureCompatibleClip para garantizar compatibilidad con TimelineClipUnified
            const compatibleClip = ensureCompatibleClip(segmentBase);
            // Convertimos a TimelineItem para mantener compatibilidad
            segments.push(compatibleClip.toTimelineItem());

            lastBeatTime = currentTime;
          }
        }
      }

      // Asegurarse de que el video cubre la duraci√≥n completa del audio
      if (segments.length > 0) {
        const lastSegment = segments[segments.length - 1];
        if (lastSegment.end_time / 1000 < totalDuration) {
          const finalShotType = weightedSelection(shotTypes);
          
          // Verificar que la duraci√≥n del segmento final no exceda el m√°ximo permitido
          let finalSegmentDuration = (totalDuration * 1000) - lastSegment.end_time;
          const maxDurationMs = 5000; // 5 segundos en milisegundos
          
          if (finalSegmentDuration > maxDurationMs) {
            console.log(`Duraci√≥n del segmento final ajustada de ${finalSegmentDuration}ms a ${maxDurationMs}ms seg√∫n l√≠mite m√°ximo`);
            finalSegmentDuration = maxDurationMs;
            // Ajustar tambi√©n el tiempo de finalizaci√≥n
            const newEndTime = lastSegment.end_time + maxDurationMs;
            if (newEndTime < totalDuration * 1000) {
              // Si a√∫n queda espacio despu√©s del segmento final ajustado, dejaremos un hueco
              console.log(`Ajuste de tiempo final: ${newEndTime}ms (tiempo total: ${totalDuration * 1000}ms)`);
            }
          }
          
          // Crear segmento final usando la misma estructura unificada
          const finalSegmentBase = {
            id: segments.length + 1,
            group: 7, // Colocamos las im√°genes generadas en la capa 7 seg√∫n especificaci√≥n
            title: `Escena Final`,
            start_time: lastSegment.end_time,
            end_time: lastSegment.end_time + finalSegmentDuration,
            description: finalShotType.description,
            shotType: finalShotType.type,
            duration: finalSegmentDuration,
            transition: "fade",
            imagePrompt: finalShotType.prompt,
            // Campos adicionales para compatibilidad con TimelineClip
            start: lastSegment.end_time / 1000,
            type: 'image' as const,
            mood: 'conclusive',
            // Indicador de que es una imagen generada por IA
            metadata: {
              isGeneratedImage: true
            }
          };
          
          // Usar ensureCompatibleClip para garantizar compatibilidad
          const compatibleFinalClip = ensureCompatibleClip(finalSegmentBase);
          // Convertimos a TimelineItem para mantener compatibilidad
          segments.push(compatibleFinalClip.toTimelineItem());
        }
      }

      // Generar el mapa de beats con los datos de timecodes para exportaci√≥n JSON
      const songMetadata = {
        title: selectedFile?.name || "Unknown Track",
        artist: "Artist",
        duration: totalDuration,
        bpm: 0, // Esto se podr√≠a calcular con los datos de beats
        key: "",
        generatedAt: new Date().toISOString()
      };
      
      // Generar el JSON con los beats detectados
      generateBeatsJSON(detectedBeats, songMetadata);
      
      // Aplicar todas las restricciones a los segmentos generados
      const processedSegments = enforceAllConstraints(segments);
      
      console.log(`Generados ${segments.length} segmentos y ${detectedBeats.length} beats detectados para una duraci√≥n de ${totalDuration.toFixed(2)} segundos`);
      console.log(`Segmentos procesados con restricciones: ${processedSegments.length}`);
      return processedSegments;
    } catch (error) {
      console.error("Error en detectBeatsAndCreateSegments:", error);
      toast({
        title: "Error",
        description: "No se pudieron detectar los beats del audio",
        variant: "destructive",
      });
      return [];
    }
  };

  /**
   * Genera un prompt para un segmento de timeline espec√≠fico
   * Extrae las letras correspondientes al segmento y genera un prompt visual
   * @param segment - El segmento de timeline para el que se generar√° el prompt
   * @returns Un string con el prompt generado o un mensaje de error
   */
  const generatePromptForSegment = async (segment: TimelineItem): Promise<string> => {
    if (!segment || typeof segment.id !== 'number') {
      console.error("Segmento inv√°lido:", segment);
      return "Error: segmento inv√°lido";
    }
    
    const maxAttempts = 3;
    let attempt = 0;
    let lastError: Error | null = null;
    
    // Determinar qu√© parte de la transcripci√≥n corresponde a este segmento
    const segmentStartTime = segment.start_time / 1000; // convertir a segundos
    const segmentEndTime = segment.end_time / 1000;
    let relevantLyrics = "";
    
    try {
      console.log(`Generando prompt para segmento ${segment.id} (${segmentStartTime.toFixed(2)}s - ${segmentEndTime.toFixed(2)}s)`);
      
      // PASO 1: EXTRACCI√ìN DE LETRAS RELEVANTES
      // Si tenemos transcripci√≥n con timestamps (m√°s preciso)
      if (transcriptionWithTimestamps && Array.isArray(transcriptionWithTimestamps.segments)) {
        // Buscar segmentos de la transcripci√≥n que coincidan con este segmento de timeline
        const relevantSegments = transcriptionWithTimestamps.segments.filter(
          (s: {start: number, end: number}) => 
            (s.start >= segmentStartTime && s.start <= segmentEndTime) || 
            (s.end >= segmentStartTime && s.end <= segmentEndTime) ||
            (s.start <= segmentStartTime && s.end >= segmentEndTime)
        );
        
        if (relevantSegments.length > 0) {
          relevantLyrics = relevantSegments
            .map((s: {text: string}) => s.text || "")
            .filter(text => text.trim().length > 0)
            .join(" ");
          
          console.log(`Encontrados ${relevantSegments.length} segmentos con timestamps para este fragmento`);
        }
      }
      
      // Si no hay letras espec√≠ficas, usar transcripci√≥n general
      if (!relevantLyrics && transcription) {
        // Dividir la transcripci√≥n total proporcionalmente
        const totalDuration = timelineItems.length > 0 ? 
          (timelineItems[timelineItems.length - 1].end_time / 1000) - (timelineItems[0].start_time / 1000) : 0;
          
        if (totalDuration > 0) {
          const segmentDuration = segmentEndTime - segmentStartTime;
          const segmentPercent = segmentDuration / totalDuration;
          const startPercent = (segmentStartTime - (timelineItems[0].start_time / 1000)) / totalDuration;
          
          // Estimar qu√© parte de la transcripci√≥n corresponde a este segmento
          const transcriptionWords = transcription.split(/\s+/);
          const startWordIndex = Math.floor(startPercent * transcriptionWords.length);
          const wordCount = Math.max(1, Math.floor(segmentPercent * transcriptionWords.length));
          
          if (startWordIndex >= 0 && wordCount > 0 && startWordIndex < transcriptionWords.length) {
            const endWordIndex = Math.min(startWordIndex + wordCount, transcriptionWords.length);
            relevantLyrics = transcriptionWords.slice(startWordIndex, endWordIndex).join(" ");
            console.log(`Usando transcripci√≥n proporcional: palabras ${startWordIndex}-${endWordIndex} de ${transcriptionWords.length}`);
          }
        }
      }

      // Si a√∫n no tenemos letras, usar informaci√≥n contextual basada en el segmento
      if (!relevantLyrics || relevantLyrics.trim().length === 0) {
        // Determinar contexto basado en la posici√≥n en el video y caracter√≠sticas del segmento
        const isBeginningSong = timelineItems.indexOf(segment) < Math.min(3, timelineItems.length * 0.2);
        const isEndingSong = timelineItems.indexOf(segment) > timelineItems.length * 0.8;
        const isHighEnergy = segment.energy && segment.averageEnergy && segment.energy > segment.averageEnergy * 1.3;
        const isLowEnergy = segment.energy && segment.averageEnergy && segment.energy < segment.averageEnergy * 0.7;
        
        if (isHighEnergy) {
          relevantLyrics = isBeginningSong 
            ? "Introducci√≥n en√©rgica e intensa" 
            : isEndingSong 
              ? "Climax final con gran energ√≠a" 
              : "Secci√≥n instrumental con alta intensidad";
        } else if (isLowEnergy) {
          relevantLyrics = isBeginningSong 
            ? "Introducci√≥n suave y atmosf√©rica" 
            : isEndingSong 
              ? "Cierre mel√≥dico y reflexivo" 
              : "Interludio tranquilo y contemplativo";
        } else {
          relevantLyrics = isBeginningSong 
            ? "Introducci√≥n de la canci√≥n" 
            : isEndingSong 
              ? "Conclusi√≥n de la canci√≥n" 
              : "Instrumental";
        }
        
        console.log(`No se encontraron letras espec√≠ficas, usando contexto: "${relevantLyrics}"`);
      }

      // PASO 2: GENERACI√ìN DEL PROMPT CON M√öLTIPLES INTENTOS
      while (attempt < maxAttempts) {
        try {
          console.log(`Generando prompt para segmento ${segment.id}, intento ${attempt + 1}/${maxAttempts}`);
          
          // Validar par√°metros del estilo de video antes de crear el prompt
          if (!videoStyle.cameraFormat || !videoStyle.mood || !videoStyle.characterStyle || 
              !videoStyle.colorPalette || videoStyle.visualIntensity === undefined || 
              videoStyle.narrativeIntensity === undefined) {
            console.error("Estilos de video incompletos:", videoStyle);
            throw new Error("Faltan par√°metros de estilo para generar el prompt");
          }
          
          // Preparar par√°metros para el prompt con tipado
          const promptParams: VideoPromptParams = {
            shotType: segment.shotType || "medium shot",
            cameraFormat: videoStyle.cameraFormat,
            mood: segment.mood === 'intense' 
              ? 'En√©rgico' 
              : segment.mood === 'calm' 
                ? 'Tranquilo' 
                : videoStyle.mood,
            visualStyle: videoStyle.characterStyle,
            visualIntensity: videoStyle.visualIntensity,
            narrativeIntensity: videoStyle.narrativeIntensity,
            colorPalette: videoStyle.colorPalette,
            duration: segment.duration / 1000,
            directorStyle: videoStyle.selectedDirector?.style,
            specialty: videoStyle.selectedDirector?.specialty,
            styleReference: videoStyle.styleReferenceUrl || ""
          };

          // A√±adir informaci√≥n de letra a los par√°metros
          const promptWithLyrics = `Escena para video musical que represente estas letras: "${relevantLyrics}". ${await generateVideoPromptWithRetry(promptParams)}`;

          if (promptWithLyrics && promptWithLyrics !== "Error generating prompt") {
            console.log(`Prompt generado exitosamente para segmento ${segment.id}`);
            return promptWithLyrics;
          }

          console.warn(`Intento ${attempt + 1} fall√≥, reintentando en ${2 * (attempt + 1)} segundos...`);
          await new Promise(resolve => setTimeout(resolve, 2000 * (attempt + 1)));
          attempt++;

        } catch (error) {
          console.error(`Error en intento ${attempt + 1}:`, error);
          lastError = error instanceof Error ? error : new Error(String(error));

          if (attempt === maxAttempts - 1) {
            toast({
              title: "Error",
              description: "No se pudo generar el prompt despu√©s de varios intentos",
              variant: "destructive",
            });
            return segment.imagePrompt || "Error generating prompt";
          }

          // Backoff exponencial
          const backoffTime = Math.min(1000 * Math.pow(2, attempt), 10000);
          console.log(`Reintentando en ${backoffTime/1000} segundos...`);
          await new Promise(resolve => setTimeout(resolve, backoffTime));
          attempt++;
        }
      }
    } catch (outerError) {
      console.error("Error general en generatePromptForSegment:", outerError);
      lastError = outerError instanceof Error ? outerError : new Error(String(outerError));
    }

    // FALLBACK: Si ning√∫n intento tuvo √©xito
    console.error(`No se pudo generar prompt para segmento ${segment.id} despu√©s de m√∫ltiples intentos:`, lastError);
    
    // Como √∫ltimo recurso, usar un prompt b√°sico basado en el tipo de plano y el mood
    const fallbackPrompt = `${segment.shotType || 'medium shot'} of a ${segment.mood || 'neutral'} scene with ${videoStyle.colorPalette || 'balanced'} colors. ${relevantLyrics}`;
    
    console.warn(`Usando prompt fallback para segmento ${segment.id}: ${fallbackPrompt}`);
    return fallbackPrompt;
  };

  const generatePromptsForSegments = async () => {
    if (timelineItems.length === 0) {
      toast({
        title: "Error",
        description: "Primero debes detectar los cortes musicales",
        variant: "destructive",
      });
      return;
    }

    if (!videoStyle.mood || !videoStyle.colorPalette || !videoStyle.characterStyle) {
      toast({
        title: "Error",
        description: "Debes configurar todos los aspectos del estilo antes de generar los prompts",
        variant: "destructive",
      });
      return;
    }

    setIsGeneratingScript(true);

    try {
      const updatedItems = [...timelineItems].slice(0, 10); // Limitar a 10 segmentos
      let hasError = false;
      let successCount = 0;

      // Procesar los segmentos en grupos de 3 para evitar sobrecargar la API
      for (let i = 0; i < updatedItems.length; i += 3) {
        const batch = updatedItems.slice(i, i + 3);

        try {
          const results = await Promise.all(
            batch.map(async (segment) => {
              const newPrompt = await generatePromptForSegment(segment);
              return {
                segment,
                prompt: newPrompt
              };
            })
          );

          results.forEach(({ segment, prompt }) => {
            if (prompt && prompt !== "Error generating prompt") {
              const index = updatedItems.findIndex(item => item.id === segment.id);
              if (index !== -1) {
                updatedItems[index] = {
                  ...updatedItems[index],
                  imagePrompt: prompt
                };
                successCount++;
              }
            } else {
              hasError = true;
            }
          });

          // Actualizar el estado despu√©s de cada batch
          setTimelineItems([...updatedItems]);

          toast({
            title: "Progreso",
            description: `Generados ${successCount} de ${updatedItems.length} prompts`,
          });

          // Esperar entre batches para evitar rate limits
          if (i + 3 < updatedItems.length) {
            await new Promise(resolve => setTimeout(resolve, 3000));
          }

        } catch (error) {
          console.error(`Error procesando batch ${i/3 + 1}:`, error);
          hasError = true;
        }
      }

      if (successCount === updatedItems.length) {
        toast({
          title: "√âxito",
          description: "Todos los prompts han sido generados",
        });
        setCurrentStep(5);
      } else {
        toast({
          title: "Completado con advertencias",
          description: `${successCount} de ${updatedItems.length} prompts generados exitosamente`,
          variant: hasError ? "destructive" : "default",
        });
      }

    } catch (error) {
      console.error("Error en la generaci√≥n de prompts:", error);
      toast({
        title: "Error",
        description: "Error al generar los prompts",
        variant: "destructive",
      });
    } finally {
      setIsGeneratingScript(false);
    }
  };

  const generateVideo = async (): Promise<string | null> => {
    if (!timelineItems.length || !audioBuffer) {
      toast({
        title: "Error",
        description: "No hay suficientes elementos para generar el video",
        variant: "destructive",
      });
      return null;
    }

    // Verificar si hay suficientes im√°genes generadas
    const itemsWithImages = timelineItems.filter(item => item.generatedImage).length;
    if (itemsWithImages < timelineItems.length * 0.7) { // Al menos 70% de cobertura
      toast({
        title: "Atenci√≥n",
        description: `Solo ${itemsWithImages} de ${timelineItems.length} segmentos tienen im√°genes. Considera generar m√°s im√°genes primero.`,
        variant: "default",
      });
    }

    setIsGeneratingVideo(true);
    try {
      toast({
        title: "Iniciando proceso",
        description: "Preparando elementos para la generaci√≥n del video...",
      });

      // Primero guardar todas las im√°genes en Firebase
      const savePromises = timelineItems
        .filter(item => item.generatedImage && !item.firebaseUrl)
        .map(async (item) => {
          try {
            const url = await saveToFirebase(item);
            if (url) {
              // Actualizar el item con la URL de Firebase
              setTimelineItems(prev => prev.map(
                i => i.id === item.id ? { ...i, firebaseUrl: url } : i
              ));
            }
            return { id: item.id, success: !!url, url };
          } catch (error) {
            console.error(`Error guardando imagen para segmento ${item.id}:`, error);
            return { id: item.id, success: false };
          }
        });

      await Promise.all(savePromises);

      // Simulaci√≥n del proceso de generaci√≥n (en una implementaci√≥n real, enviar√≠amos los elementos a un servicio)
      for (let i = 1; i <= 5; i++) {
        await new Promise(resolve => setTimeout(resolve, 800));
        // Actualizar progreso
        toast({
          title: "Generando video",
          description: `Fase ${i} de 5: ${["Procesando audio", "Sincronizando elementos", "Renderizando escenas", "Aplicando efectos", "Finalizando"][i-1]}`,
          variant: "default",
        });
      }

      // Generar ID √∫nico para este video
      const videoId = `video_${Date.now()}`;
      setVideoId(videoId);

      // Crear un documento en Firestore para el video
      try {
        const videoRef = collection(db, 'videos');
        await addDoc(videoRef, {
          id: videoId,
          userId: user?.uid,
          title: songTitle || 'Video Musical Generado',
          status: 'preview', // Inicialmente solo vista previa
          createdAt: serverTimestamp(),
          updatedAt: serverTimestamp(),
          duration: audioBuffer.duration || 0,
          thumbnailUrl: timelineItems.find(item => item.firebaseUrl || item.generatedImage)?.firebaseUrl || 
                         timelineItems.find(item => item.firebaseUrl || item.generatedImage)?.generatedImage || '',
          tags: ['m√∫sica', 'video', 'artista', 'canci√≥n', 'generado'],
        });
      } catch (error) {
        console.error("Error guardando informaci√≥n del video:", error);
      }

      // Marcar este paso como completado
      setCurrentStep(7);

      toast({
        title: "Video generado exitosamente",
        description: "Ya puedes previsualizar el video y/o comprarlo para acceso completo",
      });

      return videoId;
    } catch (error) {
      console.error("Error generando video:", error);
      toast({
        title: "Error",
        description: error instanceof Error ? error.message : "Error al generar el video",
        variant: "destructive",
      });
      return null;
    } finally {
      setIsGeneratingVideo(false);
    }
  };

  // Funci√≥n para descargar el video final
  const downloadVideo = () => {
    // Usar el video mejorado si est√° disponible, o el video generado original
    const videoToDownload = upscaledVideoUrl || generatedVideoUrl || "/assets/Standard_Mode_Generated_Video (2).mp4";
    const link = document.createElement('a');
    link.href = videoToDownload;
    link.download = `music-video-${videoId || 'final'}.mp4`;
    document.body.appendChild(link);
    link.click();
    document.body.removeChild(link);
    
    toast({
      title: "Descarga iniciada",
      description: "Tu video musical se est√° descargando ahora"
    });
  };
  
  // Funci√≥n para compartir el video en redes sociales
  const shareMusicVideo = () => {
    // En una implementaci√≥n real, aqu√≠ se abrir√≠a un modal con opciones
    // de compartir en diferentes redes sociales
    
    // Por ahora, simulamos compartir usando el navegador web API
    const videoToShare = upscaledVideoUrl || generatedVideoUrl || "/assets/Standard_Mode_Generated_Video (2).mp4";
    const shareData = {
      title: 'Mi Video Musical Generado con IA',
      text: '¬°Mira este incre√≠ble video musical que he creado con IA!',
      url: window.location.origin + videoToShare
    };
    
    if (navigator.share && navigator.canShare && navigator.canShare(shareData)) {
      navigator.share(shareData)
        .then(() => {
          toast({
            title: "Compartido con √©xito",
            description: "Tu video ha sido compartido"
          });
        })
        .catch(error => {
          console.error('Error al compartir:', error);
          toast({
            title: "Error al compartir",
            description: "No se pudo compartir el video. Intenta otra opci√≥n."
          });
        });
    } else {
      // Fallback si Web Share API no est√° disponible
      toast({
        title: "Enlace copiado",
        description: "Enlace al video copiado al portapapeles. Ahora puedes compartirlo."
      });
    }
  };

  const analyzeReferenceImage = async (image: string) => {
    try {
      const analysis = await analyzeImage(image);

      setVideoStyle(prev => ({
        ...prev,
        styleDescription: analysis
      }));

      toast({
        title: "An√°lisis completado",
        description: "Estilo de referencia actualizado"
      });
    } catch (error) {
      console.error("Error analyzing reference image:", error);
      toast({
        title: "Error",
        description: "No se pudo analizar la imagen de referencia",
        variant: "destructive"
      });
    }
  };

  useEffect(() => {
    const loadDirectors = async () => {
      try {
        const directorsSnapshot = await getDocs(collection(db, "directors"));
        const directorsData = directorsSnapshot.docs.map(doc => ({
          id: doc.id,
          ...doc.data()
        })) as Director[];
        setDirectors(directorsData);
      } catch (error) {
        console.error("Error loading directors:", error);
        toast({
          title: "Error",
          description: "No se pudieron cargar los directores",
          variant: "destructive",
        });
      }
    };

    loadDirectors();
  }, []);

  // Convertir los pasos para el componente EnhancedProgressSteps
  // Definir los pasos del workflow con el tipo Step importado
  const workflowSteps: Step[] = [
    {
      id: "transcription",
      name: "Transcripci√≥n de Audio",
      description: "Analizando y transcribiendo la letra de tu canci√≥n",
      status: currentStep > 1 ? "completed" : currentStep === 1 ? "in-progress" : "pending"
    },
    {
      id: "script",
      name: "Generaci√≥n de Guion",
      description: "Creando un guion visual basado en la letra",
      status: currentStep > 2 ? "completed" : currentStep === 2 ? "in-progress" : "pending"
    },
    {
      id: "sync",
      name: "Sincronizaci√≥n",
      description: "Alineando el contenido visual con el ritmo musical",
      status: currentStep > 3 ? "completed" : currentStep === 3 ? "in-progress" : "pending"
    },
    {
      id: "scenes",
      name: "Generaci√≥n de Escenas",
      description: "Creando escenas para cada secci√≥n",
      status: currentStep > 4 ? "completed" : currentStep === 4 ? "in-progress" : "pending"
    },
    {
      id: "customization",
      name: "Personalizaci√≥n",
      description: "Ajustando el estilo visual a tus preferencias",
      status: currentStep > 5 ? "completed" : currentStep === 5 ? "in-progress" : "pending"
    },
    {
      id: "movement",
      name: "Integraci√≥n de Movimiento",
      description: "A√±adiendo din√°micas visuales y coreograf√≠as",
      status: currentStep > 6 ? "completed" : currentStep === 6 ? "in-progress" : "pending"
    },
    {
      id: "lipsync",
      name: "Sincronizaci√≥n de Labios",
      description: "Sincronizando labios con la letra",
      status: currentStep > 7 ? "completed" : currentStep === 7 ? "in-progress" : "pending"
    },
    {
      id: "generation",
      name: "Generaci√≥n de Video",
      description: "Creando clips de video con IA",
      status: currentStep > 8 ? "completed" : currentStep === 8 ? "in-progress" : "pending"
    },
    {
      id: "rendering",
      name: "Renderizado Final",
      description: "Combinando todo en un video musical completo",
      status: currentStep > 9 ? "completed" : currentStep === 9 ? "in-progress" : "pending"
    }
  ];

  // Calcular el progreso para las animaciones
  const allStepsCompleted = workflowSteps.every(step => step.status === "completed");
  
  return (
    <div className="min-h-screen bg-black">
      {/* Efectos visuales para toda la aplicaci√≥n */}
      {allStepsCompleted && <motion.div className="confetti-container" />}
      
      {/* Sistema de part√≠culas din√°micas basadas en el paso actual - Ajustadas a naranja/negro */}
      {currentStep === 1 && (
        <ParticleSystem 
          count={30} 
          currentStep={1}
          active={true}
        />
      )}
      
      {currentStep === 2 && (
        <ParticleSystem 
          count={40} 
          currentStep={2}
          active={true}
        />
      )}
      
      {currentStep === 3 && (
        <ParticleSystem 
          count={50} 
          currentStep={3}
          active={true}
        />
      )}
      
      {currentStep === 4 && (
        <ParticleSystem 
          count={60} 
          currentStep={4}
          active={true}
        />
      )}
      
      {currentStep === 6 && (
        <ParticleSystem 
          count={80} 
          currentStep={6}
          active={true}
        />
      )}
      
      {currentStep >= 8 && currentStep < 9 && (
        <ParticleSystem 
          count={120}
          currentStep={8}
          active={true}
        />
      )}
      
      {/* Contenedor principal con posicionamiento relativo para los efectos */}
      <div className="relative">
        {/* Gradiente animado en el fondo - Usando solo naranja y negro */}
        <AnimatedGradient 
          colors={
            currentStep <= 2 ? ["#FF6B00", "#FF8800", "#FF4500", "#111111"] :
            currentStep <= 4 ? ["#FF4500", "#FF8800", "#111111", "#222222"] :
            currentStep <= 6 ? ["#FF7700", "#FF5500", "#111111", "#222222"] :
            currentStep <= 8 ? ["#FF6B00", "#111111", "#FF4500", "#000000"] :
            ["#FF8800", "#FF4500", "#111111", "#000000"]
          } 
          speed={currentStep <= 2 ? 5 : currentStep <= 5 ? 8 : 12} 
          className="opacity-20"
        />
        
        {/* Efectos de brillo seg√∫n la etapa del proceso */}
        {currentStep >= 5 && currentStep < 7 && (
          <GlowEffect 
            color="purple" 
            size={300} 
            x={25} 
            y={30} 
            pulsate={true} 
            className="opacity-10"
          />
        )}
        
        {currentStep >= 7 && (
          <GlowEffect 
            color="orange" 
            size={350} 
            x={75} 
            y={40} 
            pulsate={true} 
            className="opacity-15"
          />
        )}
        
        {/* Componente de pasos mejorado con animaciones */}
        <EnhancedProgressSteps
          steps={workflowSteps}
          currentStep={workflowSteps.find(s => s.status === "in-progress")?.id || "transcription"}
          showDescriptions={true}
        />
        
        {/* Mantener el ProgressSteps original como fallback (escondido para compatibilidad) */}
        <div className="hidden">
          <ProgressSteps 
            currentStep={String(currentStep)} 
            steps={[
              {
                id: "transcription",
                name: "Transcripci√≥n de Audio",
                description: "Analizando y transcribiendo la letra de tu canci√≥n",
                status: currentStep > 1 ? "completed" : currentStep === 1 ? "in-progress" : "pending"
              },
              {
                id: "script",
                name: "Generaci√≥n de Guion",
                description: "Creando un guion visual basado en tu m√∫sica",
                status: currentStep > 2 ? "completed" : currentStep === 2 ? "in-progress" : "pending"
              },
              {
                id: "sync",
                name: "Sincronizaci√≥n",
                description: "Sincronizando el video con el ritmo de la m√∫sica",
                status: currentStep > 3 ? "completed" : currentStep === 3 ? "in-progress" : "pending"
              },
              {
                id: "scenes",
                name: "Generaci√≥n de Escenas",
                description: "Creando las escenas del video musical",
                status: currentStep > 4 ? "completed" : currentStep === 4 ? "in-progress" : "pending"
              },
              {
                id: "customization",
                name: "Personalizaci√≥n",
                description: "Ajustando el estilo visual a tus preferencias",
                status: currentStep > 5 ? "completed" : currentStep === 5 ? "in-progress" : "pending"
              },
              {
                id: "movement",
                name: "Integraci√≥n de Movimiento",
                description: "A√±adiendo coreograf√≠as y din√°micas visuales",
                status: currentStep > 6 ? "completed" : currentStep === 6 ? "in-progress" : "pending"
              },
              {
                id: "lipsync",
                name: "Sincronizaci√≥n de Labios",
                description: "Sincronizando labios con la letra de la canci√≥n",
                status: currentStep > 7 ? "completed" : currentStep === 7 ? "in-progress" : "pending"
              },
              {
                id: "generation",
                name: "Generaci√≥n de Video",
                description: "Creando videos con IA a partir de tus escenas",
                status: currentStep > 8 ? "completed" : currentStep === 8 ? "in-progress" : "pending"
              },
              {
                id: "rendering",
                name: "Renderizado Final",
                description: "Combinando todo en tu video musical",
                status: currentStep > 9 ? "completed" : currentStep === 9 ? "in-progress" : "pending"
              }
            ]}
          />
        </div>
      </div> {/* Cierre del div className="relative" */}

      <motion.div 
        className="container py-6 space-y-8"
        initial={{ opacity: 0 }}
        animate={{ opacity: 1 }}
        transition={{ duration: 0.6 }}
      >
        <motion.div
          initial={{ y: 20, opacity: 0 }}
          animate={{ y: 0, opacity: 1 }}
          transition={{ 
            type: "spring",
            stiffness: 300,
            damping: 20,
            delay: 0.1
          }}
        >
          <Card className="p-6 relative overflow-hidden shadow-lg border-none">
            {/* Efectos decorativos m√∫ltiples en la esquina */}
            <div className="absolute top-0 right-0 w-40 h-40 bg-gradient-radial from-orange-400/20 to-transparent rounded-full -translate-y-1/2 translate-x-1/2 pointer-events-none" />
            <div className="absolute top-0 right-0 w-20 h-20 bg-gradient-radial from-purple-500/15 to-transparent rounded-full -translate-y-1/3 translate-x-1/3 pointer-events-none" />
            
            {/* L√≠nea decorativa animada - versi√≥n mejorada */}
            <motion.div 
              className="absolute bottom-0 left-0 h-1.5 bg-gradient-to-r from-orange-500 via-purple-500 to-blue-500 rounded-full"
              initial={{ width: "0%", opacity: 0.7 }}
              animate={{ 
                width: `${(currentStep / 9) * 100}%`,
                opacity: [0.7, 0.9, 0.7]
              }}
              transition={{ 
                width: { duration: 0.8, ease: "easeOut" },
                opacity: { duration: 2, repeat: Infinity, ease: "easeInOut" }
              }}
            />
            
            {/* Borde brillante animado en la parte superior */}
            <motion.div 
              className="absolute top-0 left-0 h-1 w-full bg-gradient-to-r from-blue-500/0 via-purple-500/30 to-orange-500/0"
              animate={{ 
                opacity: [0, 0.8, 0],
                left: ["-100%", "100%"]
              }}
              transition={{ 
                duration: 3, 
                repeat: Infinity, 
                ease: "easeInOut", 
                repeatDelay: 1
              }}
            />
            
          <div className="flex items-center gap-4 mb-6">
            <motion.div 
              className="h-14 w-14 rounded-xl bg-gradient-to-br from-orange-500/20 to-orange-600/10 flex items-center justify-center border border-orange-500/20 shadow-sm"
              whileHover={{ scale: 1.05 }}
              animate={{ 
                boxShadow: ["0 0 0 rgba(249, 115, 22, 0)", "0 0 12px rgba(249, 115, 22, 0.3)", "0 0 0 rgba(249, 115, 22, 0)"] 
              }}
              transition={{ 
                boxShadow: { duration: 2, repeat: Infinity, ease: "easeInOut" } 
              }}
            >
              <Video className="h-7 w-7 text-orange-500" />
            </motion.div>
            <div>
              <h2 className="text-2xl font-bold bg-clip-text text-transparent bg-gradient-to-r from-orange-600 to-orange-500">
                Creador de Videos Musicales AI
              </h2>
              <p className="text-sm text-muted-foreground/90 tracking-wide">
                Transforma tu m√∫sica en experiencias visuales cautivadoras
              </p>
            </div>
          </div>

          <div className="grid lg:grid-cols-2 gap-6">
            <div className="space-y-6 order-2 lg:order-1">
              <motion.div 
                className="border rounded-lg overflow-hidden p-5 bg-gradient-to-br from-zinc-900 to-black shadow-sm relative border-zinc-800"
                initial={{ opacity: 0, y: 20 }}
                animate={{ 
                  opacity: 1, 
                  y: 0,
                  boxShadow: currentStep >= 2 ? "0 0 0 2px rgba(249, 115, 22, 0.2)" : "none"
                }}
                transition={{ duration: 0.5 }}
              >
                {/* Indicador de paso completado */}
                {currentStep >= 2 && (
                  <motion.div 
                    className="absolute -top-1 -right-1 p-1 rounded-full bg-orange-100 text-orange-600 z-10"
                    initial={{ scale: 0 }}
                    animate={{ scale: 1 }}
                    transition={{ type: "spring", stiffness: 500, damping: 20 }}
                  >
                    <CheckCircle2 className="h-4 w-4" />
                  </motion.div>
                )}
                
                {/* T√≠tulo con icono animado */}
                <div className="flex items-center gap-3 mb-4">
                  <motion.div 
                    className="flex h-8 w-8 items-center justify-center rounded-full bg-orange-100 text-orange-600"
                    whileHover={{ scale: 1.1 }}
                    animate={{ 
                      rotate: isTranscribing ? [0, 10, -10, 0] : 0
                    }}
                    transition={{ 
                      rotate: { repeat: Infinity, duration: 1.5, ease: "easeInOut" },
                      scale: { duration: 0.2 }
                    }}
                  >
                    <Music2 className="h-4 w-4" />
                  </motion.div>
                  <Label className="text-lg font-semibold text-orange-500">1. Subir Audio</Label>
                </div>
                
                <div className="space-y-4">
                  <motion.div 
                    className="relative border-2 border-dashed border-orange-300 rounded-lg p-4 hover:border-orange-400 transition-colors bg-black/50"
                    whileHover={{ scale: 1.01 }}
                    whileTap={{ scale: 0.99 }}
                  >
                    <Input
                      type="file"
                      accept="audio/mpeg,audio/mp3,audio/mp4,audio/wav,audio/aac,audio/x-m4a,audio/ogg,audio/webm,audio/flac"
                      onChange={handleFileChange}
                      disabled={isTranscribing}
                      className="absolute inset-0 w-full h-full opacity-0 cursor-pointer z-10"
                    />
                    <div className="flex flex-col items-center justify-center gap-2 pointer-events-none">
                      <Upload className="h-8 w-8 text-orange-400 mb-1" />
                      <p className="font-medium text-sm text-center">Arrastra tu archivo de audio o haz clic para seleccionar</p>
                      <p className="text-xs text-muted-foreground text-center">Soporta MP3, WAV, FLAC, OGG y otros formatos de audio</p>
                    </div>
                  </motion.div>
                  
                  {selectedFile && (
                    <motion.div 
                      className="flex items-center gap-3 text-sm p-3 bg-orange-50 rounded-md border border-orange-100"
                      initial={{ opacity: 0, y: 10 }}
                      animate={{ opacity: 1, y: 0 }}
                      transition={{ duration: 0.3 }}
                    >
                      <div className="bg-orange-100 rounded-full p-1.5">
                        <Music2 className="h-4 w-4 text-orange-600" />
                      </div>
                      <div className="flex-1 truncate">
                        <span className="font-medium">{selectedFile.name}</span>
                        <span className="text-xs text-muted-foreground ml-2">
                          {(selectedFile.size / (1024 * 1024)).toFixed(2)} MB
                        </span>
                      </div>
                    </motion.div>
                  )}
                  
                  {isTranscribing && (
                    <motion.div 
                      className="flex items-center gap-3 text-sm p-3 bg-blue-50 rounded-md"
                      initial={{ opacity: 0, height: 0 }}
                      animate={{ opacity: 1, height: "auto" }}
                      transition={{ duration: 0.4 }}
                    >
                      <div className="bg-blue-100 rounded-full p-1.5 relative">
                        <Loader2 className="h-4 w-4 text-blue-600 animate-spin" />
                        <motion.div 
                          className="absolute inset-0 rounded-full border-2 border-blue-300 border-t-blue-600"
                          animate={{ rotate: 360 }}
                          transition={{ duration: 1.5, repeat: Infinity, ease: "linear" }}
                        />
                      </div>
                      <div>
                        <span className="font-medium">Transcribiendo audio...</span>
                        <span className="text-xs text-muted-foreground ml-2">
                          Procesando datos de voz con IA
                        </span>
                      </div>
                    </motion.div>
                  )}
                </div>
              </motion.div>

              <div className="space-y-6">
                <motion.div 
                  className="border rounded-lg overflow-hidden p-5 bg-gradient-to-br from-zinc-900 to-black shadow-sm relative border-zinc-800"
                  initial={{ opacity: 0, y: 20 }}
                  animate={{ 
                    opacity: 1, 
                    y: 0,
                    boxShadow: currentStep >= 3 ? "0 0 0 2px rgba(79, 70, 229, 0.2)" : "none"
                  }}
                  transition={{ duration: 0.5, delay: 0.1 }}
                >
                  {/* Indicador de paso completado */}
                  {currentStep >= 3 && (
                    <motion.div 
                      className="absolute -top-1 -right-1 p-1 rounded-full bg-orange-100 text-orange-600 z-10"
                      initial={{ scale: 0 }}
                      animate={{ scale: 1 }}
                      transition={{ type: "spring", stiffness: 500, damping: 20 }}
                    >
                      <CheckCircle2 className="h-4 w-4" />
                    </motion.div>
                  )}
                  
                  {/* T√≠tulo con icono animado */}
                  <div className="flex items-center gap-3 mb-4">
                    <motion.div 
                      className="flex h-8 w-8 items-center justify-center rounded-full bg-orange-100 text-orange-600"
                      whileHover={{ scale: 1.1 }}
                      animate={{ 
                        rotate: isGeneratingScript ? [0, 10, -10, 0] : 0
                      }}
                      transition={{ 
                        rotate: { repeat: Infinity, duration: 1.5, ease: "easeInOut" },
                        scale: { duration: 0.2 }
                      }}
                    >
                      <FileText className="h-4 w-4" />
                    </motion.div>
                    <Label className="text-lg font-semibold text-orange-500">2. Transcripci√≥n</Label>
                  </div>
                  
                  <div className="space-y-4">
                    <motion.div 
                      className="relative"
                      animate={{ opacity: 1 }}
                      initial={{ opacity: 0.8 }}
                      transition={{ duration: 0.3 }}
                    >
                      <ScrollArea className="h-[200px] w-full rounded-md border border-orange-500/20 bg-black/80 p-4 shadow-inner">
                        {transcription ? (
                          <motion.pre 
                            className="text-sm whitespace-pre-wrap font-normal text-slate-700"
                            initial={{ opacity: 0 }}
                            animate={{ opacity: 1 }}
                            transition={{ duration: 0.5 }}
                          >
                            {transcription}
                          </motion.pre>
                        ) : (
                          <div className="flex flex-col items-center justify-center h-full text-center opacity-60">
                            <FileText className="h-8 w-8 mb-2 text-slate-400" />
                            <p className="text-sm text-slate-500">Sube un archivo de audio para ver la transcripci√≥n</p>
                          </div>
                        )}
                      </ScrollArea>
                    </motion.div>
                    
                    {/* Mostrar bot√≥n de continuar cuando la transcripci√≥n se ha completado pero no se ha avanzado al paso 2 */}
                    {currentStep === 1.5 && (
                      <motion.div
                        initial={{ opacity: 0, y: 10 }}
                        animate={{ opacity: 1, y: 0 }}
                        transition={{ duration: 0.3 }}
                        className="space-y-4"
                      >
                        {/* Secci√≥n para subir im√°genes de referencia del artista */}
                        <div className="border border-purple-500/30 rounded-lg p-4 bg-purple-950/20">
                          <div className="flex items-center gap-2 mb-3">
                            <ImageIcon className="h-5 w-5 text-purple-400" />
                            <Label className="text-base font-semibold text-purple-400">
                              Im√°genes de Referencia del Artista (Opcional)
                            </Label>
                          </div>
                          <p className="text-xs text-muted-foreground mb-3">
                            Sube hasta 3 fotos del artista para que Nano Banana las use como referencia al generar las escenas del video
                          </p>
                          
                          {/* Grid para mostrar las im√°genes subidas */}
                          {artistReferenceImages.length > 0 && (
                            <div className="grid grid-cols-3 gap-2 mb-3">
                              {artistReferenceImages.map((img, index) => (
                                <div key={index} className="relative group">
                                  <img 
                                    src={img} 
                                    alt={`Referencia ${index + 1}`}
                                    className="w-full h-24 object-cover rounded-md border border-purple-500/40"
                                  />
                                  <button
                                    onClick={() => removeReferenceImage(index)}
                                    className="absolute -top-2 -right-2 bg-red-500 hover:bg-red-600 text-white rounded-full p-1 opacity-0 group-hover:opacity-100 transition-opacity"
                                    data-testid={`remove-reference-${index}`}
                                  >
                                    <X className="h-3 w-3" />
                                  </button>
                                </div>
                              ))}
                            </div>
                          )}
                          
                          {/* Bot√≥n para subir im√°genes */}
                          {artistReferenceImages.length < 3 && (
                            <div className="relative">
                              <Input
                                type="file"
                                accept="image/*"
                                multiple
                                onChange={handleReferenceImageUpload}
                                disabled={isUploadingReferences}
                                className="absolute inset-0 w-full h-full opacity-0 cursor-pointer z-10"
                                data-testid="upload-reference-images"
                              />
                              <div className="border-2 border-dashed border-purple-400/40 rounded-lg p-3 hover:border-purple-400 transition-colors bg-purple-950/10 cursor-pointer">
                                <div className="flex flex-col items-center justify-center gap-1">
                                  <Upload className="h-6 w-6 text-purple-400" />
                                  <p className="text-xs font-medium text-center text-purple-300">
                                    {isUploadingReferences ? "Cargando..." : `Subir im√°genes (${artistReferenceImages.length}/3)`}
                                  </p>
                                  <p className="text-xs text-muted-foreground text-center">
                                    JPG, PNG o WEBP (m√°x. 5MB)
                                  </p>
                                </div>
                              </div>
                            </div>
                          )}
                        </div>
                        
                        <Button
                          onClick={() => setCurrentStep(2)}
                          className="w-full bg-gradient-to-r from-orange-500 to-orange-600 hover:from-orange-600 hover:to-orange-700 text-white shadow-md"
                          data-testid="continue-to-next-step"
                        >
                          <motion.div 
                            className="mr-2"
                            animate={{ scale: [1, 1.2, 1] }}
                            transition={{ repeat: Infinity, duration: 1.5 }}
                          >
                            <CheckCircle2 className="h-4 w-4" />
                          </motion.div>
                          Continuar al siguiente paso
                        </Button>
                      </motion.div>
                    )}
                    
                    <Button
                      onClick={generateScriptFromTranscription}
                      disabled={!transcription || isGeneratingScript || currentStep < 2}
                      className={cn(
                        "w-full group relative overflow-hidden transition-all",
                        transcription && !isGeneratingScript && currentStep >= 2 
                          ? "bg-gradient-to-r from-orange-500 to-orange-600 hover:from-orange-600 hover:to-orange-700 text-white shadow-md" 
                          : ""
                      )}
                    >
                      {isGeneratingScript ? (
                        <motion.div className="flex items-center justify-center w-full">
                          <motion.div 
                            className="mr-2"
                            animate={{ rotate: 360 }}
                            transition={{ repeat: Infinity, duration: 1, ease: "linear" }}
                          >
                            <Loader2 className="h-4 w-4" />
                          </motion.div>
                          <span>Generando guion...</span>
                        </motion.div>
                      ) : (
                        <motion.div 
                          className="flex items-center justify-center w-full"
                          whileHover={{ scale: 1.02 }}
                          transition={{ duration: 0.2 }}
                        >
                          <FileText className="mr-2 h-4 w-4" />
                          <span>Generar Guion Musical</span>
                        </motion.div>
                      )}
                      
                      {/* Efecto de brillo al pasar el mouse */}
                      {transcription && !isGeneratingScript && currentStep >= 2 && (
                        <motion.div 
                          className="absolute inset-0 w-full h-full bg-gradient-to-r from-transparent via-white/20 to-transparent -translate-x-full"
                          animate={{ translateX: ["100%", "-100%"] }}
                          transition={{ repeat: Infinity, duration: 2, ease: "easeInOut", repeatDelay: 0.5 }}
                        />
                      )}
                    </Button>
                  </div>
                </motion.div>

                <motion.div 
                  className="border rounded-lg overflow-hidden p-5 bg-gradient-to-br from-zinc-900 to-black shadow-sm relative border-zinc-800"
                  initial={{ opacity: 0, y: 20 }}
                  animate={{ 
                    opacity: 1, 
                    y: 0,
                    boxShadow: currentStep >= 4 ? "0 0 0 2px rgba(124, 58, 237, 0.2)" : "none"
                  }}
                  transition={{ duration: 0.5, delay: 0.2 }}
                >
                  {/* Indicador de paso completado */}
                  {currentStep >= 4 && (
                    <motion.div 
                      className="absolute -top-1 -right-1 p-1 rounded-full bg-orange-100 text-orange-600 z-10"
                      initial={{ scale: 0 }}
                      animate={{ scale: 1 }}
                      transition={{ type: "spring", stiffness: 500, damping: 20 }}
                    >
                      <CheckCircle2 className="h-4 w-4" />
                    </motion.div>
                  )}
                  
                  {/* T√≠tulo con icono animado y badge */}
                  <div className="flex justify-between items-center mb-4">
                    <div className="flex items-center gap-3">
                      <motion.div 
                        className="flex h-8 w-8 items-center justify-center rounded-full bg-orange-100 text-orange-600"
                        whileHover={{ scale: 1.1 }}
                        animate={scriptContent ? { 
                          scale: [1, 1.05, 1],
                          rotate: [0, 2, -2, 0]
                        } : {}}
                        transition={{ 
                          repeat: scriptContent ? Infinity : 0,
                          repeatDelay: 3,
                          duration: 1
                        }}
                      >
                        <Film className="h-4 w-4" />
                      </motion.div>
                      <Label className="text-lg font-semibold text-orange-500">3. Guion Profesional</Label>
                    </div>
                    
                    {scriptContent && (
                      <motion.div
                        initial={{ opacity: 0, scale: 0.8 }}
                        animate={{ opacity: 1, scale: 1 }}
                        transition={{ duration: 0.3 }}
                      >
                        <Badge variant="outline" className="bg-gradient-to-r from-amber-50 to-yellow-50 text-amber-800 hover:from-amber-100 hover:to-yellow-100 border-amber-200">
                          <Film className="h-3 w-3 mr-1" />
                          An√°lisis cinematogr√°fico
                        </Badge>
                      </motion.div>
                    )}
                  </div>
                  
                  <div className="space-y-4">
                    {!scriptContent ? (
                      <motion.div 
                        className="flex flex-col items-center justify-center py-8 text-center rounded-md bg-gradient-to-b from-zinc-900 to-black border border-zinc-800 shadow-sm"
                        initial={{ opacity: 0.8 }}
                        animate={{ opacity: 1 }}
                        transition={{ duration: 0.5 }}
                      >
                        <motion.div
                          animate={{ 
                            y: [0, -5, 0],
                            opacity: [0.5, 0.8, 0.5]
                          }}
                          transition={{ 
                            repeat: Infinity,
                            duration: 3,
                            ease: "easeInOut"
                          }}
                        >
                          <Film className="h-14 w-14 mb-3 text-orange-400" />
                        </motion.div>
                        <p className="max-w-md font-medium text-gray-600">El guion profesional se generar√° basado en la transcripci√≥n de la letra.</p>
                        <div className="mt-4 grid grid-cols-3 gap-3 max-w-lg">
                          <div className="flex flex-col items-center p-3 rounded-lg bg-orange-50/50 border border-orange-100">
                            <span className="text-xs font-semibold text-orange-800 mb-1">Estilo</span>
                            <span className="text-[10px] text-center text-orange-600">An√°lisis de g√©nero y est√©tica</span>
                          </div>
                          <div className="flex flex-col items-center p-3 rounded-lg bg-amber-50/50 border border-amber-100">
                            <span className="text-xs font-semibold text-amber-800 mb-1">Arco</span>
                            <span className="text-[10px] text-center text-amber-600">Estructura narrativa</span>
                          </div>
                          <div className="flex flex-col items-center p-3 rounded-lg bg-orange-50/50 border border-orange-100">
                            <span className="text-xs font-semibold text-orange-800 mb-1">T√©cnica</span>
                            <span className="text-[10px] text-center text-orange-600">Direcci√≥n esc√©nica</span>
                          </div>
                        </div>
                      </motion.div>
                    ) : (
                      <motion.div
                        initial={{ opacity: 0, y: 10 }}
                        animate={{ opacity: 1, y: 0 }}
                        transition={{ duration: 0.5 }}
                      >
                        <motion.div 
                          className="grid grid-cols-3 gap-2 text-xs mb-4"
                          initial={{ opacity: 0, y: 5 }}
                          animate={{ opacity: 1, y: 0 }}
                          transition={{ 
                            duration: 0.5,
                            staggerChildren: 0.1
                          }}
                        >
                          <motion.div 
                            className="bg-gradient-to-br from-zinc-900 to-black p-3 rounded-md border border-orange-800/30 shadow-sm"
                            whileHover={{ scale: 1.02, boxShadow: "0 4px 12px rgba(251, 191, 36, 0.1)" }}
                            transition={{ duration: 0.2 }}
                            initial={{ opacity: 0, x: -10 }}
                            animate={{ opacity: 1, x: 0 }}
                          >
                            <span className="font-semibold block text-orange-400">An√°lisis Musical</span>
                            <span className="text-orange-300">G√©nero y estructura</span>
                          </motion.div>
                          <motion.div 
                            className="bg-gradient-to-br from-zinc-900 to-black p-3 rounded-md border border-orange-800/30 shadow-sm"
                            whileHover={{ scale: 1.02, boxShadow: "0 4px 12px rgba(249, 115, 22, 0.1)" }}
                            transition={{ duration: 0.2 }}
                            initial={{ opacity: 0, y: -10 }}
                            animate={{ opacity: 1, y: 0 }}
                            
                          >
                            <span className="font-semibold block text-orange-400">Narrativa Visual</span>
                            <span className="text-orange-300">Arco emocional y mensajes</span>
                          </motion.div>
                          <motion.div 
                            className="bg-gradient-to-br from-zinc-900 to-black p-3 rounded-md border border-orange-800/30 shadow-sm"
                            whileHover={{ scale: 1.02, boxShadow: "0 4px 12px rgba(249, 115, 22, 0.1)" }}
                            transition={{ duration: 0.2 }}
                            initial={{ opacity: 0, x: 10 }}
                            animate={{ opacity: 1, x: 0 }}
                          >
                            <span className="font-semibold block text-orange-400">Direcci√≥n T√©cnica</span>
                            <span className="text-orange-300">Planos, transiciones, mood</span>
                          </motion.div>
                        </motion.div>
                        
                        <motion.div
                          className="relative overflow-hidden rounded-lg"
                          initial={{ opacity: 0 }}
                          animate={{ opacity: 1 }}
                          transition={{ delay: 0.3, duration: 0.5 }}
                        >
                          {/* Efecto de resplandor superior */}
                          <motion.div 
                            className="absolute top-0 left-0 w-full h-[3px] bg-gradient-to-r from-orange-400/0 via-orange-500/50 to-orange-400/0 z-10"
                            animate={{ 
                              opacity: [0.3, 0.7, 0.3]
                            }}
                            transition={{ 
                              duration: 3,
                              repeat: Infinity,
                              ease: "easeInOut"
                            }}
                          />
                          
                          <ScrollArea className="h-[300px] w-full rounded-md border border-zinc-800 p-4 bg-gradient-to-b from-zinc-950 to-zinc-900 text-zinc-100 shadow-inner">
                            <pre className="text-sm whitespace-pre-wrap font-mono leading-relaxed">{scriptContent}</pre>
                          </ScrollArea>
                        </motion.div>
                      </motion.div>
                    )}
                  </div>
                </motion.div>

                <motion.div 
                  className="border rounded-lg overflow-hidden p-5 bg-gradient-to-br from-zinc-900 to-black shadow-sm relative border-zinc-800"
                  initial={{ opacity: 0, y: 20 }}
                  animate={{ 
                    opacity: 1, 
                    y: 0,
                    boxShadow: currentStep >= 5 ? "0 0 0 2px rgba(244, 63, 94, 0.2)" : "none"
                  }}
                  transition={{ duration: 0.5, delay: 0.3 }}
                >
                  {/* Indicador de paso completado */}
                  {currentStep >= 5 && (
                    <motion.div 
                      className="absolute -top-1 -right-1 p-1 rounded-full bg-orange-100 text-orange-600 z-10"
                      initial={{ scale: 0 }}
                      animate={{ scale: 1 }}
                      transition={{ type: "spring", stiffness: 500, damping: 20 }}
                    >
                      <CheckCircle2 className="h-4 w-4" />
                    </motion.div>
                  )}
                  
                  {/* T√≠tulo con icono animado */}
                  <div className="flex items-center gap-3 mb-6">
                    <motion.div 
                      className="flex h-8 w-8 items-center justify-center rounded-full bg-orange-100 text-orange-600"
                      whileHover={{ scale: 1.1 }}
                      animate={{ 
                        rotate: [0, -5, 5, 0],
                      }}
                      transition={{ 
                        rotate: { repeat: Infinity, duration: 5, ease: "easeInOut", repeatDelay: 1 },
                        scale: { duration: 0.2 }
                      }}
                    >
                      <ImageIcon className="h-4 w-4" />
                    </motion.div>
                    <div>
                      <Label className="text-lg font-semibold bg-clip-text text-transparent bg-gradient-to-r from-orange-600 to-orange-500">4. Estilo Visual</Label>
                      <p className="text-xs text-muted-foreground">Define la est√©tica visual de tu video musical</p>
                    </div>
                  </div>
                  
                  <div className="grid gap-5">
                    <motion.div 
                      className="space-y-3"
                      initial={{ opacity: 0, y: 10 }}
                      animate={{ opacity: 1, y: 0 }}
                      transition={{ duration: 0.3 }}
                    >
                      <div className="flex items-center justify-between">
                        <Label className="font-medium text-orange-900/80">Formato de C√°mara</Label>
                        <motion.div 
                          className="h-6 w-6 rounded-full bg-orange-50 flex items-center justify-center text-orange-500"
                          whileHover={{ scale: 1.2, backgroundColor: "rgb(255 237 213 / 1)" }}
                          transition={{ duration: 0.2 }}
                        >
                          <Film className="h-3 w-3" />
                        </motion.div>
                      </div>
                      <Select
                        value={videoStyle.cameraFormat}
                        onValueChange={(value) => setVideoStyle(prev => ({ ...prev, cameraFormat: value }))}
                      >
                        <SelectTrigger className="bg-black/90 border-orange-500/20 focus:ring-orange-500 h-11 text-white/90">
                          <SelectValue placeholder="Seleccionar formato de c√°mara" />
                        </SelectTrigger>
                        <SelectContent>
                          {videoStyles.cameraFormats.map((format) => (
                            <SelectItem key={format.name} value={format.name}>
                              <div className="grid gap-1">
                                <span>{format.name}</span>
                                <span className="text-xs text-muted-foreground">{format.description}</span>
                              </div>
                            </SelectItem>
                          ))}
                        </SelectContent>
                      </Select>
                    </motion.div>

                    <div className="grid sm:grid-cols-2 gap-4">
                      <motion.div 
                        className="space-y-3"
                        initial={{ opacity: 0, y: 10 }}
                        animate={{ opacity: 1, y: 0 }}
                        transition={{ duration: 0.3, delay: 0.1 }}
                      >
                        <div className="flex items-center justify-between">
                          <Label className="font-medium text-orange-900/80">Mood</Label>
                          <motion.div 
                            className="h-6 w-6 rounded-full bg-orange-50 flex items-center justify-center text-orange-500"
                            whileHover={{ scale: 1.2, backgroundColor: "rgb(255 237 213 / 1)" }}
                            transition={{ duration: 0.2 }}
                          >
                            <span className="text-xs font-semibold">M</span>
                          </motion.div>
                        </div>
                        <Select
                          value={videoStyle.mood}
                          onValueChange={(value) => setVideoStyle(prev => ({ ...prev, mood: value }))}
                        >
                          <SelectTrigger className="bg-black/90 border-orange-500/20 focus:ring-orange-500 h-11 text-white/90">
                            <SelectValue placeholder="Seleccionar mood" />
                          </SelectTrigger>
                          <SelectContent>
                            {videoStyles.moods.map((mood) => (
                              <SelectItem key={mood} value={mood}>
                                {mood}
                              </SelectItem>
                            ))}
                          </SelectContent>
                        </Select>
                      </motion.div>

                      <motion.div 
                        className="space-y-3"
                        initial={{ opacity: 0, y: 10 }}
                        animate={{ opacity: 1, y: 0 }}
                        transition={{ duration: 0.3, delay: 0.2 }}
                      >
                        <div className="flex items-center justify-between">
                          <Label className="font-medium text-orange-900/80">Paleta de Colores</Label>
                          <div className="flex space-x-1">
                            <motion.div 
                              className="h-4 w-4 rounded-full bg-orange-400"
                              whileHover={{ scale: 1.2 }}
                              transition={{ duration: 0.2 }}
                            />
                            <motion.div 
                              className="h-4 w-4 rounded-full bg-orange-600"
                              whileHover={{ scale: 1.2 }}
                              transition={{ duration: 0.2 }}
                            />
                            <motion.div 
                              className="h-4 w-4 rounded-full bg-zinc-900"
                              whileHover={{ scale: 1.2 }}
                              transition={{ duration: 0.2 }}
                            />
                          </div>
                        </div>
                        <Select
                          value={videoStyle.colorPalette}
                          onValueChange={(value) => setVideoStyle(prev => ({ ...prev, colorPalette: value }))}
                        >
                          <SelectTrigger className="bg-black/90 border-orange-500/20 focus:ring-orange-500 h-11 text-white/90">
                            <SelectValue placeholder="Seleccionar paleta" />
                          </SelectTrigger>
                          <SelectContent>
                            {videoStyles.colorPalettes.map((palette) => (
                              <SelectItem key={palette} value={palette}>
                                {palette}
                              </SelectItem>
                            ))}
                          </SelectContent>
                        </Select>
                      </motion.div>
                    </div>

                    <div className="grid sm:grid-cols-2 gap-4">
                      <motion.div 
                        className="space-y-3"
                        initial={{ opacity: 0, y: 10 }}
                        animate={{ opacity: 1, y: 0 }}
                        transition={{ duration: 0.3, delay: 0.3 }}
                      >
                        <div className="flex items-center justify-between">
                          <Label className="font-medium text-orange-900/80">Estilo de Personajes</Label>
                          <motion.div 
                            className="h-6 w-6 rounded-full bg-orange-50 flex items-center justify-center text-orange-500"
                            whileHover={{ scale: 1.2, backgroundColor: "rgb(255 237 213 / 1)" }}
                            transition={{ duration: 0.2 }}
                          >
                            <User className="h-3 w-3" />
                          </motion.div>
                        </div>
                        <Select
                          value={videoStyle.characterStyle}
                          onValueChange={(value) => setVideoStyle(prev => ({ ...prev, characterStyle: value }))}
                        >
                          <SelectTrigger className="bg-black/90 border-orange-500/20 focus:ring-orange-500 h-11 text-white/90">
                            <SelectValue placeholder="Seleccionar estilo" />
                          </SelectTrigger>
                          <SelectContent>
                            {videoStyles.characterStyles.map((style) => (
                              <SelectItem key={style} value={style}>
                                {style}
                              </SelectItem>
                            ))}
                          </SelectContent>
                        </Select>
                      </motion.div>

                      <motion.div 
                        className="space-y-3"
                        initial={{ opacity: 0, y: 10 }}
                        animate={{ opacity: 1, y: 0 }}
                        transition={{ duration: 0.3, delay: 0.4 }}
                      >
                        <div className="flex items-center justify-between">
                          <Label className="font-medium text-orange-900/80">
                            Intensidad Visual
                            <span className="ml-2 inline-flex items-center justify-center rounded-full bg-orange-100 px-2 py-0.5 text-xs font-medium text-orange-700">
                              {videoStyle.visualIntensity}%
                            </span>
                          </Label>
                        </div>
                        <div className="pt-2">
                          <Slider
                            value={[videoStyle.visualIntensity]}
                            onValueChange={([value]) => setVideoStyle(prev => ({ ...prev, visualIntensity: value }))}
                            max={100}
                            step={1}
                            className="py-2"
                          />
                          <div className="flex justify-between text-xs text-muted-foreground mt-1">
                            <span>Sutil</span>
                            <span>Impactante</span>
                          </div>
                        </div>
                      </motion.div>
                    </div>

                    <motion.div 
                      className="space-y-3 pt-1"
                      initial={{ opacity: 0, y: 10 }}
                      animate={{ opacity: 1, y: 0 }}
                      transition={{ duration: 0.3, delay: 0.5 }}
                    >
                      <div className="flex items-center justify-between">
                        <Label className="font-medium text-orange-900/80">
                          Intensidad Narrativa 
                          <span className="ml-2 inline-flex items-center justify-center rounded-full bg-orange-100 px-2 py-0.5 text-xs font-medium text-orange-700">
                            {videoStyle.narrativeIntensity}%
                          </span>
                        </Label>
                      </div>
                      <p className="text-xs text-muted-foreground">
                        Ajusta qu√© tan fielmente el video sigue la narrativa de la letra
                      </p>
                      <div className="pt-1">
                        <Slider
                          value={[videoStyle.narrativeIntensity]}
                          onValueChange={([value]) => setVideoStyle(prev => ({ ...prev, narrativeIntensity: value }))}
                          max={100}
                          step={1}
                          className="py-2"
                        />
                        <div className="flex justify-between text-xs text-muted-foreground mt-1">
                          <span>Abstracto</span>
                          <span>Literal</span>
                        </div>
                      </div>
                    </motion.div>

                    <div className="space-y-2">
                      <Label>Imagen de Referencia</Label>
                      <div className="grid gap-4">
                        <Input
                          type="file"
                          accept="image/*"
                          onChange={async (e) => {
                            const file = e.target.files?.[0];
                            if (file) {
                              const reader = new FileReader();
                              reader.onload = async (e) => {
                                const base64 = e.target?.result as string;
                                setVideoStyle(prev => ({
                                  ...prev,
                                  referenceImage: base64
                                }));
                                await analyzeReferenceImage(base64);
                              };
                              reader.readAsDataURL(file);
                            }
                          }}
                        />
                        {videoStyle.referenceImage && (
                          <div className="relative aspect-video w-full rounded-lg overflow-hidden">
                            <img
                              src={videoStyle.referenceImage}
                              alt="Referencia de estilo"
                              className="object-cover w-full h-full"
                            />
                          </div>
                        )}
                        {videoStyle.styleDescription && (
                          <div className="p-4 bg-muted rounded-lg">
                            <p className="text-sm">{videoStyle.styleDescription}</p>
                          </div>
                        )}
                      </div>
                    </div>

                    <div className="space-y-2">
                      <Label>Director del Video</Label>
                      {directors.length > 0 ? (
                        <div className="grid gap-4">
                          <Select
                            value={videoStyle.selectedDirector?.id || ""}
                            onValueChange={(directorId) => {
                              const director = directors.find(d => d.id === directorId);
                              setVideoStyle(prev => ({
                                ...prev,
                                selectedDirector: director || null
                              }));
                            }}
                          >
                            <SelectTrigger>
                              <SelectValue placeholder="Seleccionar director" />
                            </SelectTrigger>
                            <SelectContent>
                              {directors.map((director) => (
                                <SelectItem key={director.id} value={director.id}>
                                  <div className="flex items-center gap-2">
                                    {director.imageUrl && (
                                      <img
                                        src={director.imageUrl}
                                        alt={director.name}
                                        className="w-8 h-8 rounded-full object-cover"
                                      />
                                    )}
                                    <div className="grid gap-0.5">
                                      <span className="font-medium">{director.name}</span>
                                      <span className="text-xs text-muted-foreground">{director.specialty}</span>
                                    </div>
                                  </div>
                                </SelectItem>
                              ))}
                            </SelectContent>
                          </Select>

                          {videoStyle.selectedDirector && (
                            <div className="p-4 bg-muted rounded-lg">
                              <div className="flex items-center gap-4">
                                {videoStyle.selectedDirector.imageUrl && (
                                  <img
                                    src={videoStyle.selectedDirector.imageUrl}
                                    alt={videoStyle.selectedDirector.name}
                                    className="w-16 h-16 rounded-full object-cover"
                                  />
                                )}
                                <div className="space-y-1">
                                  <h4 className="font-semibold">{videoStyle.selectedDirector.name}</h4>
                                  <p className="text-sm text-muted-foreground">{videoStyle.selectedDirector.experience}</p>
                                  <p className="text-sm">{videoStyle.selectedDirector.style}</p>
                                  <div className="flex items-center gap-1">
                                    <span className="text-orange-500">‚òÖ</span>
                                    <span className="text-sm">{videoStyle.selectedDirector.rating.toFixed(1)}</span>
                                  </div>
                                </div>
                              </div>
                            </div>
                          )}
                        </div>
                      ) : (
                        <div className="p-4 border rounded-lg bg-muted">
                          <p className="text-sm text-muted-foreground">Cargando directores...</p>
                        </div>
                      )}
                    </div>
                  </div>
                </motion.div>

                <motion.div 
                  className="border border-orange-500/30 rounded-lg overflow-hidden p-5 bg-gradient-to-br from-black to-black/70 shadow-sm relative"
                  initial={{ opacity: 0, y: 20 }}
                  animate={{ 
                    opacity: 1, 
                    y: 0,
                    boxShadow: currentStep >= 6 ? "0 0 0 2px rgba(255, 98, 0, 0.4)" : "none"
                  }}
                  transition={{ duration: 0.5, delay: 0.3 }}
                >
                  {/* Indicador de paso completado */}
                  {currentStep >= 6 && (
                    <motion.div 
                      className="absolute -top-1 -right-1 p-1 rounded-full bg-orange-100 text-orange-600 z-10"
                      initial={{ scale: 0 }}
                      animate={{ scale: 1 }}
                      transition={{ type: "spring", stiffness: 500, damping: 20 }}
                    >
                      <CheckCircle2 className="h-4 w-4" />
                    </motion.div>
                  )}
                  
                  {/* T√≠tulo con icono animado */}
                  <div className="flex items-center gap-3 mb-6">
                    <motion.div 
                      className="flex h-8 w-8 items-center justify-center rounded-full bg-orange-500/20 text-orange-500"
                      whileHover={{ scale: 1.1 }}
                      animate={{ 
                        rotate: [0, -3, 3, 0],
                      }}
                      transition={{ 
                        rotate: { repeat: Infinity, duration: 4, ease: "easeInOut", repeatDelay: 1 },
                        scale: { duration: 0.2 }
                      }}
                    >
                      <Waves className="h-4 w-4" />
                    </motion.div>
                    <div>
                      <Label className="text-lg font-semibold bg-clip-text text-transparent bg-gradient-to-r from-orange-500 to-orange-300">5. Sincronizar Beats</Label>
                      <p className="text-xs text-white/70">Detecta puntos clave para sincronizaci√≥n de video</p>
                    </div>
                  </div>
                  
                  <motion.div
                    initial={{ opacity: 0, y: 10 }}
                    animate={{ opacity: 1, y: 0 }}
                    transition={{ duration: 0.3 }}
                  >
                    <Button
                      onClick={syncAudioWithTimeline}
                      disabled={!audioBuffer || isGeneratingShots || currentStep < 3}
                      className="w-full mb-3 h-12 bg-gradient-to-r from-orange-600 to-orange-500 hover:from-orange-700 hover:to-orange-600 border-0 shadow-md"
                    >
                      {isGeneratingShots ? (
                        <motion.div className="flex items-center justify-center gap-2" animate={{ opacity: [0.7, 1] }} transition={{ duration: 0.5, repeat: Infinity, repeatType: "reverse" }}>
                          <Loader2 className="mr-2 h-4 w-4 animate-spin" />
                          <span>Detectando patrones r√≠tmicos...</span>
                        </motion.div>
                      ) : (
                        <motion.div className="flex items-center justify-center" whileHover={{ scale: 1.03 }} transition={{ duration: 0.2 }}>
                          <RefreshCcw className="mr-2 h-4 w-4" />
                          <span>Detectar Cortes Musicales</span>
                        </motion.div>
                      )}
                    </Button>
                    
                    {/* Bot√≥n para generar im√°genes con Gemini */}
                    {timelineItems.length > 0 && scriptContent && (
                      <motion.div
                        initial={{ opacity: 0, y: 5 }}
                        animate={{ opacity: 1, y: 0 }}
                        transition={{ duration: 0.3, delay: 0.1 }}
                        className="mt-3"
                      >
                        <Button
                          onClick={generateAllSceneImages}
                          disabled={isGeneratingImages || !scriptContent}
                          className="w-full h-12 bg-gradient-to-r from-purple-600 to-pink-500 hover:from-purple-700 hover:to-pink-600 border-0 shadow-md"
                        >
                          {isGeneratingImages ? (
                            <motion.div className="flex items-center justify-center gap-2" animate={{ opacity: [0.7, 1] }} transition={{ duration: 0.5, repeat: Infinity, repeatType: "reverse" }}>
                              <Loader2 className="mr-2 h-4 w-4 animate-spin" />
                              <span>Generando im√°genes con Gemini...</span>
                            </motion.div>
                          ) : (
                            <motion.div className="flex items-center justify-center" whileHover={{ scale: 1.03 }} transition={{ duration: 0.2 }}>
                              <Sparkles className="mr-2 h-4 w-4" />
                              <span>Generar Im√°genes ({artistReferenceImages.length > 0 ? `${artistReferenceImages.length} referencias` : 'sin referencias'})</span>
                            </motion.div>
                          )}
                        </Button>
                      </motion.div>
                    )}
                    
                    {/* Bot√≥n para descargar el archivo JSON de timecodes */}
                    {beatsJsonData && (
                      <motion.div
                        initial={{ opacity: 0, y: 5 }}
                        animate={{ opacity: 1, y: 0 }}
                        transition={{ duration: 0.3, delay: 0.2 }}
                      >
                        <Button
                          onClick={downloadBeatsJSON}
                          variant="outline"
                          className="w-full mt-2 border-orange-500/20 text-orange-500 hover:bg-orange-500/10"
                        >
                          <Download className="mr-2 h-4 w-4" />
                          <span>Descargar Timecodes JSON</span>
                        </Button>
                      </motion.div>
                    )}
                  </motion.div>
                  
                  {/* Visualizaci√≥n de los beats detectados */}
                  {beatsJsonData && (
                    <motion.div 
                      className="mt-5 border border-orange-500/20 rounded-lg p-4 bg-black/50 overflow-hidden"
                      initial={{ opacity: 0, height: 0 }}
                      animate={{ opacity: 1, height: "auto" }}
                      transition={{ duration: 0.5, delay: 0.3 }}
                    >
                      <div className="flex items-center justify-between">
                        <div className="flex items-center gap-2">
                          <motion.div 
                            animate={{ scale: [1, 1.1, 1] }}
                            transition={{ duration: 2, repeat: Infinity }}
                            className="h-5 w-5 rounded-full bg-orange-500/20 flex items-center justify-center"
                          >
                            <Activity className="h-3 w-3 text-orange-500" />
                          </motion.div>
                          <h4 className="font-medium text-white/90">Beats Detectados</h4>
                        </div>
                        <Button 
                          variant="ghost" 
                          size="sm" 
                          className="h-7 px-2 text-xs text-orange-500 hover:text-orange-600 hover:bg-orange-500/10"
                          onClick={() => setShowBeatDetails(prev => !prev)}
                        >
                          {showBeatDetails ? (
                            <motion.div 
                              className="flex items-center gap-1"
                              initial={{ x: 0 }}
                              whileHover={{ x: -2 }}
                            >
                              <ChevronUp className="h-3 w-3" />
                              <span>Ocultar detalles</span>
                            </motion.div>
                          ) : (
                            <motion.div 
                              className="flex items-center gap-1"
                              initial={{ x: 0 }}
                              whileHover={{ x: 2 }}
                            >
                              <span>Ver detalles</span>
                              <ChevronDown className="h-3 w-3" />
                            </motion.div>
                          )}
                        </Button>
                      </div>
                      
                      <div className="text-xs text-white/80 mt-3 mb-2">
                        Clasificaci√≥n por tipo de intensidad:
                      </div>
                      <div className="flex items-center gap-3 mb-3">
                        <motion.div 
                          className="flex items-center bg-white/80 px-2 py-1 rounded-full shadow-sm border border-red-200"
                          whileHover={{ scale: 1.05 }}
                        >
                          <div className="w-3 h-3 rounded-full bg-red-500 mr-1.5"></div>
                          <span className="text-xs font-medium text-red-700">Downbeat</span>
                        </motion.div>
                        <motion.div 
                          className="flex items-center bg-white/80 px-2 py-1 rounded-full shadow-sm border border-yellow-200"
                          whileHover={{ scale: 1.05 }}
                        >
                          <div className="w-3 h-3 rounded-full bg-yellow-500 mr-1.5"></div>
                          <span className="text-xs font-medium text-yellow-700">Accent</span>
                        </motion.div>
                        <motion.div 
                          className="flex items-center bg-white/80 px-2 py-1 rounded-full shadow-sm border border-blue-200"
                          whileHover={{ scale: 1.05 }}
                        >
                          <div className="w-3 h-3 rounded-full bg-blue-500 mr-1.5"></div>
                          <span className="text-xs font-medium text-blue-700">Beat</span>
                        </motion.div>
                      </div>
                      
                      {/* Visualizaci√≥n gr√°fica de beats */}
                      <motion.div 
                        className="h-16 border rounded-lg shadow-inner bg-white/70 flex items-end p-1 overflow-x-auto relative"
                        whileHover={{ boxShadow: "0 2px 8px rgba(0,0,0,0.1)" }}
                      >
                        {JSON.parse(beatsJsonData).beats.map((beat: any, idx: number) => {
                          // Determinar color seg√∫n tipo de beat
                          const beatColor = beat.type === 'downbeat' 
                            ? 'bg-red-500' 
                            : beat.type === 'accent'
                              ? 'bg-yellow-500'
                              : 'bg-blue-500';
                          
                          // Altura basada en intensidad (0-1)
                          const height = `${Math.max(15, Math.min(100, beat.intensity * 90))}%`;
                          
                          return (
                            <motion.div 
                              key={idx} 
                              className={`${beatColor} w-1 mx-[1px] rounded-t hover:w-2 hover:mx-0 transition-all cursor-pointer`} 
                              style={{ height }}
                              title={`${beat.timecode} - ${beat.type} (${beat.intensity.toFixed(2)})`}
                              onClick={() => setSelectedBeatIndex(idx)}
                              initial={{ y: 20, opacity: 0 }}
                              animate={{ y: 0, opacity: 1 }}
                              transition={{ delay: idx * 0.001, duration: 0.2 }}
                              whileHover={{ 
                                boxShadow: "0 0 8px rgba(0,0,0,0.3)",
                                filter: "brightness(1.2)"
                              }}
                            />
                          );
                        })}
                        
                        {/* Indicador de beat seleccionado */}
                        {selectedBeatIndex !== null && (
                          <motion.div 
                            className="absolute bottom-0 border-l-2 border-dashed border-primary h-full" 
                            initial={{ opacity: 0 }}
                            animate={{ opacity: 1 }}
                            style={{ 
                              left: `${selectedBeatIndex * 3 + 4}px`, 
                              transition: 'left 0.2s ease-out' 
                            }} 
                          />
                        )}
                      </motion.div>
                      
                      {/* Panel de detalles de beats */}
                      {showBeatDetails && (
                        <motion.div 
                          className="mt-4 pt-3 border-t border-orange-500/20 text-xs"
                          initial={{ opacity: 0, y: -10 }}
                          animate={{ opacity: 1, y: 0 }}
                          transition={{ duration: 0.3 }}
                        >
                          <div className="flex justify-between mb-3 bg-black/50 p-2 rounded-md shadow-sm">
                            <div className="flex flex-col items-center">
                              <span className="font-medium text-orange-500">An√°lisis del Ritmo</span>
                              <span className="text-white text-sm font-semibold">{JSON.parse(beatsJsonData).metadata.beatAnalysis.patternComplexity}</span>
                            </div>
                            <div className="flex flex-col items-center">
                              <span className="font-medium text-orange-500">BPM Estimado</span>
                              <span className="text-white text-sm font-semibold">{JSON.parse(beatsJsonData).metadata.bpm}</span>
                            </div>
                          </div>
                          
                          <div className="grid grid-cols-3 gap-2 mb-3">
                            <motion.div 
                              className="flex flex-col items-center border border-red-500/20 rounded-lg p-2 bg-black/40 shadow-sm"
                              whileHover={{ y: -2, boxShadow: "0 4px 8px rgba(0,0,0,0.2)" }}
                            >
                              <span className="text-red-500 font-bold text-lg">
                                {JSON.parse(beatsJsonData).metadata.beatAnalysis.beatTypes.downbeats}
                              </span>
                              <span className="text-[10px] text-white/90 font-medium">Downbeats</span>
                            </motion.div>
                            <motion.div 
                              className="flex flex-col items-center border border-yellow-500/20 rounded-lg p-2 bg-black/40 shadow-sm"
                              whileHover={{ y: -2, boxShadow: "0 4px 8px rgba(0,0,0,0.2)" }}
                            >
                              <span className="text-yellow-500 font-bold text-lg">
                                {JSON.parse(beatsJsonData).metadata.beatAnalysis.beatTypes.accents}
                              </span>
                              <span className="text-[10px] text-white/90 font-medium">Accents</span>
                            </motion.div>
                            <motion.div 
                              className="flex flex-col items-center border border-blue-500/20 rounded-lg p-2 bg-black/40 shadow-sm"
                              whileHover={{ y: -2, boxShadow: "0 4px 8px rgba(0,0,0,0.2)" }}
                            >
                              <span className="text-blue-500 font-bold text-lg">
                                {JSON.parse(beatsJsonData).metadata.beatAnalysis.beatTypes.regularBeats}
                              </span>
                              <span className="text-[10px] text-white/90 font-medium">Beats</span>
                            </motion.div>
                          </div>
                          
                          {/* Detalles del beat seleccionado, si hay alguno */}
                          {selectedBeatIndex !== null && (
                            <motion.div 
                              className="p-3 rounded-lg border border-orange-500/20 bg-black/60 shadow-sm"
                              initial={{ opacity: 0, scale: 0.95 }}
                              animate={{ opacity: 1, scale: 1 }}
                              transition={{ duration: 0.3 }}
                            >
                              <h5 className="font-medium mb-2 flex items-center gap-2 text-orange-500">
                                <Music2 className="h-3 w-3" />
                                <span>Beat #{selectedBeatIndex + 1}</span>
                              </h5>
                              <div className="grid grid-cols-2 gap-2">
                                <div className="flex items-center gap-1.5">
                                  <span className="text-orange-400">Tipo:</span> 
                                  <span className={
                                    JSON.parse(beatsJsonData).beats[selectedBeatIndex].type === 'downbeat'
                                      ? 'text-red-500 font-medium bg-red-600/20 px-1.5 py-0.5 rounded-full text-[10px]'
                                      : JSON.parse(beatsJsonData).beats[selectedBeatIndex].type === 'accent'
                                        ? 'text-yellow-500 font-medium bg-yellow-600/20 px-1.5 py-0.5 rounded-full text-[10px]'
                                        : 'text-blue-500 font-medium bg-blue-600/20 px-1.5 py-0.5 rounded-full text-[10px]'
                                  }>
                                    {JSON.parse(beatsJsonData).beats[selectedBeatIndex].type}
                                  </span>
                                </div>
                                <div className="flex items-center gap-1.5">
                                  <span className="text-orange-400">Tiempo:</span>
                                  <span className="font-mono bg-black/40 text-white px-1.5 py-0.5 rounded-full text-[10px]">
                                    {JSON.parse(beatsJsonData).beats[selectedBeatIndex].timecode}
                                  </span>
                                </div>
                                <div className="flex items-center gap-1.5">
                                  <span className="text-orange-400">Intensidad:</span>
                                  <span className="font-medium text-white">
                                    {(JSON.parse(beatsJsonData).beats[selectedBeatIndex].intensity * 100).toFixed(0)}%
                                  </span>
                                </div>
                                <div className="flex items-center gap-1.5">
                                  <span className="text-orange-400">Energ√≠a:</span>
                                  <span className="font-medium text-white">
                                    {JSON.parse(beatsJsonData).beats[selectedBeatIndex].energy.toFixed(4)}
                                  </span>
                                </div>
                              </div>
                            </motion.div>
                          )}
                        </motion.div>
                      )}
                    </motion.div>
                  )}
                </motion.div>

                <div className="border rounded-lg p-4 mt-4">
                  <Label className="text-lg font-semibold mb-4">Estilo de Edici√≥n</Label>
                  <RadioGroup
                    value={selectedEditingStyle}
                    onValueChange={setSelectedEditingStyle}
                    className="grid grid-cols-2 gap-4"
                  >
                    {editingStyles.map((style) => (
                      <div key={style.id} className="flex items-start space-x-3">
                        <RadioGroupItem value={style.id} id={style.id} />
                        <div className="grid gap-1.5">
                          <Label htmlFor={style.id} className="font-medium">
                            {style.name}
                          </Label>
                          <p className="text-sm text-muted-foreground">
                            {style.description}
                          </p>
                        </div>
                      </div>
                    ))}
                  </RadioGroup>
                </div>

                <motion.div 
                  className="border border-orange-500/20 rounded-lg overflow-hidden p-5 bg-gradient-to-br from-black to-black/70 shadow-sm relative"
                  initial={{ opacity: 0, y: 20 }}
                  animate={{ 
                    opacity: 1, 
                    y: 0,
                    boxShadow: currentStep >= 7 ? "0 0 0 2px rgba(249, 115, 22, 0.3)" : "none"
                  }}
                  transition={{ duration: 0.5, delay: 0.3 }}
                >
                  {/* Indicador de paso completado */}
                  {currentStep >= 7 && (
                    <motion.div 
                      className="absolute -top-1 -right-1 p-1 rounded-full bg-orange-900 text-orange-400 z-10"
                      initial={{ scale: 0 }}
                      animate={{ scale: 1 }}
                      transition={{ type: "spring", stiffness: 500, damping: 20 }}
                    >
                      <CheckCircle2 className="h-4 w-4" />
                    </motion.div>
                  )}
                  
                  {/* T√≠tulo con icono animado */}
                  <div className="flex items-center gap-3 mb-6">
                    <motion.div 
                      className="flex h-8 w-8 items-center justify-center rounded-full bg-orange-900 text-orange-400"
                      whileHover={{ scale: 1.1 }}
                      animate={{ 
                        rotate: [0, -3, 3, 0],
                      }}
                      transition={{ 
                        rotate: { repeat: Infinity, duration: 4, ease: "easeInOut", repeatDelay: 1 },
                        scale: { duration: 0.2 }
                      }}
                    >
                      <Megaphone className="h-4 w-4" />
                    </motion.div>
                    <div>
                      <Label className="text-lg font-semibold text-orange-500">6. Generar Prompts</Label>
                      <p className="text-xs text-white/70">Crea instrucciones de IA con el estilo definido</p>
                    </div>
                  </div>
                  
                  <motion.div
                    initial={{ opacity: 0, y: 10 }}
                    animate={{ opacity: 1, y: 0 }}
                    transition={{ duration: 0.3 }}
                    className="relative"
                  >
                    <Button
                      onClick={generatePromptsForSegments}
                      disabled={
                        timelineItems.length === 0 ||
                        isGeneratingScript ||
                        currentStep < 4 ||
                        !videoStyle.mood ||
                        !videoStyle.colorPalette ||
                        !videoStyle.characterStyle
                      }
                      className="w-full h-12 mt-4 bg-gradient-to-r from-orange-600 to-orange-500 hover:from-orange-700 hover:to-orange-600 border-0 shadow-md"
                    >
                      {isGeneratingScript ? (
                        <motion.div className="flex items-center justify-center gap-2" animate={{ opacity: [0.7, 1] }} transition={{ duration: 0.5, repeat: Infinity, repeatType: "reverse" }}>
                          <Loader2 className="mr-2 h-4 w-4 animate-spin" />
                          <span>Creando prompts art√≠sticos...</span>
                        </motion.div>
                      ) : (
                        <motion.div className="flex items-center justify-center" whileHover={{ scale: 1.03 }} transition={{ duration: 0.2 }}>
                          <Edit className="mr-2 h-4 w-4" />
                          <span>Generar Prompts con Estilo</span>
                        </motion.div>
                      )}
                    </Button>
                    
                    {/* Fondo decorativo para el bot√≥n */}
                    {!isGeneratingScript && (
                      <motion.div 
                        className="absolute -bottom-2 -right-2 -left-2 h-8 rounded-b-lg opacity-30 bg-gradient-to-t from-orange-900/40 to-transparent"
                        initial={{ opacity: 0 }}
                        animate={{ opacity: 0.3 }}
                        transition={{ duration: 1, delay: 0.5 }}
                      />
                    )}
                  </motion.div>
                </motion.div>

                <motion.div 
                  className="border border-orange-500/20 rounded-lg overflow-hidden p-5 bg-gradient-to-br from-black to-black/70 shadow-sm relative"
                  initial={{ opacity: 0, y: 20 }}
                  animate={{ 
                    opacity: 1, 
                    y: 0,
                    boxShadow: currentStep >= 8 ? "0 0 0 2px rgba(249, 115, 22, 0.3)" : "none"
                  }}
                  transition={{ duration: 0.5, delay: 0.3 }}
                >
                  {/* Indicador de paso completado */}
                  {currentStep >= 8 && (
                    <motion.div 
                      className="absolute -top-1 -right-1 p-1 rounded-full bg-orange-900 text-orange-400 z-10"
                      initial={{ scale: 0 }}
                      animate={{ scale: 1 }}
                      transition={{ type: "spring", stiffness: 500, damping: 20 }}
                    >
                      <CheckCircle2 className="h-4 w-4" />
                    </motion.div>
                  )}
                  
                  {/* T√≠tulo con icono animado */}
                  <div className="flex items-center gap-3 mb-6">
                    <motion.div 
                      className="flex h-8 w-8 items-center justify-center rounded-full bg-orange-900 text-orange-400"
                      whileHover={{ scale: 1.1 }}
                      animate={{ 
                        rotate: [0, -3, 3, 0],
                      }}
                      transition={{ 
                        rotate: { repeat: Infinity, duration: 4, ease: "easeInOut", repeatDelay: 1 },
                        scale: { duration: 0.2 }
                      }}
                    >
                      <ImageIcon className="h-4 w-4" />
                    </motion.div>
                    <div>
                      <Label className="text-lg font-semibold text-orange-500">7. Generar Im√°genes</Label>
                      <p className="text-xs text-white/70">Crea visuales impactantes para cada segmento</p>
                    </div>
                  </div>
                  
                  <motion.div
                    initial={{ opacity: 0, y: 10 }}
                    animate={{ opacity: 1, y: 0 }}
                    transition={{ duration: 0.3 }}
                    className="relative mt-4"
                  >
                    <Button
                      onClick={generateShotImages}
                      disabled={
                        !timelineItems.length ||
                        isGeneratingShots ||
                        currentStep < 5
                      }
                      className="w-full h-12 bg-gradient-to-r from-orange-600 to-orange-500 hover:from-orange-700 hover:to-orange-600 border-0 shadow-md"
                    >
                      {isGeneratingShots ? (
                        <motion.div className="flex items-center justify-center gap-2" animate={{ opacity: [0.7, 1] }} transition={{ duration: 0.5, repeat: Infinity, repeatType: "reverse" }}>
                          <Loader2 className="mr-2 h-4 w-4 animate-spin" />
                          <span>Generando escenas visuales...</span>
                        </motion.div>
                      ) : (
                        <motion.div className="flex items-center justify-center" whileHover={{ scale: 1.03 }} transition={{ duration: 0.2 }}>
                          <ImageIcon className="mr-2 h-4 w-4" />
                          <span>Generar Im√°genes para Escenas</span>
                        </motion.div>
                      )}
                    </Button>
                    
                    {/* Decoraci√≥n visual */}
                    {!isGeneratingShots && (
                      <motion.div 
                        className="absolute -bottom-2 -right-2 -left-2 h-8 rounded-b-lg opacity-30 bg-gradient-to-t from-orange-900/40 to-transparent"
                        initial={{ opacity: 0 }}
                        animate={{ opacity: 0.3 }}
                        transition={{ duration: 1, delay: 0.5 }}
                      />
                    )}
                  </motion.div>
                  
                  {/* Informaci√≥n de ayuda */}
                  <motion.div 
                    className="mt-5 bg-black/50 rounded-lg p-3 text-xs text-orange-400 border border-orange-500/20 flex items-start gap-2"
                    initial={{ opacity: 0 }}
                    animate={{ opacity: 1 }}
                    transition={{ delay: 0.6, duration: 0.4 }}
                  >
                    <HelpCircle className="h-4 w-4 text-orange-400/70 mt-0.5 flex-shrink-0" />
                    <div className="text-white/80">
                      Este paso utilizar√° los prompts generados para crear im√°genes para cada segmento del video. 
                      Las im√°genes generadas se adaptar√°n al estilo visual que has definido anteriormente.
                    </div>
                  </motion.div>
                </motion.div>

                {/* Componente de Generaci√≥n de Video (Paso 8) */}
                {currentStep === 8 && (
                  <div className="mt-6">
                    <div className="border rounded-lg p-4 mb-6">
                      <Label className="text-lg font-semibold mb-4">8. Generaci√≥n de Video</Label>
                      <p className="text-sm text-muted-foreground mb-4">
                        Genera un video a partir de tus escenas sincronizadas. Este paso utiliza IA para convertir
                        tus im√°genes en secuencias de video fluidas con efectos profesionales.
                      </p>
                      <VideoGenerator
                        onGenerateVideo={async (settings) => {
                          console.log("Configuraci√≥n para generar video:", settings);
                          toast({
                            title: "Generaci√≥n iniciada",
                            description: `Generando video con modelo ${settings.model}, calidad ${settings.quality}`
                          });
                          await generateVideo();
                        }}
                        isLoading={isGeneratingVideo}
                        scenesCount={timelineItems.length}
                        clips={timelineItems.map(item => ({
                          id: item.id,
                          start: (item.start_time - (timelineItems[0]?.start_time || 0)) / 1000,
                          duration: item.duration / 1000,
                          type: 'image' as const,
                          layer: 1, // A√±adimos layer=1 para video/imagen
                          thumbnail: item.generatedImage || item.firebaseUrl,
                          title: item.shotType || 'Escena',
                          description: item.description || '',
                          imageUrl: item.generatedImage || item.firebaseUrl,
                          imagePrompt: item.imagePrompt,
                          metadata: {
                            section: item.metadata?.section || 'default',
                            movementApplied: item.metadata?.movementApplied,
                            movementPattern: item.metadata?.movementPattern,
                            movementIntensity: item.metadata?.movementIntensity,
                            faceSwapApplied: item.metadata?.faceSwapApplied,
                            musicianIntegrated: item.metadata?.musicianIntegrated
                          }
                        }))}
                        duration={audioBuffer?.duration || 0}
                        isGenerating={isGeneratingVideo}
                        onGenerate={async () => { await generateVideo(); return; }}
                      />
                      {videoId && (
                        <Button 
                          className="w-full mt-4 bg-gradient-to-r from-orange-600 to-orange-500 hover:from-orange-700 hover:to-orange-600 border-0 shadow-md"
                          onClick={() => setCurrentStep(9)}
                        >
                          <CheckCircle2 className="mr-2 h-4 w-4" />
                          Continuar a Renderizado Final
                        </Button>
                      )}
                    </div>
                  </div>
                )}

                {/* Personalizaci√≥n de Artista (Paso 5) */}
                {currentStep === 5 && (
                  <div className="mt-6">
                    <div className="border rounded-lg p-4 mb-6">
                      <Label className="text-lg font-semibold mb-4">5. Personalizaci√≥n de Estilo</Label>
                      <p className="text-sm text-muted-foreground mb-4">
                        Personaliza tus escenas ajustando el estilo visual y los elementos de identidad del artista.
                      </p>
                      <ArtistCustomization
                        clips={clips}
                        onUpdateClip={handleClipUpdate}
                      />
                      <Button 
                        className="w-full mt-4 bg-gradient-to-r from-orange-600 to-orange-500 hover:from-orange-700 hover:to-orange-600 border-0 shadow-md"
                        onClick={() => setCurrentStep(6)}
                      >
                        <CheckCircle2 className="mr-2 h-4 w-4" />
                        Continuar a Integraci√≥n de Movimiento
                      </Button>
                    </div>
                  </div>
                )}

                {/* Integraci√≥n de Movimiento (Paso 6) */}
                {currentStep === 6 && (
                  <div className="mt-6">
                    <div className="border rounded-lg p-4 mb-6">
                      <Label className="text-lg font-semibold mb-4">6. Integraci√≥n de Movimiento</Label>
                      <p className="text-sm text-muted-foreground mb-4">
                        A√±ade efectos de movimiento y coreograf√≠as a tus escenas para crear secuencias m√°s din√°micas.
                      </p>
                      <MovementIntegration
                        onApplyMovements={(movementSettings) => {
                          console.log("Aplicando configuraci√≥n de movimientos:", movementSettings);
                          // Aqu√≠ implementar√≠as la l√≥gica real para aplicar los movimientos
                          toast({
                            title: "Movimientos aplicados",
                            description: `Estilo: ${movementSettings.style}, Intensidad: ${movementSettings.intensity}%`
                          });
                        }}
                        isLoading={false}
                      />
                      <Button 
                        className="w-full mt-4 bg-gradient-to-r from-orange-600 to-orange-500 hover:from-orange-700 hover:to-orange-600 border-0 shadow-md"
                        onClick={() => setCurrentStep(7)}
                      >
                        <CheckCircle2 className="mr-2 h-4 w-4" />
                        Continuar a Sincronizaci√≥n de Labios
                      </Button>
                    </div>
                  </div>
                )}

                {/* M√∫sica e Integraciones Opcionales (fuera del flujo principal) */}
                {false && (
                  <MusicianIntegration
                    clips={clips}
                    audioBuffer={audioBuffer}
                    onUpdateClip={handleClipUpdate}
                  />
                )}

                {/* Sincronizaci√≥n de Labios (Paso 7) */}
                {currentStep === 7 && (
                  <div className="mt-6">
                    <div className="border rounded-lg p-4 mb-6">
                      <Label className="text-lg font-semibold mb-4">7. Sincronizaci√≥n de Labios</Label>
                      <p className="text-sm text-muted-foreground mb-4">
                        Sincroniza los movimientos labiales con la letra de la canci√≥n para dar mayor realismo al video.
                      </p>
                      <LipSyncIntegration
                        onApplyLipSync={(lipSyncSettings) => {
                          console.log("Aplicando configuraci√≥n de sincronizaci√≥n de labios:", lipSyncSettings);
                          // Aqu√≠ implementar√≠as la l√≥gica real para aplicar la sincronizaci√≥n
                          toast({
                            title: "Sincronizaci√≥n aplicada",
                            description: `Tipo: ${lipSyncSettings.sourceType}, ${lipSyncSettings.sourceType === 'text' ? 'Texto configurado' : 'Audio cargado'}`
                          });
                        }}
                        isLoading={false}
                      />
                      <Button 
                        className="w-full mt-4 bg-gradient-to-r from-orange-600 to-orange-500 hover:from-orange-700 hover:to-orange-600 border-0 shadow-md"
                        onClick={() => setCurrentStep(8)}
                      >
                        <CheckCircle2 className="mr-2 h-4 w-4" />
                        Continuar a Generaci√≥n de Video
                      </Button>
                    </div>
                  </div>
                )}

                {/* Paso 8: Generaci√≥n de Video */}
                {currentStep === 8 && (
                  <div className="mt-6">
                    <div className="border rounded-lg p-4 mb-6">
                      <Label className="text-lg font-semibold mb-4">8. Generaci√≥n de Video</Label>
                      <p className="text-sm text-muted-foreground mb-4">
                        Genera videos din√°micos a partir de tus escenas utilizando inteligencia artificial avanzada.
                      </p>
                      <VideoGenerator
                        scenesCount={timelineItems.length}
                        isLoading={isGeneratingVideo}
                        onGenerateVideo={async (settings) => {
                          console.log("Configuraci√≥n para generar video:", settings);
                          toast({
                            title: "Generaci√≥n iniciada",
                            description: `Generando video con modelo ${settings.model}, calidad ${settings.quality}`
                          });
                          
                          try {
                            await generateVideo();
                            setCurrentStep(9);
                          } catch (error) {
                            console.error("Error generando video:", error);
                            toast({
                              title: "Error",
                              description: "No se pudo generar el video. Intenta de nuevo.",
                              variant: "destructive"
                            });
                          }
                        }}
                      />
                    </div>
                  </div>
                )}

                {/* Paso 9: Renderizado Final con Upscaling */}
                {currentStep === 9 && (
                  <div className="mt-6">
                    <div className="border rounded-lg p-4 mb-6">
                      <Label className="text-lg font-semibold mb-4">9. Renderizado Final</Label>
                      <p className="text-sm text-muted-foreground mb-4">
                        El proceso de creaci√≥n ha terminado. Ahora puedes mejorar la calidad de tu video musical con Qubico Video Toolkit antes de exportarlo.
                      </p>
                      
                      <FinalRendering
                        timelineClips={timelineItems.map(item => ({
                          id: item.id,
                          start: (item.start_time - (timelineItems[0]?.start_time || 0)) / 1000,
                          duration: item.duration / 1000,
                          title: item.shotType || 'Escena',
                          type: 'video' as const,
                          layer: 1, // A√±adimos layer=1 para video/imagen
                          thumbnail: item.generatedImage || fallbackImage
                        }))}
                        videoUrl={generatedVideoUrl || '/assets/Standard_Mode_Generated_Video (2).mp4'}
                        onUpscaleVideo={async (options) => {
                          try {
                            setIsUpscaling(true);
                            // Llamar al servicio real de upscaling
                            const result = await upscaleVideo(
                              generatedVideoUrl || '/assets/Standard_Mode_Generated_Video (2).mp4', 
                              options
                            );
                            
                            if (result.success && result.url) {
                              setUpscaledVideoUrl(result.url);
                              return result.url;
                            } else {
                              throw new Error(result.error || 'Error al mejorar el video');
                            }
                          } catch (error) {
                            console.error('Error en upscaling:', error);
                            throw error;
                          } finally {
                            setIsUpscaling(false);
                          }
                        }}
                        onDownloadVideo={downloadVideo}
                        onShareVideo={shareMusicVideo}
                      />
                    </div>
                  </div>
                )}

              </div>
            </div>

            <div className="lg:order-2 order-1">
              <div className="sticky top-4 space-y-4">
                <div className="space-y-4">
                  {/* Visor de Im√°genes Generadas */}
                  {timelineItems.some(item => item.imageUrl || item.thumbnail) && (
                    <motion.div
                      initial={{ opacity: 0, y: 10 }}
                      animate={{ opacity: 1, y: 0 }}
                      className="bg-black/40 backdrop-blur-lg border border-white/10 rounded-lg p-4"
                    >
                      <div className="flex items-center gap-2 mb-3">
                        <ImageIcon className="h-5 w-5 text-purple-400" />
                        <h3 className="text-sm font-semibold text-white">Escenas Generadas</h3>
                        <Badge variant="secondary" className="ml-auto">
                          {timelineItems.filter(item => item.imageUrl || item.thumbnail).length} / {timelineItems.length}
                        </Badge>
                      </div>
                      
                      <ScrollArea className="h-[200px]">
                        <div className="grid grid-cols-3 gap-2">
                          {timelineItems.map((item, index) => {
                            const hasImage = item.imageUrl || item.thumbnail;
                            return (
                              <motion.div
                                key={item.id}
                                initial={{ opacity: 0, scale: 0.9 }}
                                animate={{ opacity: 1, scale: 1 }}
                                transition={{ delay: index * 0.05 }}
                                className="relative group cursor-pointer"
                                whileHover={{ scale: 1.05 }}
                              >
                                <div className="aspect-video rounded overflow-hidden bg-black/60 border border-white/10">
                                  {hasImage ? (
                                    <img
                                      src={item.imageUrl || item.thumbnail}
                                      alt={item.title || `Scene ${index + 1}`}
                                      className="w-full h-full object-cover"
                                    />
                                  ) : (
                                    <div className="w-full h-full flex items-center justify-center">
                                      <ImageIcon className="h-6 w-6 text-white/20" />
                                    </div>
                                  )}
                                </div>
                                <div className="absolute bottom-0 left-0 right-0 bg-gradient-to-t from-black/80 to-transparent p-1.5">
                                  <p className="text-[10px] text-white/80 font-medium truncate">
                                    {item.title || `Escena ${index + 1}`}
                                  </p>
                                </div>
                                {hasImage && (
                                  <div className="absolute top-1 right-1 bg-green-500 rounded-full p-0.5">
                                    <CheckCircle2 className="h-3 w-3 text-white" />
                                  </div>
                                )}
                              </motion.div>
                            );
                          })}
                        </div>
                      </ScrollArea>
                    </motion.div>
                  )}
                  
                  {/* Preview Player - Muestra la imagen actual basada en currentTime */}
                  {/* SIEMPRE visible si hay timeline items, muestra placeholder si falta la imagen */}
                  {timelineItems.length > 0 && (
                    <motion.div
                      initial={{ opacity: 0, y: 10 }}
                      animate={{ opacity: 1, y: 0 }}
                      className="bg-black/60 backdrop-blur-lg border border-white/10 rounded-lg p-4 mb-4"
                    >
                      <div className="flex items-center gap-2 mb-3">
                        <Play className="h-5 w-5 text-green-400" />
                        <h3 className="text-sm font-semibold text-white">Preview en Vivo</h3>
                        <Badge variant="secondary" className="ml-auto">
                          {(currentTime / 1000).toFixed(2)}s / {totalDuration.toFixed(2)}s
                        </Badge>
                      </div>
                      
                      {(() => {
                        // Encontrar la imagen actual basada en currentTime
                        const currentScene = timelineItems.find(item => {
                          const itemStart = item.start_time || 0;
                          const itemEnd = (item.start_time || 0) + (item.duration || 0);
                          return currentTime >= itemStart && currentTime < itemEnd;
                        });
                        
                        const currentImage = currentScene?.imageUrl || currentScene?.thumbnail;
                        
                        return (
                          <div className="relative">
                            {/* Preview de imagen actual */}
                            <div className="aspect-video rounded-lg overflow-hidden bg-black/80 border border-white/20 relative">
                              {currentImage ? (
                                <>
                                  <img
                                    src={currentImage}
                                    alt={currentScene?.title || "Vista previa"}
                                    className="w-full h-full object-contain"
                                  />
                                  {/* Informaci√≥n de la escena actual */}
                                  <div className="absolute bottom-0 left-0 right-0 bg-gradient-to-t from-black via-black/80 to-transparent p-3">
                                    <div className="flex items-center justify-between">
                                      <div className="flex-1">
                                        <p className="text-white font-semibold text-sm mb-1">
                                          {currentScene?.title || "Escena actual"}
                                        </p>
                                        <div className="flex items-center gap-2 text-xs">
                                          {currentScene?.shotType && (
                                            <Badge className="bg-purple-500/80 border-purple-400 text-white font-mono text-[10px] px-1.5 py-0.5">
                                              {currentScene.shotType}
                                            </Badge>
                                          )}
                                          {currentScene?.metadata?.role && (
                                            <Badge className="bg-blue-500/80 border-blue-400 text-white text-[10px] px-1.5 py-0.5">
                                              {currentScene.metadata.role}
                                            </Badge>
                                          )}
                                        </div>
                                      </div>
                                      {isPlaying && (
                                        <div className="flex items-center gap-1.5 text-green-400">
                                          <Activity className="h-4 w-4 animate-pulse" />
                                          <span className="text-[10px] font-semibold">EN VIVO</span>
                                        </div>
                                      )}
                                    </div>
                                  </div>
                                </>
                              ) : (
                                <div className="w-full h-full flex flex-col items-center justify-center gap-3">
                                  <ImageIcon className="h-12 w-12 text-white/20" />
                                  <p className="text-white/40 text-sm">
                                    {currentScene ? "Imagen a√∫n no generada" : "Ninguna escena activa"}
                                  </p>
                                </div>
                              )}
                            </div>
                            
                            {/* Indicador de progreso */}
                            {currentScene && (
                              <div className="mt-2 bg-white/10 rounded-full h-1 overflow-hidden">
                                <div 
                                  className="h-full bg-gradient-to-r from-green-400 to-blue-500 transition-all duration-100"
                                  style={{
                                    width: `${((currentTime - (currentScene.start_time || 0)) / (currentScene.duration || 1)) * 100}%`
                                  }}
                                />
                              </div>
                            )}
                          </div>
                        );
                      })()}
                    </motion.div>
                  )}
                  
                  <TimelineEditor
                    clips={clips}
                    currentTime={(currentTime - (timelineItems[0]?.start_time || 0)) / 1000}
                    duration={totalDuration}
                    audioBuffer={audioBuffer}
                    onTimeUpdate={handleTimeUpdate}
                    onClipUpdate={handleClipUpdate}
                    onSplitClip={handleSplitClip}
                    onPlay={() => setIsPlaying(true)}
                    onPause={() => setIsPlaying(false)}
                    isPlaying={isPlaying}
                    onRegenerateImage={(clipId) => {
                      const item = timelineItems.find(item => item.id === clipId);
                      if (item) {
                        regenerateImage(item);
                      }
                    }}
                  />

                  <AnalyticsDashboard
                    clips={clips}
                    audioBuffer={audioBuffer}
                    duration={totalDuration}
                  />
                </div>
              </div>
            </div>
          </div>
        </Card>
        </motion.div>
      </motion.div>
    </div>
  );
}